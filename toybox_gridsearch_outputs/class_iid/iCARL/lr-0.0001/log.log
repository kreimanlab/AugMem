=============Stream Learning Run 0=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	0.905 (0.905)	60.00 (60.00)
[1/294]	0.895 (0.900)	60.00 (60.00)
[2/294]	0.820 (0.873)	50.00 (56.67)
[3/294]	0.553 (0.793)	70.00 (60.00)
[4/294]	1.166 (0.868)	50.00 (58.00)
[5/294]	1.049 (0.898)	50.00 (56.67)
[6/294]	0.967 (0.908)	50.00 (55.71)
[7/294]	0.687 (0.880)	55.00 (55.62)
[8/294]	0.491 (0.837)	85.00 (58.89)
[9/294]	0.676 (0.821)	55.00 (58.50)
[10/294]	0.620 (0.803)	60.00 (58.64)
[11/294]	0.555 (0.782)	60.00 (58.75)
[12/294]	0.585 (0.767)	60.00 (58.85)
[13/294]	0.436 (0.743)	80.00 (60.36)
[14/294]	0.631 (0.736)	65.00 (60.67)
[15/294]	0.617 (0.728)	65.00 (60.94)
[16/294]	0.426 (0.710)	90.00 (62.65)
[17/294]	0.467 (0.697)	85.00 (63.89)
[18/294]	0.465 (0.685)	90.00 (65.26)
[19/294]	0.393 (0.670)	90.00 (66.50)
[20/294]	0.425 (0.658)	85.00 (67.38)
[21/294]	0.494 (0.651)	75.00 (67.73)
[22/294]	0.616 (0.649)	65.00 (67.61)
[23/294]	0.509 (0.644)	60.00 (67.29)
[24/294]	0.340 (0.631)	90.00 (68.20)
[25/294]	0.392 (0.622)	90.00 (69.04)
[26/294]	0.380 (0.613)	85.00 (69.63)
[27/294]	0.459 (0.608)	75.00 (69.82)
[28/294]	0.330 (0.598)	95.00 (70.69)
[29/294]	0.385 (0.591)	85.00 (71.17)
[30/294]	0.271 (0.581)	90.00 (71.77)
[31/294]	0.408 (0.575)	80.00 (72.03)
[32/294]	0.191 (0.564)	90.00 (72.58)
[33/294]	0.398 (0.559)	80.00 (72.79)
[34/294]	0.309 (0.552)	80.00 (73.00)
[35/294]	0.201 (0.542)	100.00 (73.75)
[36/294]	0.343 (0.537)	85.00 (74.05)
[37/294]	0.255 (0.529)	90.00 (74.47)
[38/294]	0.436 (0.527)	85.00 (74.74)
[39/294]	0.367 (0.523)	85.00 (75.00)
[40/294]	0.171 (0.514)	95.00 (75.49)
[41/294]	0.165 (0.506)	100.00 (76.07)
[42/294]	0.198 (0.499)	95.00 (76.51)
[43/294]	0.222 (0.492)	95.00 (76.93)
[44/294]	0.328 (0.489)	80.00 (77.00)
[45/294]	0.307 (0.485)	85.00 (77.17)
[46/294]	0.243 (0.480)	90.00 (77.45)
[47/294]	0.563 (0.481)	75.00 (77.40)
[48/294]	0.257 (0.477)	85.00 (77.55)
[49/294]	0.188 (0.471)	90.00 (77.80)
[50/294]	0.124 (0.464)	100.00 (78.24)
[51/294]	0.399 (0.463)	85.00 (78.37)
[52/294]	0.231 (0.459)	90.00 (78.58)
[53/294]	0.108 (0.452)	100.00 (78.98)
[54/294]	0.162 (0.447)	100.00 (79.36)
[55/294]	0.392 (0.446)	85.00 (79.46)
[56/294]	0.157 (0.441)	95.00 (79.74)
[57/294]	0.264 (0.438)	90.00 (79.91)
[58/294]	0.095 (0.432)	100.00 (80.25)
[59/294]	0.163 (0.427)	95.00 (80.50)
[60/294]	0.180 (0.423)	90.00 (80.66)
[61/294]	0.176 (0.419)	95.00 (80.89)
[62/294]	0.254 (0.417)	85.00 (80.95)
[63/294]	0.116 (0.412)	95.00 (81.17)
[64/294]	0.264 (0.410)	90.00 (81.31)
[65/294]	0.123 (0.405)	100.00 (81.59)
[66/294]	0.103 (0.401)	95.00 (81.79)
[67/294]	0.160 (0.397)	90.00 (81.91)
[68/294]	0.141 (0.394)	95.00 (82.10)
[69/294]	0.195 (0.391)	85.00 (82.14)
[70/294]	0.065 (0.386)	100.00 (82.39)
[71/294]	0.252 (0.384)	85.00 (82.43)
[72/294]	0.329 (0.384)	90.00 (82.53)
[73/294]	0.157 (0.381)	95.00 (82.70)
[74/294]	0.110 (0.377)	100.00 (82.93)
[75/294]	0.049 (0.373)	100.00 (83.16)
[76/294]	0.059 (0.369)	100.00 (83.38)
[77/294]	0.018 (0.364)	100.00 (83.59)
[78/294]	0.096 (0.361)	95.00 (83.73)
[79/294]	0.172 (0.358)	95.00 (83.88)
[80/294]	0.335 (0.358)	95.00 (84.01)
[81/294]	0.027 (0.354)	100.00 (84.21)
[82/294]	0.151 (0.352)	100.00 (84.40)
[83/294]	0.115 (0.349)	95.00 (84.52)
[84/294]	0.168 (0.347)	90.00 (84.59)
[85/294]	0.189 (0.345)	90.00 (84.65)
[86/294]	0.215 (0.343)	90.00 (84.71)
[87/294]	0.127 (0.341)	95.00 (84.83)
[88/294]	0.138 (0.339)	95.00 (84.94)
[89/294]	0.332 (0.338)	90.00 (85.00)
[90/294]	0.220 (0.337)	90.00 (85.05)
[91/294]	0.100 (0.335)	95.00 (85.16)
[92/294]	0.413 (0.335)	75.00 (85.05)
[93/294]	0.094 (0.333)	100.00 (85.21)
[94/294]	0.208 (0.332)	95.00 (85.32)
[95/294]	0.074 (0.329)	100.00 (85.47)
[96/294]	0.186 (0.327)	95.00 (85.57)
[97/294]	0.071 (0.325)	95.00 (85.66)
[98/294]	0.055 (0.322)	100.00 (85.81)
[99/294]	0.068 (0.320)	95.00 (85.90)
[100/294]	0.098 (0.317)	95.00 (85.99)
[101/294]	0.080 (0.315)	95.00 (86.08)
[102/294]	0.250 (0.314)	85.00 (86.07)
[103/294]	0.281 (0.314)	90.00 (86.11)
[104/294]	0.084 (0.312)	100.00 (86.24)
[105/294]	0.067 (0.310)	95.00 (86.32)
[106/294]	0.098 (0.308)	100.00 (86.45)
[107/294]	0.066 (0.305)	100.00 (86.57)
[108/294]	0.097 (0.303)	100.00 (86.70)
[109/294]	0.088 (0.301)	95.00 (86.77)
[110/294]	0.082 (0.299)	100.00 (86.89)
[111/294]	0.050 (0.297)	100.00 (87.01)
[112/294]	0.148 (0.296)	95.00 (87.08)
[113/294]	0.146 (0.295)	90.00 (87.11)
[114/294]	0.060 (0.293)	100.00 (87.22)
[115/294]	0.176 (0.292)	90.00 (87.24)
[116/294]	0.069 (0.290)	95.00 (87.31)
[117/294]	0.075 (0.288)	100.00 (87.42)
[118/294]	0.167 (0.287)	90.00 (87.44)
[119/294]	0.127 (0.286)	95.00 (87.50)
[120/294]	0.092 (0.284)	100.00 (87.60)
[121/294]	0.153 (0.283)	90.00 (87.62)
[122/294]	0.248 (0.283)	95.00 (87.68)
[123/294]	0.051 (0.281)	100.00 (87.78)
[124/294]	0.155 (0.280)	90.00 (87.80)
[125/294]	0.191 (0.279)	90.00 (87.82)
[126/294]	0.658 (0.282)	75.00 (87.72)
[127/294]	0.155 (0.281)	95.00 (87.77)
[128/294]	0.072 (0.279)	95.00 (87.83)
[129/294]	0.143 (0.278)	90.00 (87.85)
[130/294]	0.057 (0.277)	100.00 (87.94)
[131/294]	0.227 (0.276)	95.00 (87.99)
[132/294]	0.122 (0.275)	90.00 (88.01)
[133/294]	0.345 (0.276)	90.00 (88.02)
[134/294]	0.176 (0.275)	90.00 (88.04)
[135/294]	0.401 (0.276)	90.00 (88.05)
[136/294]	0.058 (0.274)	100.00 (88.14)
[137/294]	0.121 (0.273)	95.00 (88.19)
[138/294]	0.066 (0.272)	100.00 (88.27)
[139/294]	0.130 (0.271)	100.00 (88.36)
[140/294]	0.212 (0.270)	95.00 (88.40)
[141/294]	0.150 (0.269)	90.00 (88.42)
[142/294]	0.093 (0.268)	100.00 (88.50)
[143/294]	0.052 (0.267)	100.00 (88.58)
[144/294]	0.067 (0.265)	95.00 (88.62)
[145/294]	0.132 (0.264)	100.00 (88.70)
[146/294]	0.071 (0.263)	100.00 (88.78)
[147/294]	0.030 (0.261)	100.00 (88.85)
[148/294]	0.236 (0.261)	90.00 (88.86)
[149/294]	0.324 (0.262)	85.00 (88.83)
[150/294]	0.206 (0.261)	90.00 (88.84)
[151/294]	0.174 (0.261)	95.00 (88.88)
[152/294]	0.020 (0.259)	100.00 (88.95)
[153/294]	0.038 (0.258)	100.00 (89.03)
[154/294]	0.039 (0.256)	100.00 (89.10)
[155/294]	0.065 (0.255)	100.00 (89.17)
[156/294]	0.174 (0.255)	85.00 (89.14)
[157/294]	0.015 (0.253)	100.00 (89.21)
[158/294]	0.050 (0.252)	100.00 (89.28)
[159/294]	0.252 (0.252)	90.00 (89.28)
[160/294]	0.177 (0.251)	95.00 (89.32)
[161/294]	0.114 (0.250)	95.00 (89.35)
[162/294]	0.133 (0.250)	95.00 (89.39)
[163/294]	0.070 (0.249)	95.00 (89.42)
[164/294]	0.069 (0.248)	95.00 (89.45)
[165/294]	0.072 (0.246)	100.00 (89.52)
[166/294]	0.066 (0.245)	95.00 (89.55)
[167/294]	0.067 (0.244)	100.00 (89.61)
[168/294]	0.129 (0.244)	95.00 (89.64)
[169/294]	0.122 (0.243)	95.00 (89.68)
[170/294]	0.106 (0.242)	95.00 (89.71)
[171/294]	0.206 (0.242)	90.00 (89.71)
[172/294]	0.066 (0.241)	95.00 (89.74)
[173/294]	0.049 (0.240)	100.00 (89.80)
[174/294]	0.201 (0.240)	85.00 (89.77)
[175/294]	0.085 (0.239)	95.00 (89.80)
[176/294]	0.056 (0.238)	100.00 (89.86)
[177/294]	0.125 (0.237)	90.00 (89.86)
[178/294]	0.033 (0.236)	100.00 (89.92)
[179/294]	0.272 (0.236)	85.00 (89.89)
[180/294]	0.024 (0.235)	100.00 (89.94)
[181/294]	0.152 (0.234)	95.00 (89.97)
[182/294]	0.107 (0.234)	95.00 (90.00)
[183/294]	0.048 (0.233)	100.00 (90.05)
[184/294]	0.026 (0.232)	100.00 (90.11)
[185/294]	0.086 (0.231)	100.00 (90.16)
[186/294]	0.034 (0.230)	100.00 (90.21)
[187/294]	0.080 (0.229)	100.00 (90.27)
[188/294]	0.229 (0.229)	85.00 (90.24)
[189/294]	0.338 (0.230)	90.00 (90.24)
[190/294]	0.048 (0.229)	100.00 (90.29)
[191/294]	0.024 (0.228)	100.00 (90.34)
[192/294]	0.123 (0.227)	95.00 (90.36)
[193/294]	0.052 (0.226)	95.00 (90.39)
[194/294]	0.199 (0.226)	95.00 (90.41)
[195/294]	0.090 (0.225)	95.00 (90.43)
[196/294]	0.009 (0.224)	100.00 (90.48)
[197/294]	0.064 (0.223)	95.00 (90.51)
[198/294]	0.037 (0.222)	100.00 (90.55)
[199/294]	0.202 (0.222)	90.00 (90.55)
[200/294]	0.064 (0.222)	100.00 (90.60)
[201/294]	0.439 (0.223)	90.00 (90.59)
[202/294]	0.179 (0.222)	95.00 (90.62)
[203/294]	0.061 (0.222)	100.00 (90.66)
[204/294]	0.153 (0.221)	90.00 (90.66)
[205/294]	0.022 (0.220)	100.00 (90.70)
[206/294]	0.133 (0.220)	95.00 (90.72)
[207/294]	0.049 (0.219)	100.00 (90.77)
[208/294]	0.153 (0.219)	90.00 (90.77)
[209/294]	0.085 (0.218)	95.00 (90.79)
[210/294]	0.053 (0.217)	95.00 (90.81)
[211/294]	0.006 (0.216)	100.00 (90.85)
[212/294]	0.036 (0.216)	100.00 (90.89)
[213/294]	0.071 (0.215)	95.00 (90.91)
[214/294]	0.054 (0.214)	100.00 (90.95)
[215/294]	0.244 (0.214)	95.00 (90.97)
[216/294]	0.104 (0.214)	100.00 (91.01)
[217/294]	0.081 (0.213)	95.00 (91.03)
[218/294]	0.045 (0.212)	100.00 (91.07)
[219/294]	0.073 (0.212)	95.00 (91.09)
[220/294]	0.055 (0.211)	95.00 (91.11)
[221/294]	0.023 (0.210)	100.00 (91.15)
[222/294]	0.196 (0.210)	90.00 (91.14)
[223/294]	0.078 (0.209)	95.00 (91.16)
[224/294]	0.025 (0.209)	100.00 (91.20)
[225/294]	0.136 (0.208)	95.00 (91.22)
[226/294]	0.024 (0.208)	100.00 (91.26)
[227/294]	0.037 (0.207)	100.00 (91.29)
[228/294]	0.020 (0.206)	100.00 (91.33)
[229/294]	0.104 (0.206)	95.00 (91.35)
[230/294]	0.111 (0.205)	95.00 (91.36)
[231/294]	0.096 (0.205)	95.00 (91.38)
[232/294]	0.190 (0.205)	95.00 (91.39)
[233/294]	0.051 (0.204)	100.00 (91.43)
[234/294]	0.075 (0.203)	100.00 (91.47)
[235/294]	0.029 (0.203)	100.00 (91.50)
[236/294]	0.025 (0.202)	100.00 (91.54)
[237/294]	0.071 (0.201)	95.00 (91.55)
[238/294]	0.035 (0.201)	100.00 (91.59)
[239/294]	0.026 (0.200)	100.00 (91.62)
[240/294]	0.106 (0.200)	90.00 (91.62)
[241/294]	0.138 (0.199)	95.00 (91.63)
[242/294]	0.068 (0.199)	100.00 (91.67)
[243/294]	0.008 (0.198)	100.00 (91.70)
[244/294]	0.331 (0.199)	90.00 (91.69)
[245/294]	0.020 (0.198)	100.00 (91.73)
[246/294]	0.093 (0.197)	95.00 (91.74)
[247/294]	0.071 (0.197)	95.00 (91.75)
[248/294]	0.041 (0.196)	100.00 (91.79)
[249/294]	0.210 (0.196)	95.00 (91.80)
[250/294]	0.120 (0.196)	95.00 (91.81)
[251/294]	0.144 (0.196)	95.00 (91.83)
[252/294]	0.102 (0.195)	95.00 (91.84)
[253/294]	0.122 (0.195)	95.00 (91.85)
[254/294]	0.064 (0.195)	100.00 (91.88)
[255/294]	0.078 (0.194)	95.00 (91.89)
[256/294]	0.104 (0.194)	95.00 (91.91)
[257/294]	0.236 (0.194)	90.00 (91.90)
[258/294]	0.028 (0.193)	100.00 (91.93)
[259/294]	0.035 (0.193)	100.00 (91.96)
[260/294]	0.014 (0.192)	100.00 (91.99)
[261/294]	0.043 (0.191)	95.00 (92.00)
[262/294]	0.032 (0.191)	100.00 (92.03)
[263/294]	0.037 (0.190)	100.00 (92.06)
[264/294]	0.115 (0.190)	95.00 (92.08)
[265/294]	0.011 (0.189)	100.00 (92.11)
[266/294]	0.022 (0.189)	100.00 (92.13)
[267/294]	0.194 (0.189)	95.00 (92.15)
[268/294]	0.020 (0.188)	100.00 (92.17)
[269/294]	0.112 (0.188)	95.00 (92.19)
[270/294]	0.080 (0.187)	100.00 (92.21)
[271/294]	0.058 (0.187)	95.00 (92.22)
[272/294]	0.123 (0.187)	95.00 (92.23)
[273/294]	0.049 (0.186)	100.00 (92.26)
[274/294]	0.028 (0.186)	100.00 (92.29)
[275/294]	0.044 (0.185)	100.00 (92.32)
[276/294]	0.013 (0.184)	100.00 (92.35)
[277/294]	0.092 (0.184)	95.00 (92.36)
[278/294]	0.113 (0.184)	95.00 (92.37)
[279/294]	0.040 (0.183)	100.00 (92.39)
[280/294]	0.061 (0.183)	100.00 (92.42)
[281/294]	0.067 (0.183)	95.00 (92.43)
[282/294]	0.021 (0.182)	100.00 (92.46)
[283/294]	0.033 (0.181)	100.00 (92.48)
[284/294]	0.017 (0.181)	100.00 (92.51)
[285/294]	0.030 (0.180)	100.00 (92.53)
[286/294]	0.106 (0.180)	95.00 (92.54)
[287/294]	0.033 (0.180)	100.00 (92.57)
[288/294]	0.013 (0.179)	100.00 (92.60)
[289/294]	0.129 (0.179)	90.00 (92.59)
[290/294]	0.070 (0.178)	95.00 (92.59)
[291/294]	0.034 (0.178)	100.00 (92.62)
[292/294]	0.049 (0.177)	100.00 (92.65)
[293/294]	0.015 (0.177)	100.00 (92.67)
 * Train Acc: 92.670
 * Avg. Data time: 0.005, Avg. Batch time: 0.041, Avg. Forward time: 0.004, Avg. Backward time: 0.018
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 97.183, Time: 5.51
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.296 (6.163)	0.00 (0.00)
[1/294]	0.363 (4.525)	5.00 (2.50)
[2/294]	0.528 (3.512)	30.00 (11.67)
[3/294]	0.365 (2.804)	55.00 (22.50)
[4/294]	0.449 (2.391)	45.00 (27.00)
[5/294]	0.601 (2.074)	80.00 (35.83)
[6/294]	0.719 (1.876)	55.00 (38.57)
[7/294]	0.413 (1.708)	60.00 (41.25)
[8/294]	0.528 (1.614)	50.00 (42.22)
[9/294]	0.612 (1.510)	70.00 (45.00)
[10/294]	0.634 (1.425)	70.00 (47.27)
[11/294]	0.498 (1.332)	100.00 (51.67)
[12/294]	0.513 (1.282)	70.00 (53.08)
[13/294]	0.560 (1.238)	60.00 (53.57)
 * Train Acc: 53.571
 * Avg. Data time: 0.114, Avg. Batch time: 0.192, Avg. Train-batch time: 0.032, Avg. Replay-batch time: 0.040
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 50.714, Time: 9.10
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.471 (3.881)	0.00 (0.00)
[1/294]	0.459 (3.390)	0.00 (0.00)
[2/294]	0.484 (2.908)	0.00 (0.00)
[3/294]	0.587 (2.484)	45.00 (11.25)
[4/294]	0.633 (2.172)	55.00 (20.00)
[5/294]	0.630 (1.944)	65.00 (27.50)
[6/294]	0.628 (1.774)	65.00 (32.86)
[7/294]	0.631 (1.632)	85.00 (39.38)
[8/294]	0.710 (1.521)	70.00 (42.78)
[9/294]	0.810 (1.430)	75.00 (46.00)
[10/294]	0.757 (1.354)	65.00 (47.73)
[11/294]	0.736 (1.281)	85.00 (50.83)
[12/294]	0.714 (1.222)	85.00 (53.46)
[13/294]	0.780 (1.167)	95.00 (56.43)
[14/294]	0.720 (1.120)	80.00 (58.00)
[15/294]	0.810 (1.079)	80.00 (59.38)
[16/294]	0.725 (1.047)	75.00 (60.29)
[17/294]	0.731 (1.011)	95.00 (62.22)
[18/294]	0.682 (0.980)	85.00 (63.42)
[19/294]	0.766 (0.947)	95.00 (65.00)
 * Train Acc: 65.000
 * Avg. Data time: 0.092, Avg. Batch time: 0.159, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.035
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 40.260, Time: 11.48
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.539 (4.470)	0.00 (0.00)
[1/294]	0.560 (4.117)	0.00 (0.00)
[2/294]	0.545 (3.795)	0.00 (0.00)
[3/294]	0.551 (3.441)	0.00 (0.00)
[4/294]	0.609 (3.169)	0.00 (0.00)
[5/294]	0.628 (2.964)	15.00 (2.50)
[6/294]	0.599 (2.796)	35.00 (7.14)
[7/294]	0.661 (2.646)	35.00 (10.62)
[8/294]	0.660 (2.501)	60.00 (16.11)
[9/294]	0.674 (2.386)	50.00 (19.50)
[10/294]	0.650 (2.282)	55.00 (22.73)
[11/294]	0.710 (2.191)	45.00 (24.58)
[12/294]	0.683 (2.110)	55.00 (26.92)
[13/294]	0.759 (2.040)	40.00 (27.86)
[14/294]	0.773 (1.961)	70.00 (30.67)
[15/294]	0.768 (1.890)	70.00 (33.12)
[16/294]	0.757 (1.820)	90.00 (36.47)
[17/294]	0.787 (1.760)	75.00 (38.61)
[18/294]	0.853 (1.701)	85.00 (41.05)
[19/294]	0.891 (1.647)	80.00 (43.00)
[20/294]	0.800 (1.601)	75.00 (44.52)
[21/294]	0.837 (1.556)	80.00 (46.14)
[22/294]	0.818 (1.515)	80.00 (47.61)
[23/294]	0.824 (1.477)	80.00 (48.96)
 * Train Acc: 48.958
 * Avg. Data time: 0.077, Avg. Batch time: 0.145, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.036
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 37.306, Time: 17.92
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.570 (4.153)	0.00 (0.00)
[1/294]	0.576 (4.037)	0.00 (0.00)
[2/294]	0.569 (3.796)	0.00 (0.00)
[3/294]	0.597 (3.574)	0.00 (0.00)
[4/294]	0.609 (3.379)	0.00 (0.00)
[5/294]	0.622 (3.198)	0.00 (0.00)
[6/294]	0.623 (3.042)	0.00 (0.00)
[7/294]	0.638 (2.915)	15.00 (1.88)
[8/294]	0.650 (2.794)	40.00 (6.11)
[9/294]	0.645 (2.683)	40.00 (9.50)
[10/294]	0.660 (2.574)	60.00 (14.09)
[11/294]	0.653 (2.488)	45.00 (16.67)
[12/294]	0.672 (2.404)	65.00 (20.38)
[13/294]	0.698 (2.340)	30.00 (21.07)
[14/294]	0.690 (2.245)	65.00 (24.00)
[15/294]	0.736 (2.165)	55.00 (25.94)
[16/294]	0.723 (2.096)	40.00 (26.76)
[17/294]	0.777 (2.030)	45.00 (27.78)
[18/294]	0.756 (1.960)	85.00 (30.79)
[19/294]	0.859 (1.897)	75.00 (33.00)
[20/294]	0.892 (1.834)	80.00 (35.24)
[21/294]	0.873 (1.777)	95.00 (37.95)
[22/294]	0.929 (1.726)	75.00 (39.57)
[23/294]	0.918 (1.681)	65.00 (40.62)
[24/294]	0.889 (1.640)	65.00 (41.60)
[25/294]	0.946 (1.599)	90.00 (43.46)
 * Train Acc: 43.462
 * Avg. Data time: 0.080, Avg. Batch time: 0.126, Avg. Train-batch time: 0.023, Avg. Replay-batch time: 0.022
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 30.504, Time: 20.76
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.568 (4.578)	0.00 (0.00)
[1/294]	0.583 (4.114)	0.00 (0.00)
[2/294]	0.584 (3.756)	0.00 (0.00)
[3/294]	0.608 (3.471)	0.00 (0.00)
[4/294]	0.606 (3.255)	0.00 (0.00)
[5/294]	0.607 (3.105)	0.00 (0.00)
[6/294]	0.621 (2.992)	0.00 (0.00)
[7/294]	0.620 (2.888)	15.00 (1.88)
[8/294]	0.627 (2.809)	5.00 (2.22)
[9/294]	0.606 (2.733)	15.00 (3.50)
[10/294]	0.627 (2.665)	15.00 (4.55)
[11/294]	0.639 (2.596)	55.00 (8.75)
[12/294]	0.637 (2.535)	65.00 (13.08)
[13/294]	0.647 (2.478)	80.00 (17.86)
[14/294]	0.642 (2.417)	65.00 (21.00)
[15/294]	0.651 (2.354)	75.00 (24.38)
[16/294]	0.666 (2.296)	65.00 (26.76)
[17/294]	0.679 (2.238)	70.00 (29.17)
[18/294]	0.664 (2.174)	70.00 (31.32)
[19/294]	0.695 (2.115)	80.00 (33.75)
[20/294]	0.677 (2.056)	70.00 (35.48)
[21/294]	0.722 (1.999)	70.00 (37.05)
[22/294]	0.776 (1.940)	70.00 (38.48)
[23/294]	0.747 (1.889)	55.00 (39.17)
[24/294]	0.787 (1.845)	60.00 (40.00)
[25/294]	0.772 (1.798)	75.00 (41.35)
[26/294]	0.754 (1.754)	85.00 (42.96)
[27/294]	0.767 (1.714)	70.00 (43.93)
 * Train Acc: 43.929
 * Avg. Data time: 0.064, Avg. Batch time: 0.139, Avg. Train-batch time: 0.030, Avg. Replay-batch time: 0.039
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 29.532, Time: 25.85
=============Stream Learning Run 1=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	1.274 (1.274)	30.00 (30.00)
[1/294]	0.563 (0.919)	75.00 (52.50)
[2/294]	0.594 (0.810)	75.00 (60.00)
[3/294]	0.721 (0.788)	45.00 (56.25)
[4/294]	0.553 (0.741)	65.00 (58.00)
[5/294]	0.623 (0.721)	65.00 (59.17)
[6/294]	0.501 (0.690)	80.00 (62.14)
[7/294]	0.522 (0.669)	80.00 (64.38)
[8/294]	0.481 (0.648)	75.00 (65.56)
[9/294]	0.392 (0.623)	85.00 (67.50)
[10/294]	0.300 (0.593)	90.00 (69.55)
[11/294]	0.627 (0.596)	65.00 (69.17)
[12/294]	0.329 (0.575)	90.00 (70.77)
[13/294]	0.423 (0.565)	80.00 (71.43)
[14/294]	0.284 (0.546)	90.00 (72.67)
[15/294]	0.267 (0.528)	95.00 (74.06)
[16/294]	0.151 (0.506)	100.00 (75.59)
[17/294]	0.448 (0.503)	80.00 (75.83)
[18/294]	0.187 (0.486)	95.00 (76.84)
[19/294]	0.231 (0.474)	90.00 (77.50)
[20/294]	0.300 (0.465)	85.00 (77.86)
[21/294]	0.210 (0.454)	90.00 (78.41)
[22/294]	0.100 (0.438)	100.00 (79.35)
[23/294]	0.129 (0.425)	100.00 (80.21)
[24/294]	0.162 (0.415)	95.00 (80.80)
[25/294]	0.227 (0.408)	90.00 (81.15)
[26/294]	0.319 (0.404)	90.00 (81.48)
[27/294]	0.306 (0.401)	90.00 (81.79)
[28/294]	0.269 (0.396)	85.00 (81.90)
[29/294]	0.115 (0.387)	100.00 (82.50)
[30/294]	0.126 (0.379)	95.00 (82.90)
[31/294]	0.195 (0.373)	95.00 (83.28)
[32/294]	0.199 (0.368)	90.00 (83.48)
[33/294]	0.214 (0.363)	95.00 (83.82)
[34/294]	0.061 (0.354)	100.00 (84.29)
[35/294]	0.187 (0.350)	90.00 (84.44)
[36/294]	0.450 (0.352)	75.00 (84.19)
[37/294]	0.078 (0.345)	100.00 (84.61)
[38/294]	0.088 (0.339)	100.00 (85.00)
[39/294]	0.021 (0.331)	100.00 (85.38)
[40/294]	0.035 (0.323)	100.00 (85.73)
[41/294]	0.024 (0.316)	100.00 (86.07)
[42/294]	0.051 (0.310)	100.00 (86.40)
[43/294]	0.130 (0.306)	95.00 (86.59)
[44/294]	0.245 (0.305)	95.00 (86.78)
[45/294]	0.162 (0.302)	95.00 (86.96)
[46/294]	0.078 (0.297)	95.00 (87.13)
[47/294]	0.092 (0.293)	100.00 (87.40)
[48/294]	0.122 (0.289)	90.00 (87.45)
[49/294]	0.127 (0.286)	90.00 (87.50)
[50/294]	0.162 (0.283)	95.00 (87.65)
[51/294]	0.184 (0.282)	90.00 (87.69)
[52/294]	0.088 (0.278)	100.00 (87.92)
[53/294]	0.063 (0.274)	100.00 (88.15)
[54/294]	0.092 (0.271)	95.00 (88.27)
[55/294]	0.122 (0.268)	95.00 (88.39)
[56/294]	0.048 (0.264)	100.00 (88.60)
[57/294]	0.122 (0.262)	95.00 (88.71)
[58/294]	0.304 (0.262)	90.00 (88.73)
[59/294]	0.064 (0.259)	100.00 (88.92)
[60/294]	0.016 (0.255)	100.00 (89.10)
[61/294]	0.136 (0.253)	95.00 (89.19)
[62/294]	0.107 (0.251)	90.00 (89.21)
[63/294]	0.095 (0.248)	95.00 (89.30)
[64/294]	0.208 (0.248)	90.00 (89.31)
[65/294]	0.081 (0.245)	100.00 (89.47)
[66/294]	0.011 (0.242)	100.00 (89.63)
[67/294]	0.070 (0.239)	100.00 (89.78)
[68/294]	0.064 (0.237)	100.00 (89.93)
[69/294]	0.079 (0.234)	95.00 (90.00)
[70/294]	0.129 (0.233)	95.00 (90.07)
[71/294]	0.039 (0.230)	100.00 (90.21)
[72/294]	0.339 (0.232)	80.00 (90.07)
[73/294]	0.052 (0.229)	100.00 (90.20)
[74/294]	0.056 (0.227)	100.00 (90.33)
[75/294]	0.014 (0.224)	100.00 (90.46)
[76/294]	0.082 (0.222)	100.00 (90.58)
[77/294]	0.257 (0.223)	85.00 (90.51)
[78/294]	0.145 (0.222)	90.00 (90.51)
[79/294]	0.142 (0.221)	95.00 (90.56)
[80/294]	0.062 (0.219)	100.00 (90.68)
[81/294]	0.085 (0.217)	95.00 (90.73)
[82/294]	0.120 (0.216)	95.00 (90.78)
[83/294]	0.059 (0.214)	100.00 (90.89)
[84/294]	0.027 (0.212)	100.00 (91.00)
[85/294]	0.030 (0.210)	100.00 (91.10)
[86/294]	0.022 (0.208)	100.00 (91.21)
[87/294]	0.031 (0.206)	100.00 (91.31)
[88/294]	0.024 (0.204)	100.00 (91.40)
[89/294]	0.067 (0.202)	100.00 (91.50)
[90/294]	0.065 (0.201)	95.00 (91.54)
[91/294]	0.140 (0.200)	90.00 (91.52)
[92/294]	0.015 (0.198)	100.00 (91.61)
[93/294]	0.034 (0.196)	100.00 (91.70)
[94/294]	0.122 (0.195)	95.00 (91.74)
[95/294]	0.059 (0.194)	95.00 (91.77)
[96/294]	0.013 (0.192)	100.00 (91.86)
[97/294]	0.011 (0.190)	100.00 (91.94)
[98/294]	0.037 (0.189)	100.00 (92.02)
[99/294]	0.072 (0.188)	100.00 (92.10)
[100/294]	0.041 (0.186)	100.00 (92.18)
[101/294]	0.077 (0.185)	95.00 (92.21)
[102/294]	0.165 (0.185)	90.00 (92.18)
[103/294]	0.112 (0.184)	95.00 (92.21)
[104/294]	0.122 (0.184)	90.00 (92.19)
[105/294]	0.046 (0.182)	100.00 (92.26)
[106/294]	0.196 (0.182)	90.00 (92.24)
[107/294]	0.014 (0.181)	100.00 (92.31)
[108/294]	0.091 (0.180)	95.00 (92.34)
[109/294]	0.053 (0.179)	100.00 (92.41)
[110/294]	0.078 (0.178)	95.00 (92.43)
[111/294]	0.143 (0.178)	95.00 (92.46)
[112/294]	0.039 (0.176)	100.00 (92.52)
[113/294]	0.050 (0.175)	100.00 (92.59)
[114/294]	0.096 (0.175)	90.00 (92.57)
[115/294]	0.061 (0.174)	100.00 (92.63)
[116/294]	0.198 (0.174)	95.00 (92.65)
[117/294]	0.041 (0.173)	100.00 (92.71)
[118/294]	0.048 (0.172)	95.00 (92.73)
[119/294]	0.104 (0.171)	95.00 (92.75)
[120/294]	0.086 (0.170)	100.00 (92.81)
[121/294]	0.029 (0.169)	100.00 (92.87)
[122/294]	0.052 (0.168)	100.00 (92.93)
[123/294]	0.046 (0.167)	100.00 (92.98)
[124/294]	0.046 (0.166)	100.00 (93.04)
[125/294]	0.037 (0.165)	100.00 (93.10)
[126/294]	0.137 (0.165)	90.00 (93.07)
[127/294]	0.050 (0.164)	100.00 (93.12)
[128/294]	0.040 (0.163)	100.00 (93.18)
[129/294]	0.208 (0.164)	90.00 (93.15)
[130/294]	0.195 (0.164)	95.00 (93.17)
[131/294]	0.188 (0.164)	95.00 (93.18)
[132/294]	0.058 (0.163)	100.00 (93.23)
[133/294]	0.048 (0.162)	100.00 (93.28)
[134/294]	0.004 (0.161)	100.00 (93.33)
[135/294]	0.014 (0.160)	100.00 (93.38)
[136/294]	0.021 (0.159)	100.00 (93.43)
[137/294]	0.100 (0.159)	95.00 (93.44)
[138/294]	0.166 (0.159)	90.00 (93.42)
[139/294]	0.060 (0.158)	95.00 (93.43)
[140/294]	0.055 (0.157)	100.00 (93.48)
[141/294]	0.010 (0.156)	100.00 (93.52)
[142/294]	0.026 (0.155)	100.00 (93.57)
[143/294]	0.117 (0.155)	95.00 (93.58)
[144/294]	0.027 (0.154)	100.00 (93.62)
[145/294]	0.016 (0.153)	100.00 (93.66)
[146/294]	0.036 (0.152)	100.00 (93.71)
[147/294]	0.323 (0.154)	75.00 (93.58)
[148/294]	0.121 (0.153)	90.00 (93.56)
[149/294]	0.021 (0.152)	100.00 (93.60)
[150/294]	0.029 (0.152)	100.00 (93.64)
[151/294]	0.020 (0.151)	100.00 (93.68)
[152/294]	0.114 (0.151)	95.00 (93.69)
[153/294]	0.030 (0.150)	100.00 (93.73)
[154/294]	0.139 (0.150)	90.00 (93.71)
[155/294]	0.055 (0.149)	95.00 (93.72)
[156/294]	0.180 (0.149)	90.00 (93.69)
[157/294]	0.098 (0.149)	95.00 (93.70)
[158/294]	0.171 (0.149)	95.00 (93.71)
[159/294]	0.021 (0.148)	100.00 (93.75)
[160/294]	0.082 (0.148)	95.00 (93.76)
[161/294]	0.320 (0.149)	90.00 (93.73)
[162/294]	0.127 (0.149)	90.00 (93.71)
[163/294]	0.022 (0.148)	100.00 (93.75)
[164/294]	0.052 (0.147)	100.00 (93.79)
[165/294]	0.136 (0.147)	95.00 (93.80)
[166/294]	0.028 (0.147)	100.00 (93.83)
[167/294]	0.053 (0.146)	100.00 (93.87)
[168/294]	0.038 (0.145)	100.00 (93.91)
[169/294]	0.062 (0.145)	95.00 (93.91)
[170/294]	0.050 (0.144)	95.00 (93.92)
[171/294]	0.056 (0.144)	100.00 (93.95)
[172/294]	0.059 (0.143)	95.00 (93.96)
[173/294]	0.005 (0.143)	100.00 (93.99)
[174/294]	0.117 (0.143)	85.00 (93.94)
[175/294]	0.051 (0.142)	100.00 (93.98)
[176/294]	0.047 (0.141)	95.00 (93.98)
[177/294]	0.043 (0.141)	100.00 (94.02)
[178/294]	0.068 (0.140)	95.00 (94.02)
[179/294]	0.136 (0.140)	95.00 (94.03)
[180/294]	0.072 (0.140)	95.00 (94.03)
[181/294]	0.012 (0.139)	100.00 (94.07)
[182/294]	0.138 (0.139)	90.00 (94.04)
[183/294]	0.072 (0.139)	100.00 (94.08)
[184/294]	0.043 (0.138)	100.00 (94.11)
[185/294]	0.016 (0.138)	100.00 (94.14)
[186/294]	0.101 (0.138)	90.00 (94.12)
[187/294]	0.034 (0.137)	100.00 (94.15)
[188/294]	0.008 (0.136)	100.00 (94.18)
[189/294]	0.023 (0.136)	100.00 (94.21)
[190/294]	0.004 (0.135)	100.00 (94.24)
[191/294]	0.036 (0.135)	100.00 (94.27)
[192/294]	0.031 (0.134)	100.00 (94.30)
[193/294]	0.003 (0.133)	100.00 (94.33)
[194/294]	0.059 (0.133)	95.00 (94.33)
[195/294]	0.055 (0.133)	95.00 (94.34)
[196/294]	0.255 (0.133)	95.00 (94.34)
[197/294]	0.030 (0.133)	100.00 (94.37)
[198/294]	0.125 (0.133)	95.00 (94.37)
[199/294]	0.013 (0.132)	100.00 (94.40)
[200/294]	0.044 (0.132)	95.00 (94.40)
[201/294]	0.037 (0.131)	100.00 (94.43)
[202/294]	0.044 (0.131)	100.00 (94.46)
[203/294]	0.012 (0.130)	100.00 (94.49)
[204/294]	0.043 (0.130)	100.00 (94.51)
[205/294]	0.111 (0.130)	90.00 (94.49)
[206/294]	0.011 (0.129)	100.00 (94.52)
[207/294]	0.015 (0.128)	100.00 (94.54)
[208/294]	0.069 (0.128)	95.00 (94.55)
[209/294]	0.116 (0.128)	95.00 (94.55)
[210/294]	0.054 (0.128)	100.00 (94.57)
[211/294]	0.020 (0.127)	100.00 (94.60)
[212/294]	0.076 (0.127)	100.00 (94.62)
[213/294]	0.081 (0.127)	95.00 (94.63)
[214/294]	0.008 (0.126)	100.00 (94.65)
[215/294]	0.022 (0.126)	100.00 (94.68)
[216/294]	0.008 (0.125)	100.00 (94.70)
[217/294]	0.053 (0.125)	100.00 (94.72)
[218/294]	0.006 (0.124)	100.00 (94.75)
[219/294]	0.041 (0.124)	100.00 (94.77)
[220/294]	0.004 (0.123)	100.00 (94.80)
[221/294]	0.001 (0.123)	100.00 (94.82)
[222/294]	0.002 (0.122)	100.00 (94.84)
[223/294]	0.025 (0.122)	100.00 (94.87)
[224/294]	0.006 (0.121)	100.00 (94.89)
[225/294]	0.282 (0.122)	90.00 (94.87)
[226/294]	0.075 (0.122)	95.00 (94.87)
[227/294]	0.012 (0.121)	100.00 (94.89)
[228/294]	0.016 (0.121)	100.00 (94.91)
[229/294]	0.033 (0.121)	100.00 (94.93)
[230/294]	0.006 (0.120)	100.00 (94.96)
[231/294]	0.050 (0.120)	100.00 (94.98)
[232/294]	0.246 (0.120)	95.00 (94.98)
[233/294]	0.169 (0.121)	95.00 (94.98)
[234/294]	0.087 (0.120)	95.00 (94.98)
[235/294]	0.020 (0.120)	100.00 (95.00)
[236/294]	0.024 (0.120)	100.00 (95.02)
[237/294]	0.013 (0.119)	100.00 (95.04)
[238/294]	0.014 (0.119)	100.00 (95.06)
[239/294]	0.039 (0.118)	95.00 (95.06)
[240/294]	0.000 (0.118)	100.00 (95.08)
[241/294]	0.034 (0.118)	100.00 (95.10)
[242/294]	0.019 (0.117)	100.00 (95.12)
[243/294]	0.083 (0.117)	95.00 (95.12)
[244/294]	0.004 (0.117)	100.00 (95.14)
[245/294]	0.005 (0.116)	100.00 (95.16)
[246/294]	0.016 (0.116)	100.00 (95.18)
[247/294]	0.026 (0.115)	100.00 (95.20)
[248/294]	0.030 (0.115)	100.00 (95.22)
[249/294]	0.004 (0.115)	100.00 (95.24)
[250/294]	0.066 (0.114)	95.00 (95.24)
[251/294]	0.173 (0.115)	95.00 (95.24)
[252/294]	0.007 (0.114)	100.00 (95.26)
[253/294]	0.020 (0.114)	100.00 (95.28)
[254/294]	0.043 (0.113)	100.00 (95.29)
[255/294]	0.002 (0.113)	100.00 (95.31)
[256/294]	0.103 (0.113)	95.00 (95.31)
[257/294]	0.021 (0.113)	100.00 (95.33)
[258/294]	0.037 (0.112)	100.00 (95.35)
[259/294]	0.036 (0.112)	100.00 (95.37)
[260/294]	0.002 (0.112)	100.00 (95.38)
[261/294]	0.053 (0.111)	95.00 (95.38)
[262/294]	0.009 (0.111)	100.00 (95.40)
[263/294]	0.018 (0.111)	100.00 (95.42)
[264/294]	0.055 (0.110)	100.00 (95.43)
[265/294]	0.027 (0.110)	100.00 (95.45)
[266/294]	0.005 (0.110)	100.00 (95.47)
[267/294]	0.011 (0.109)	100.00 (95.49)
[268/294]	0.002 (0.109)	100.00 (95.50)
[269/294]	0.011 (0.109)	100.00 (95.52)
[270/294]	0.034 (0.108)	100.00 (95.54)
[271/294]	0.140 (0.108)	95.00 (95.53)
[272/294]	0.052 (0.108)	95.00 (95.53)
[273/294]	0.028 (0.108)	100.00 (95.55)
[274/294]	0.015 (0.108)	100.00 (95.56)
[275/294]	0.006 (0.107)	100.00 (95.58)
[276/294]	0.042 (0.107)	100.00 (95.60)
[277/294]	0.043 (0.107)	95.00 (95.59)
[278/294]	0.083 (0.107)	95.00 (95.59)
[279/294]	0.003 (0.106)	100.00 (95.61)
[280/294]	0.004 (0.106)	100.00 (95.62)
[281/294]	0.008 (0.106)	100.00 (95.64)
[282/294]	0.016 (0.105)	100.00 (95.65)
[283/294]	0.014 (0.105)	100.00 (95.67)
[284/294]	0.005 (0.105)	100.00 (95.68)
[285/294]	0.033 (0.104)	100.00 (95.70)
[286/294]	0.018 (0.104)	100.00 (95.71)
[287/294]	0.016 (0.104)	100.00 (95.73)
[288/294]	0.037 (0.104)	95.00 (95.73)
[289/294]	0.032 (0.103)	100.00 (95.74)
[290/294]	0.037 (0.103)	100.00 (95.76)
[291/294]	0.031 (0.103)	100.00 (95.77)
[292/294]	0.182 (0.103)	95.00 (95.77)
[293/294]	0.010 (0.103)	100.00 (95.78)
 * Train Acc: 95.782
 * Avg. Data time: 0.005, Avg. Batch time: 0.051, Avg. Forward time: 0.003, Avg. Backward time: 0.023
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 94.048, Time: 5.29
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.249 (4.458)	0.00 (0.00)
[1/294]	0.772 (3.464)	5.00 (2.50)
[2/294]	0.167 (2.626)	55.00 (20.00)
[3/294]	0.218 (2.126)	60.00 (30.00)
[4/294]	0.660 (1.811)	75.00 (39.00)
[5/294]	0.210 (1.632)	55.00 (41.67)
[6/294]	0.454 (1.481)	65.00 (45.00)
[7/294]	0.561 (1.402)	50.00 (45.62)
[8/294]	0.332 (1.294)	75.00 (48.89)
[9/294]	0.473 (1.208)	85.00 (52.50)
[10/294]	0.284 (1.122)	95.00 (56.36)
[11/294]	0.317 (1.073)	70.00 (57.50)
[12/294]	0.389 (1.022)	75.00 (58.85)
[13/294]	0.598 (0.974)	80.00 (60.36)
 * Train Acc: 60.357
 * Avg. Data time: 0.130, Avg. Batch time: 0.196, Avg. Train-batch time: 0.025, Avg. Replay-batch time: 0.037
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 50.972, Time: 9.72
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.392 (7.959)	0.00 (0.00)
[1/294]	0.402 (6.837)	0.00 (0.00)
[2/294]	0.387 (5.782)	0.00 (0.00)
[3/294]	0.456 (4.790)	0.00 (0.00)
[4/294]	0.485 (4.105)	35.00 (7.00)
[5/294]	0.596 (3.596)	55.00 (15.00)
[6/294]	0.559 (3.241)	40.00 (18.57)
[7/294]	0.543 (2.939)	80.00 (26.25)
[8/294]	0.584 (2.726)	35.00 (27.22)
[9/294]	0.580 (2.523)	80.00 (32.50)
[10/294]	0.683 (2.361)	55.00 (34.55)
[11/294]	0.589 (2.223)	70.00 (37.50)
[12/294]	0.628 (2.104)	75.00 (40.38)
[13/294]	0.680 (1.998)	70.00 (42.50)
[14/294]	0.673 (1.911)	60.00 (43.67)
[15/294]	0.615 (1.835)	65.00 (45.00)
[16/294]	0.729 (1.766)	75.00 (46.76)
[17/294]	0.663 (1.702)	80.00 (48.61)
[18/294]	0.673 (1.638)	85.00 (50.53)
[19/294]	0.573 (1.587)	75.00 (51.75)
 * Train Acc: 51.750
 * Avg. Data time: 0.086, Avg. Batch time: 0.164, Avg. Train-batch time: 0.031, Avg. Replay-batch time: 0.039
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 40.754, Time: 13.00
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.543 (3.916)	0.00 (0.00)
[1/294]	0.547 (3.567)	0.00 (0.00)
[2/294]	0.545 (3.326)	0.00 (0.00)
[3/294]	0.565 (3.107)	0.00 (0.00)
[4/294]	0.561 (2.912)	0.00 (0.00)
[5/294]	0.573 (2.726)	5.00 (0.83)
[6/294]	0.584 (2.567)	30.00 (5.00)
[7/294]	0.603 (2.413)	65.00 (12.50)
[8/294]	0.630 (2.284)	40.00 (15.56)
[9/294]	0.674 (2.163)	70.00 (21.00)
[10/294]	0.634 (2.056)	60.00 (24.55)
[11/294]	0.726 (1.962)	55.00 (27.08)
[12/294]	0.765 (1.862)	70.00 (30.38)
[13/294]	0.807 (1.779)	70.00 (33.21)
[14/294]	0.742 (1.710)	50.00 (34.33)
[15/294]	0.828 (1.642)	75.00 (36.88)
[16/294]	0.752 (1.577)	85.00 (39.71)
[17/294]	0.877 (1.524)	50.00 (40.28)
[18/294]	0.778 (1.470)	90.00 (42.89)
[19/294]	0.836 (1.425)	80.00 (44.75)
[20/294]	0.822 (1.378)	90.00 (46.90)
[21/294]	0.845 (1.345)	60.00 (47.50)
[22/294]	0.783 (1.309)	75.00 (48.70)
[23/294]	0.823 (1.277)	85.00 (50.21)
 * Train Acc: 50.208
 * Avg. Data time: 0.072, Avg. Batch time: 0.145, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.039
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 30.757, Time: 16.00
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.555 (3.980)	0.00 (0.00)
[1/294]	0.576 (3.823)	0.00 (0.00)
[2/294]	0.557 (3.506)	0.00 (0.00)
[3/294]	0.578 (3.226)	0.00 (0.00)
[4/294]	0.600 (2.985)	5.00 (1.00)
[5/294]	0.607 (2.801)	15.00 (3.33)
[6/294]	0.638 (2.665)	30.00 (7.14)
[7/294]	0.631 (2.537)	40.00 (11.25)
[8/294]	0.627 (2.412)	65.00 (17.22)
[9/294]	0.618 (2.313)	45.00 (20.00)
[10/294]	0.643 (2.220)	65.00 (24.09)
[11/294]	0.663 (2.132)	60.00 (27.08)
[12/294]	0.678 (2.044)	50.00 (28.85)
[13/294]	0.682 (1.960)	75.00 (32.14)
[14/294]	0.680 (1.887)	80.00 (35.33)
[15/294]	0.708 (1.823)	70.00 (37.50)
[16/294]	0.777 (1.756)	85.00 (40.29)
[17/294]	0.786 (1.701)	65.00 (41.67)
[18/294]	0.829 (1.644)	80.00 (43.68)
[19/294]	0.725 (1.586)	85.00 (45.75)
[20/294]	0.720 (1.536)	85.00 (47.62)
[21/294]	0.826 (1.490)	75.00 (48.86)
[22/294]	0.821 (1.444)	85.00 (50.43)
[23/294]	0.813 (1.404)	75.00 (51.46)
[24/294]	0.792 (1.364)	90.00 (53.00)
[25/294]	0.754 (1.329)	95.00 (54.62)
 * Train Acc: 54.615
 * Avg. Data time: 0.064, Avg. Batch time: 0.132, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.036
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 26.450, Time: 18.74
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.607 (4.376)	0.00 (0.00)
[1/294]	0.563 (4.277)	0.00 (0.00)
[2/294]	0.562 (4.068)	0.00 (0.00)
[3/294]	0.615 (3.816)	0.00 (0.00)
[4/294]	0.559 (3.575)	0.00 (0.00)
[5/294]	0.585 (3.362)	0.00 (0.00)
[6/294]	0.566 (3.186)	10.00 (1.43)
[7/294]	0.618 (3.035)	30.00 (5.00)
[8/294]	0.607 (2.900)	45.00 (9.44)
[9/294]	0.640 (2.775)	70.00 (15.50)
[10/294]	0.605 (2.660)	75.00 (20.91)
[11/294]	0.645 (2.555)	70.00 (25.00)
[12/294]	0.640 (2.459)	60.00 (27.69)
[13/294]	0.665 (2.359)	80.00 (31.43)
[14/294]	0.645 (2.271)	65.00 (33.67)
[15/294]	0.612 (2.175)	90.00 (37.19)
[16/294]	0.690 (2.090)	65.00 (38.82)
[17/294]	0.724 (2.006)	85.00 (41.39)
[18/294]	0.696 (1.931)	90.00 (43.95)
[19/294]	0.793 (1.858)	95.00 (46.50)
[20/294]	0.928 (1.794)	80.00 (48.10)
[21/294]	0.705 (1.729)	100.00 (50.45)
[22/294]	0.773 (1.675)	85.00 (51.96)
[23/294]	0.758 (1.623)	95.00 (53.75)
[24/294]	0.865 (1.571)	100.00 (55.60)
[25/294]	0.852 (1.525)	95.00 (57.12)
[26/294]	0.786 (1.478)	95.00 (58.52)
[27/294]	0.696 (1.437)	90.00 (59.64)
 * Train Acc: 59.643
 * Avg. Data time: 0.065, Avg. Batch time: 0.132, Avg. Train-batch time: 0.027, Avg. Replay-batch time: 0.036
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 34.634, Time: 23.00
testing accuracies
           0          1          2          3          4          5
0  97.182540  50.714286  40.259740  37.306009  30.504295  29.532202
1  94.047619  50.972222  40.753968  30.757004  26.450024  34.634243
validation accuracies
Empty DataFrame
Columns: []
Index: [0, 1]

=============Stream Learning Run 0=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	0.905 (0.905)	60.00 (60.00)
[1/294]	1.090 (0.998)	45.00 (52.50)
[2/294]	0.582 (0.859)	65.00 (56.67)
[3/294]	0.686 (0.816)	45.00 (53.75)
[4/294]	0.638 (0.780)	55.00 (54.00)
[5/294]	0.560 (0.743)	65.00 (55.83)
[6/294]	0.480 (0.706)	85.00 (60.00)
[7/294]	0.458 (0.675)	90.00 (63.75)
[8/294]	0.384 (0.643)	90.00 (66.67)
[9/294]	0.440 (0.622)	80.00 (68.00)
[10/294]	0.340 (0.597)	80.00 (69.09)
[11/294]	0.264 (0.569)	90.00 (70.83)
[12/294]	0.195 (0.540)	100.00 (73.08)
[13/294]	0.122 (0.510)	95.00 (74.64)
[14/294]	0.324 (0.498)	85.00 (75.33)
[15/294]	0.318 (0.487)	90.00 (76.25)
[16/294]	0.043 (0.461)	100.00 (77.65)
[17/294]	0.328 (0.453)	85.00 (78.06)
[18/294]	0.528 (0.457)	85.00 (78.42)
[19/294]	0.435 (0.456)	90.00 (79.00)
[20/294]	0.095 (0.439)	95.00 (79.76)
[21/294]	0.532 (0.443)	85.00 (80.00)
[22/294]	0.152 (0.430)	100.00 (80.87)
[23/294]	0.410 (0.430)	75.00 (80.62)
[24/294]	0.238 (0.422)	100.00 (81.40)
[25/294]	0.170 (0.412)	100.00 (82.12)
[26/294]	0.306 (0.408)	90.00 (82.41)
[27/294]	0.211 (0.401)	85.00 (82.50)
[28/294]	0.185 (0.394)	95.00 (82.93)
[29/294]	0.236 (0.389)	95.00 (83.33)
[30/294]	0.149 (0.381)	95.00 (83.71)
[31/294]	0.351 (0.380)	90.00 (83.91)
[32/294]	0.126 (0.372)	95.00 (84.24)
[33/294]	0.350 (0.372)	85.00 (84.26)
[34/294]	0.053 (0.362)	100.00 (84.71)
[35/294]	0.039 (0.353)	100.00 (85.14)
[36/294]	0.222 (0.350)	85.00 (85.14)
[37/294]	0.043 (0.342)	100.00 (85.53)
[38/294]	0.172 (0.337)	90.00 (85.64)
[39/294]	0.140 (0.333)	90.00 (85.75)
[40/294]	0.311 (0.332)	85.00 (85.73)
[41/294]	0.012 (0.324)	100.00 (86.07)
[42/294]	0.034 (0.318)	100.00 (86.40)
[43/294]	0.185 (0.315)	90.00 (86.48)
[44/294]	0.113 (0.310)	90.00 (86.56)
[45/294]	0.222 (0.308)	95.00 (86.74)
[46/294]	0.089 (0.304)	95.00 (86.91)
[47/294]	0.163 (0.301)	95.00 (87.08)
[48/294]	0.110 (0.297)	95.00 (87.24)
[49/294]	0.172 (0.294)	100.00 (87.50)
[50/294]	0.081 (0.290)	100.00 (87.75)
[51/294]	0.155 (0.287)	95.00 (87.88)
[52/294]	0.118 (0.284)	95.00 (88.02)
[53/294]	0.044 (0.280)	100.00 (88.24)
[54/294]	0.053 (0.276)	100.00 (88.45)
[55/294]	0.136 (0.273)	95.00 (88.57)
[56/294]	0.127 (0.271)	95.00 (88.68)
[57/294]	0.236 (0.270)	90.00 (88.71)
[58/294]	0.022 (0.266)	100.00 (88.90)
[59/294]	0.063 (0.262)	95.00 (89.00)
[60/294]	0.089 (0.260)	95.00 (89.10)
[61/294]	0.020 (0.256)	100.00 (89.27)
[62/294]	0.405 (0.258)	90.00 (89.29)
[63/294]	0.058 (0.255)	100.00 (89.45)
[64/294]	0.048 (0.252)	100.00 (89.62)
[65/294]	0.481 (0.255)	80.00 (89.47)
[66/294]	0.049 (0.252)	100.00 (89.63)
[67/294]	0.040 (0.249)	100.00 (89.78)
[68/294]	0.065 (0.246)	100.00 (89.93)
[69/294]	0.024 (0.243)	100.00 (90.07)
[70/294]	0.018 (0.240)	100.00 (90.21)
[71/294]	0.157 (0.239)	90.00 (90.21)
[72/294]	0.066 (0.237)	100.00 (90.34)
[73/294]	0.090 (0.235)	95.00 (90.41)
[74/294]	0.066 (0.232)	100.00 (90.53)
[75/294]	0.011 (0.229)	100.00 (90.66)
[76/294]	0.043 (0.227)	100.00 (90.78)
[77/294]	0.004 (0.224)	100.00 (90.90)
[78/294]	0.020 (0.222)	100.00 (91.01)
[79/294]	0.039 (0.219)	100.00 (91.12)
[80/294]	0.056 (0.217)	100.00 (91.23)
[81/294]	0.066 (0.215)	95.00 (91.28)
[82/294]	0.155 (0.215)	95.00 (91.33)
[83/294]	0.052 (0.213)	100.00 (91.43)
[84/294]	0.065 (0.211)	95.00 (91.47)
[85/294]	0.086 (0.210)	95.00 (91.51)
[86/294]	0.203 (0.209)	90.00 (91.49)
[87/294]	0.135 (0.209)	95.00 (91.53)
[88/294]	0.057 (0.207)	100.00 (91.63)
[89/294]	0.016 (0.205)	100.00 (91.72)
[90/294]	0.128 (0.204)	90.00 (91.70)
[91/294]	0.006 (0.202)	100.00 (91.79)
[92/294]	0.554 (0.206)	80.00 (91.67)
[93/294]	0.046 (0.204)	100.00 (91.76)
[94/294]	0.195 (0.204)	95.00 (91.79)
[95/294]	0.114 (0.203)	90.00 (91.77)
[96/294]	0.231 (0.203)	95.00 (91.80)
[97/294]	0.134 (0.202)	95.00 (91.84)
[98/294]	0.017 (0.201)	100.00 (91.92)
[99/294]	0.043 (0.199)	100.00 (92.00)
[100/294]	0.095 (0.198)	95.00 (92.03)
[101/294]	0.165 (0.198)	90.00 (92.01)
[102/294]	0.163 (0.197)	95.00 (92.04)
[103/294]	0.176 (0.197)	95.00 (92.07)
[104/294]	0.078 (0.196)	100.00 (92.14)
[105/294]	0.181 (0.196)	95.00 (92.17)
[106/294]	0.039 (0.194)	100.00 (92.24)
[107/294]	0.103 (0.194)	95.00 (92.27)
[108/294]	0.080 (0.192)	95.00 (92.29)
[109/294]	0.083 (0.191)	95.00 (92.32)
[110/294]	0.150 (0.191)	95.00 (92.34)
[111/294]	0.020 (0.190)	100.00 (92.41)
[112/294]	0.375 (0.191)	95.00 (92.43)
[113/294]	0.082 (0.190)	95.00 (92.46)
[114/294]	0.056 (0.189)	95.00 (92.48)
[115/294]	0.089 (0.188)	95.00 (92.50)
[116/294]	0.044 (0.187)	100.00 (92.56)
[117/294]	0.083 (0.186)	95.00 (92.58)
[118/294]	0.116 (0.186)	95.00 (92.61)
[119/294]	0.028 (0.184)	100.00 (92.67)
[120/294]	0.055 (0.183)	100.00 (92.73)
[121/294]	0.021 (0.182)	100.00 (92.79)
[122/294]	0.109 (0.181)	95.00 (92.80)
[123/294]	0.032 (0.180)	100.00 (92.86)
[124/294]	0.031 (0.179)	100.00 (92.92)
[125/294]	0.195 (0.179)	95.00 (92.94)
[126/294]	0.698 (0.183)	85.00 (92.87)
[127/294]	0.097 (0.182)	95.00 (92.89)
[128/294]	0.058 (0.181)	100.00 (92.95)
[129/294]	0.109 (0.181)	95.00 (92.96)
[130/294]	0.023 (0.180)	100.00 (93.02)
[131/294]	0.148 (0.179)	95.00 (93.03)
[132/294]	0.162 (0.179)	95.00 (93.05)
[133/294]	0.188 (0.179)	90.00 (93.02)
[134/294]	0.117 (0.179)	95.00 (93.04)
[135/294]	0.110 (0.178)	95.00 (93.05)
[136/294]	0.041 (0.177)	100.00 (93.10)
[137/294]	0.076 (0.177)	100.00 (93.15)
[138/294]	0.168 (0.177)	90.00 (93.13)
[139/294]	0.184 (0.177)	90.00 (93.11)
[140/294]	0.226 (0.177)	95.00 (93.12)
[141/294]	0.028 (0.176)	100.00 (93.17)
[142/294]	0.051 (0.175)	100.00 (93.22)
[143/294]	0.109 (0.175)	95.00 (93.23)
[144/294]	0.038 (0.174)	100.00 (93.28)
[145/294]	0.160 (0.174)	90.00 (93.25)
[146/294]	0.030 (0.173)	100.00 (93.30)
[147/294]	0.040 (0.172)	100.00 (93.34)
[148/294]	0.045 (0.171)	100.00 (93.39)
[149/294]	0.319 (0.172)	90.00 (93.37)
[150/294]	0.140 (0.172)	90.00 (93.34)
[151/294]	0.356 (0.173)	90.00 (93.32)
[152/294]	0.190 (0.173)	95.00 (93.33)
[153/294]	0.069 (0.172)	95.00 (93.34)
[154/294]	0.062 (0.172)	100.00 (93.39)
[155/294]	0.010 (0.171)	100.00 (93.43)
[156/294]	0.145 (0.170)	90.00 (93.41)
[157/294]	0.008 (0.169)	100.00 (93.45)
[158/294]	0.090 (0.169)	100.00 (93.49)
[159/294]	0.034 (0.168)	100.00 (93.53)
[160/294]	0.114 (0.168)	95.00 (93.54)
[161/294]	0.088 (0.167)	95.00 (93.55)
[162/294]	0.027 (0.166)	100.00 (93.59)
[163/294]	0.023 (0.165)	100.00 (93.63)
[164/294]	0.024 (0.165)	100.00 (93.67)
[165/294]	0.066 (0.164)	100.00 (93.70)
[166/294]	0.004 (0.163)	100.00 (93.74)
[167/294]	0.009 (0.162)	100.00 (93.78)
[168/294]	0.131 (0.162)	95.00 (93.79)
[169/294]	0.030 (0.161)	100.00 (93.82)
[170/294]	0.044 (0.160)	100.00 (93.86)
[171/294]	0.138 (0.160)	90.00 (93.84)
[172/294]	0.105 (0.160)	95.00 (93.84)
[173/294]	0.033 (0.159)	100.00 (93.88)
[174/294]	0.119 (0.159)	95.00 (93.89)
[175/294]	0.080 (0.159)	95.00 (93.89)
[176/294]	0.126 (0.158)	95.00 (93.90)
[177/294]	0.144 (0.158)	90.00 (93.88)
[178/294]	0.056 (0.158)	95.00 (93.88)
[179/294]	0.256 (0.158)	90.00 (93.86)
[180/294]	0.005 (0.157)	100.00 (93.90)
[181/294]	0.031 (0.157)	100.00 (93.93)
[182/294]	0.126 (0.157)	95.00 (93.93)
[183/294]	0.030 (0.156)	100.00 (93.97)
[184/294]	0.007 (0.155)	100.00 (94.00)
[185/294]	0.070 (0.155)	95.00 (94.01)
[186/294]	0.018 (0.154)	100.00 (94.04)
[187/294]	0.020 (0.153)	100.00 (94.07)
[188/294]	0.085 (0.153)	95.00 (94.07)
[189/294]	0.145 (0.153)	95.00 (94.08)
[190/294]	0.025 (0.152)	100.00 (94.11)
[191/294]	0.006 (0.151)	100.00 (94.14)
[192/294]	0.002 (0.151)	100.00 (94.17)
[193/294]	0.007 (0.150)	100.00 (94.20)
[194/294]	0.013 (0.149)	100.00 (94.23)
[195/294]	0.121 (0.149)	95.00 (94.23)
[196/294]	0.003 (0.148)	100.00 (94.26)
[197/294]	0.146 (0.148)	95.00 (94.27)
[198/294]	0.003 (0.148)	100.00 (94.30)
[199/294]	0.061 (0.147)	95.00 (94.30)
[200/294]	0.013 (0.146)	100.00 (94.33)
[201/294]	0.221 (0.147)	95.00 (94.33)
[202/294]	0.265 (0.147)	90.00 (94.31)
[203/294]	0.029 (0.147)	100.00 (94.34)
[204/294]	0.012 (0.146)	100.00 (94.37)
[205/294]	0.013 (0.146)	100.00 (94.39)
[206/294]	0.130 (0.145)	95.00 (94.40)
[207/294]	0.031 (0.145)	100.00 (94.42)
[208/294]	0.158 (0.145)	90.00 (94.40)
[209/294]	0.211 (0.145)	90.00 (94.38)
[210/294]	0.153 (0.145)	95.00 (94.38)
[211/294]	0.013 (0.145)	100.00 (94.41)
[212/294]	0.022 (0.144)	100.00 (94.44)
[213/294]	0.026 (0.144)	100.00 (94.46)
[214/294]	0.059 (0.143)	100.00 (94.49)
[215/294]	0.062 (0.143)	95.00 (94.49)
[216/294]	0.151 (0.143)	95.00 (94.49)
[217/294]	0.031 (0.142)	100.00 (94.52)
[218/294]	0.060 (0.142)	100.00 (94.54)
[219/294]	0.038 (0.141)	100.00 (94.57)
[220/294]	0.049 (0.141)	100.00 (94.59)
[221/294]	0.063 (0.141)	100.00 (94.62)
[222/294]	0.095 (0.141)	95.00 (94.62)
[223/294]	0.100 (0.140)	95.00 (94.62)
[224/294]	0.021 (0.140)	100.00 (94.64)
[225/294]	0.061 (0.139)	95.00 (94.65)
[226/294]	0.017 (0.139)	100.00 (94.67)
[227/294]	0.041 (0.138)	100.00 (94.69)
[228/294]	0.006 (0.138)	100.00 (94.72)
[229/294]	0.069 (0.138)	95.00 (94.72)
[230/294]	0.043 (0.137)	100.00 (94.74)
[231/294]	0.011 (0.137)	100.00 (94.76)
[232/294]	0.153 (0.137)	95.00 (94.76)
[233/294]	0.040 (0.136)	100.00 (94.79)
[234/294]	0.035 (0.136)	100.00 (94.81)
[235/294]	0.007 (0.135)	100.00 (94.83)
[236/294]	0.004 (0.135)	100.00 (94.85)
[237/294]	0.281 (0.135)	90.00 (94.83)
[238/294]	0.088 (0.135)	95.00 (94.83)
[239/294]	0.011 (0.135)	100.00 (94.85)
[240/294]	0.009 (0.134)	100.00 (94.88)
[241/294]	0.026 (0.134)	100.00 (94.90)
[242/294]	0.214 (0.134)	90.00 (94.88)
[243/294]	0.008 (0.134)	100.00 (94.90)
[244/294]	0.761 (0.136)	85.00 (94.86)
[245/294]	0.008 (0.136)	100.00 (94.88)
[246/294]	0.013 (0.135)	100.00 (94.90)
[247/294]	0.009 (0.135)	100.00 (94.92)
[248/294]	0.091 (0.134)	95.00 (94.92)
[249/294]	0.080 (0.134)	95.00 (94.92)
[250/294]	0.104 (0.134)	95.00 (94.92)
[251/294]	0.102 (0.134)	95.00 (94.92)
[252/294]	0.309 (0.135)	80.00 (94.86)
[253/294]	0.233 (0.135)	80.00 (94.80)
[254/294]	0.084 (0.135)	95.00 (94.80)
[255/294]	0.058 (0.134)	100.00 (94.82)
[256/294]	0.075 (0.134)	100.00 (94.84)
[257/294]	0.133 (0.134)	90.00 (94.83)
[258/294]	0.072 (0.134)	100.00 (94.85)
[259/294]	0.021 (0.134)	100.00 (94.87)
[260/294]	0.073 (0.133)	100.00 (94.89)
[261/294]	0.094 (0.133)	95.00 (94.89)
[262/294]	0.100 (0.133)	95.00 (94.89)
[263/294]	0.054 (0.133)	100.00 (94.91)
[264/294]	0.072 (0.133)	100.00 (94.92)
[265/294]	0.066 (0.132)	95.00 (94.92)
[266/294]	0.008 (0.132)	100.00 (94.94)
[267/294]	0.034 (0.131)	100.00 (94.96)
[268/294]	0.027 (0.131)	100.00 (94.98)
[269/294]	0.023 (0.131)	100.00 (95.00)
[270/294]	0.222 (0.131)	95.00 (95.00)
[271/294]	0.276 (0.132)	95.00 (95.00)
[272/294]	0.017 (0.131)	100.00 (95.02)
[273/294]	0.014 (0.131)	100.00 (95.04)
[274/294]	0.015 (0.130)	100.00 (95.05)
[275/294]	0.009 (0.130)	100.00 (95.07)
[276/294]	0.017 (0.129)	100.00 (95.09)
[277/294]	0.008 (0.129)	100.00 (95.11)
[278/294]	0.015 (0.129)	100.00 (95.13)
[279/294]	0.076 (0.128)	95.00 (95.12)
[280/294]	0.123 (0.128)	95.00 (95.12)
[281/294]	0.005 (0.128)	100.00 (95.14)
[282/294]	0.008 (0.128)	100.00 (95.16)
[283/294]	0.010 (0.127)	100.00 (95.18)
[284/294]	0.013 (0.127)	100.00 (95.19)
[285/294]	0.039 (0.126)	100.00 (95.21)
[286/294]	0.064 (0.126)	100.00 (95.23)
[287/294]	0.007 (0.126)	100.00 (95.24)
[288/294]	0.014 (0.125)	100.00 (95.26)
[289/294]	0.047 (0.125)	100.00 (95.28)
[290/294]	0.232 (0.125)	90.00 (95.26)
[291/294]	0.034 (0.125)	100.00 (95.27)
[292/294]	0.012 (0.125)	100.00 (95.29)
[293/294]	0.016 (0.124)	100.00 (95.31)
 * Train Acc: 95.306
 * Avg. Data time: 0.005, Avg. Batch time: 0.053, Avg. Forward time: 0.004, Avg. Backward time: 0.023
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 98.452, Time: 4.93
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.413 (6.842)	0.00 (0.00)
[1/294]	0.534 (4.088)	25.00 (12.50)
[2/294]	0.604 (3.018)	50.00 (25.00)
[3/294]	0.803 (2.463)	60.00 (33.75)
[4/294]	0.836 (2.111)	50.00 (37.00)
[5/294]	0.791 (1.899)	45.00 (38.33)
[6/294]	0.731 (1.742)	35.00 (37.86)
[7/294]	0.678 (1.619)	50.00 (39.38)
[8/294]	0.674 (1.542)	30.00 (38.33)
[9/294]	0.616 (1.474)	60.00 (40.50)
[10/294]	0.640 (1.417)	45.00 (40.91)
[11/294]	0.638 (1.362)	80.00 (44.17)
[12/294]	0.676 (1.324)	50.00 (44.62)
[13/294]	0.598 (1.288)	40.00 (44.29)
 * Train Acc: 44.286
 * Avg. Data time: 0.140, Avg. Batch time: 0.196, Avg. Train-batch time: 0.024, Avg. Replay-batch time: 0.027
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 27.540, Time: 9.20
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.576 (2.900)	0.00 (0.00)
[1/294]	0.597 (2.510)	0.00 (0.00)
[2/294]	0.636 (2.273)	0.00 (0.00)
[3/294]	0.673 (2.079)	45.00 (11.25)
[4/294]	0.801 (1.909)	50.00 (19.00)
[5/294]	1.017 (1.747)	50.00 (24.17)
[6/294]	0.863 (1.604)	50.00 (27.86)
[7/294]	0.955 (1.487)	65.00 (32.50)
[8/294]	0.965 (1.422)	35.00 (32.78)
[9/294]	0.760 (1.380)	50.00 (34.50)
[10/294]	0.675 (1.376)	45.00 (35.45)
[11/294]	0.730 (1.364)	45.00 (36.25)
[12/294]	0.844 (1.327)	55.00 (37.69)
[13/294]	0.924 (1.304)	35.00 (37.50)
[14/294]	0.845 (1.284)	35.00 (37.33)
[15/294]	0.864 (1.263)	40.00 (37.50)
[16/294]	0.727 (1.241)	65.00 (39.12)
[17/294]	0.785 (1.219)	85.00 (41.67)
[18/294]	0.808 (1.192)	80.00 (43.68)
[19/294]	0.885 (1.170)	60.00 (44.50)
 * Train Acc: 44.500
 * Avg. Data time: 0.087, Avg. Batch time: 0.162, Avg. Train-batch time: 0.029, Avg. Replay-batch time: 0.039
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 20.395, Time: 12.67
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.576 (3.676)	0.00 (0.00)
[1/294]	0.638 (3.035)	0.00 (0.00)
[2/294]	0.669 (2.731)	0.00 (0.00)
[3/294]	0.673 (2.565)	0.00 (0.00)
[4/294]	0.677 (2.455)	5.00 (1.00)
[5/294]	0.675 (2.375)	10.00 (2.50)
[6/294]	0.682 (2.307)	45.00 (8.57)
[7/294]	0.690 (2.244)	65.00 (15.62)
[8/294]	0.700 (2.190)	35.00 (17.78)
[9/294]	0.731 (2.119)	50.00 (21.00)
[10/294]	0.838 (2.035)	50.00 (23.64)
[11/294]	0.973 (1.943)	55.00 (26.25)
[12/294]	0.946 (1.856)	45.00 (27.69)
[13/294]	1.175 (1.788)	40.00 (28.57)
[14/294]	1.253 (1.725)	35.00 (29.00)
[15/294]	1.054 (1.666)	45.00 (30.00)
[16/294]	0.966 (1.618)	35.00 (30.29)
[17/294]	0.815 (1.576)	45.00 (31.11)
[18/294]	0.834 (1.547)	35.00 (31.32)
[19/294]	0.808 (1.514)	55.00 (32.50)
[20/294]	0.882 (1.484)	65.00 (34.05)
[21/294]	0.933 (1.454)	50.00 (34.77)
[22/294]	1.003 (1.423)	65.00 (36.09)
[23/294]	0.908 (1.399)	45.00 (36.46)
 * Train Acc: 36.458
 * Avg. Data time: 0.081, Avg. Batch time: 0.146, Avg. Train-batch time: 0.025, Avg. Replay-batch time: 0.036
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 16.047, Time: 17.49
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.592 (4.020)	0.00 (0.00)
[1/294]	0.635 (3.205)	0.00 (0.00)
[2/294]	0.654 (2.862)	0.00 (0.00)
[3/294]	0.671 (2.691)	0.00 (0.00)
[4/294]	0.675 (2.588)	0.00 (0.00)
[5/294]	0.675 (2.520)	0.00 (0.00)
[6/294]	0.673 (2.467)	0.00 (0.00)
[7/294]	0.676 (2.426)	0.00 (0.00)
[8/294]	0.677 (2.391)	10.00 (1.11)
[9/294]	0.676 (2.357)	30.00 (4.00)
[10/294]	0.673 (2.322)	50.00 (8.18)
[11/294]	0.672 (2.286)	35.00 (10.42)
[12/294]	0.683 (2.247)	55.00 (13.85)
[13/294]	0.697 (2.192)	75.00 (18.21)
[14/294]	0.775 (2.123)	35.00 (19.33)
[15/294]	0.874 (2.046)	40.00 (20.62)
[16/294]	0.993 (1.972)	35.00 (21.47)
[17/294]	0.978 (1.901)	60.00 (23.61)
[18/294]	1.032 (1.843)	35.00 (24.21)
[19/294]	1.094 (1.792)	45.00 (25.25)
[20/294]	0.976 (1.742)	40.00 (25.95)
[21/294]	1.041 (1.703)	50.00 (27.05)
[22/294]	0.851 (1.661)	65.00 (28.70)
[23/294]	0.827 (1.627)	45.00 (29.38)
[24/294]	0.753 (1.596)	55.00 (30.40)
[25/294]	0.761 (1.567)	65.00 (31.73)
 * Train Acc: 31.731
 * Avg. Data time: 0.074, Avg. Batch time: 0.119, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.021
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 12.647, Time: 21.97
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.591 (3.602)	0.00 (0.00)
[1/294]	0.628 (3.300)	0.00 (0.00)
[2/294]	0.650 (3.066)	0.00 (0.00)
[3/294]	0.656 (2.919)	0.00 (0.00)
[4/294]	0.650 (2.821)	0.00 (0.00)
[5/294]	0.672 (2.754)	0.00 (0.00)
[6/294]	0.663 (2.701)	0.00 (0.00)
[7/294]	0.667 (2.656)	0.00 (0.00)
[8/294]	0.666 (2.618)	0.00 (0.00)
[9/294]	0.665 (2.581)	0.00 (0.00)
[10/294]	0.670 (2.544)	25.00 (2.27)
[11/294]	0.672 (2.500)	55.00 (6.67)
[12/294]	0.700 (2.443)	45.00 (9.62)
[13/294]	0.767 (2.358)	65.00 (13.57)
[14/294]	1.050 (2.283)	35.00 (15.00)
[15/294]	1.152 (2.191)	60.00 (17.81)
[16/294]	1.087 (2.103)	65.00 (20.59)
[17/294]	1.135 (2.026)	65.00 (23.06)
[18/294]	1.085 (1.957)	80.00 (26.05)
[19/294]	1.055 (1.895)	55.00 (27.50)
[20/294]	0.928 (1.836)	65.00 (29.29)
[21/294]	0.998 (1.781)	65.00 (30.91)
[22/294]	1.004 (1.737)	60.00 (32.17)
[23/294]	0.929 (1.693)	80.00 (34.17)
[24/294]	0.740 (1.659)	60.00 (35.20)
[25/294]	0.877 (1.624)	65.00 (36.35)
[26/294]	0.795 (1.607)	35.00 (36.30)
[27/294]	0.907 (1.578)	75.00 (37.68)
 * Train Acc: 37.679
 * Avg. Data time: 0.063, Avg. Batch time: 0.138, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.040
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 11.622, Time: 25.00
=============Stream Learning Run 1=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	1.274 (1.274)	30.00 (30.00)
[1/294]	2.215 (1.745)	40.00 (35.00)
[2/294]	0.649 (1.379)	45.00 (38.33)
[3/294]	0.596 (1.184)	65.00 (45.00)
[4/294]	0.551 (1.057)	95.00 (55.00)
[5/294]	0.528 (0.969)	95.00 (61.67)
[6/294]	0.501 (0.902)	100.00 (67.14)
[7/294]	0.557 (0.859)	95.00 (70.62)
[8/294]	0.510 (0.820)	80.00 (71.67)
[9/294]	0.416 (0.780)	95.00 (74.00)
[10/294]	0.405 (0.746)	90.00 (75.45)
[11/294]	0.413 (0.718)	80.00 (75.83)
[12/294]	0.381 (0.692)	95.00 (77.31)
[13/294]	0.419 (0.672)	75.00 (77.14)
[14/294]	0.256 (0.645)	90.00 (78.00)
[15/294]	0.230 (0.619)	90.00 (78.75)
[16/294]	0.092 (0.588)	100.00 (80.00)
[17/294]	0.225 (0.568)	90.00 (80.56)
[18/294]	0.122 (0.544)	95.00 (81.32)
[19/294]	0.164 (0.525)	90.00 (81.75)
[20/294]	0.063 (0.503)	100.00 (82.62)
[21/294]	0.086 (0.484)	100.00 (83.41)
[22/294]	0.151 (0.470)	90.00 (83.70)
[23/294]	0.022 (0.451)	100.00 (84.38)
[24/294]	0.162 (0.439)	90.00 (84.60)
[25/294]	0.269 (0.433)	90.00 (84.81)
[26/294]	0.299 (0.428)	90.00 (85.00)
[27/294]	0.418 (0.428)	90.00 (85.18)
[28/294]	0.029 (0.414)	100.00 (85.69)
[29/294]	0.109 (0.404)	90.00 (85.83)
[30/294]	0.144 (0.395)	95.00 (86.13)
[31/294]	0.180 (0.389)	90.00 (86.25)
[32/294]	0.092 (0.380)	95.00 (86.52)
[33/294]	0.028 (0.369)	100.00 (86.91)
[34/294]	0.121 (0.362)	95.00 (87.14)
[35/294]	0.237 (0.359)	90.00 (87.22)
[36/294]	0.278 (0.357)	85.00 (87.16)
[37/294]	0.061 (0.349)	100.00 (87.50)
[38/294]	0.064 (0.341)	100.00 (87.82)
[39/294]	0.046 (0.334)	100.00 (88.12)
[40/294]	0.037 (0.327)	100.00 (88.41)
[41/294]	0.050 (0.320)	100.00 (88.69)
[42/294]	0.135 (0.316)	100.00 (88.95)
[43/294]	0.058 (0.310)	100.00 (89.20)
[44/294]	0.100 (0.305)	95.00 (89.33)
[45/294]	0.062 (0.300)	95.00 (89.46)
[46/294]	0.013 (0.294)	100.00 (89.68)
[47/294]	0.069 (0.289)	95.00 (89.79)
[48/294]	0.050 (0.284)	100.00 (90.00)
[49/294]	0.058 (0.280)	100.00 (90.20)
[50/294]	0.064 (0.276)	95.00 (90.29)
[51/294]	0.112 (0.273)	95.00 (90.38)
[52/294]	0.016 (0.268)	100.00 (90.57)
[53/294]	0.055 (0.264)	100.00 (90.74)
[54/294]	0.019 (0.259)	100.00 (90.91)
[55/294]	0.032 (0.255)	100.00 (91.07)
[56/294]	0.003 (0.251)	100.00 (91.23)
[57/294]	0.021 (0.247)	100.00 (91.38)
[58/294]	0.386 (0.249)	95.00 (91.44)
[59/294]	0.021 (0.245)	100.00 (91.58)
[60/294]	0.005 (0.241)	100.00 (91.72)
[61/294]	0.061 (0.239)	100.00 (91.85)
[62/294]	0.027 (0.235)	100.00 (91.98)
[63/294]	0.015 (0.232)	100.00 (92.11)
[64/294]	0.342 (0.233)	90.00 (92.08)
[65/294]	0.005 (0.230)	100.00 (92.20)
[66/294]	0.010 (0.227)	100.00 (92.31)
[67/294]	0.030 (0.224)	100.00 (92.43)
[68/294]	0.016 (0.221)	100.00 (92.54)
[69/294]	0.011 (0.218)	100.00 (92.64)
[70/294]	0.286 (0.219)	90.00 (92.61)
[71/294]	0.001 (0.216)	100.00 (92.71)
[72/294]	0.248 (0.216)	85.00 (92.60)
[73/294]	0.016 (0.213)	100.00 (92.70)
[74/294]	0.005 (0.211)	100.00 (92.80)
[75/294]	0.002 (0.208)	100.00 (92.89)
[76/294]	0.050 (0.206)	100.00 (92.99)
[77/294]	0.339 (0.208)	90.00 (92.95)
[78/294]	0.123 (0.207)	90.00 (92.91)
[79/294]	0.152 (0.206)	95.00 (92.94)
[80/294]	0.033 (0.204)	100.00 (93.02)
[81/294]	0.026 (0.202)	100.00 (93.11)
[82/294]	0.174 (0.201)	95.00 (93.13)
[83/294]	0.130 (0.200)	95.00 (93.15)
[84/294]	0.042 (0.199)	100.00 (93.24)
[85/294]	0.070 (0.197)	100.00 (93.31)
[86/294]	0.041 (0.195)	100.00 (93.39)
[87/294]	0.068 (0.194)	95.00 (93.41)
[88/294]	0.015 (0.192)	100.00 (93.48)
[89/294]	0.075 (0.190)	100.00 (93.56)
[90/294]	0.020 (0.189)	100.00 (93.63)
[91/294]	0.136 (0.188)	95.00 (93.64)
[92/294]	0.007 (0.186)	100.00 (93.71)
[93/294]	0.010 (0.184)	100.00 (93.78)
[94/294]	0.119 (0.183)	95.00 (93.79)
[95/294]	0.065 (0.182)	95.00 (93.80)
[96/294]	0.004 (0.180)	100.00 (93.87)
[97/294]	0.028 (0.179)	100.00 (93.93)
[98/294]	0.108 (0.178)	95.00 (93.94)
[99/294]	0.051 (0.177)	100.00 (94.00)
[100/294]	0.041 (0.176)	100.00 (94.06)
[101/294]	0.043 (0.174)	95.00 (94.07)
[102/294]	0.089 (0.173)	90.00 (94.03)
[103/294]	0.050 (0.172)	95.00 (94.04)
[104/294]	0.083 (0.171)	95.00 (94.05)
[105/294]	0.036 (0.170)	100.00 (94.10)
[106/294]	0.122 (0.170)	95.00 (94.11)
[107/294]	0.034 (0.168)	100.00 (94.17)
[108/294]	0.003 (0.167)	100.00 (94.22)
[109/294]	0.001 (0.165)	100.00 (94.27)
[110/294]	0.039 (0.164)	95.00 (94.28)
[111/294]	0.200 (0.165)	95.00 (94.29)
[112/294]	0.002 (0.163)	100.00 (94.34)
[113/294]	0.010 (0.162)	100.00 (94.39)
[114/294]	0.147 (0.162)	95.00 (94.39)
[115/294]	0.227 (0.162)	85.00 (94.31)
[116/294]	0.111 (0.162)	95.00 (94.32)
[117/294]	0.029 (0.161)	100.00 (94.36)
[118/294]	0.032 (0.160)	100.00 (94.41)
[119/294]	0.238 (0.160)	85.00 (94.33)
[120/294]	0.283 (0.161)	85.00 (94.26)
[121/294]	0.040 (0.160)	100.00 (94.30)
[122/294]	0.078 (0.160)	100.00 (94.35)
[123/294]	0.091 (0.159)	100.00 (94.40)
[124/294]	0.043 (0.158)	95.00 (94.40)
[125/294]	0.013 (0.157)	100.00 (94.44)
[126/294]	0.124 (0.157)	95.00 (94.45)
[127/294]	0.029 (0.156)	100.00 (94.49)
[128/294]	0.030 (0.155)	100.00 (94.53)
[129/294]	0.107 (0.154)	95.00 (94.54)
[130/294]	0.071 (0.154)	100.00 (94.58)
[131/294]	0.184 (0.154)	95.00 (94.58)
[132/294]	0.058 (0.153)	95.00 (94.59)
[133/294]	0.034 (0.152)	100.00 (94.63)
[134/294]	0.009 (0.151)	100.00 (94.67)
[135/294]	0.014 (0.150)	100.00 (94.71)
[136/294]	0.011 (0.149)	100.00 (94.74)
[137/294]	0.011 (0.148)	100.00 (94.78)
[138/294]	0.019 (0.147)	100.00 (94.82)
[139/294]	0.039 (0.147)	95.00 (94.82)
[140/294]	0.019 (0.146)	100.00 (94.86)
[141/294]	0.008 (0.145)	100.00 (94.89)
[142/294]	0.027 (0.144)	100.00 (94.93)
[143/294]	0.010 (0.143)	100.00 (94.97)
[144/294]	0.006 (0.142)	100.00 (95.00)
[145/294]	0.004 (0.141)	100.00 (95.03)
[146/294]	0.023 (0.140)	100.00 (95.07)
[147/294]	0.246 (0.141)	95.00 (95.07)
[148/294]	0.045 (0.140)	95.00 (95.07)
[149/294]	0.027 (0.140)	100.00 (95.10)
[150/294]	0.002 (0.139)	100.00 (95.13)
[151/294]	0.005 (0.138)	100.00 (95.16)
[152/294]	0.037 (0.137)	100.00 (95.20)
[153/294]	0.001 (0.136)	100.00 (95.23)
[154/294]	0.081 (0.136)	90.00 (95.19)
[155/294]	0.010 (0.135)	100.00 (95.22)
[156/294]	0.093 (0.135)	95.00 (95.22)
[157/294]	0.008 (0.134)	100.00 (95.25)
[158/294]	0.123 (0.134)	95.00 (95.25)
[159/294]	0.004 (0.133)	100.00 (95.28)
[160/294]	0.024 (0.132)	100.00 (95.31)
[161/294]	0.112 (0.132)	95.00 (95.31)
[162/294]	0.020 (0.132)	100.00 (95.34)
[163/294]	0.017 (0.131)	100.00 (95.37)
[164/294]	0.016 (0.130)	100.00 (95.39)
[165/294]	0.075 (0.130)	95.00 (95.39)
[166/294]	0.035 (0.129)	95.00 (95.39)
[167/294]	0.033 (0.129)	100.00 (95.42)
[168/294]	0.032 (0.128)	100.00 (95.44)
[169/294]	0.058 (0.128)	95.00 (95.44)
[170/294]	0.042 (0.127)	95.00 (95.44)
[171/294]	0.004 (0.127)	100.00 (95.47)
[172/294]	0.004 (0.126)	100.00 (95.49)
[173/294]	0.000 (0.125)	100.00 (95.52)
[174/294]	0.044 (0.125)	95.00 (95.51)
[175/294]	0.039 (0.124)	100.00 (95.54)
[176/294]	0.000 (0.123)	100.00 (95.56)
[177/294]	0.006 (0.123)	100.00 (95.59)
[178/294]	0.138 (0.123)	90.00 (95.56)
[179/294]	0.044 (0.122)	100.00 (95.58)
[180/294]	0.031 (0.122)	100.00 (95.61)
[181/294]	0.002 (0.121)	100.00 (95.63)
[182/294]	0.020 (0.121)	100.00 (95.66)
[183/294]	0.004 (0.120)	100.00 (95.68)
[184/294]	0.035 (0.120)	95.00 (95.68)
[185/294]	0.001 (0.119)	100.00 (95.70)
[186/294]	0.041 (0.119)	100.00 (95.72)
[187/294]	0.002 (0.118)	100.00 (95.74)
[188/294]	0.000 (0.117)	100.00 (95.77)
[189/294]	0.011 (0.117)	100.00 (95.79)
[190/294]	0.000 (0.116)	100.00 (95.81)
[191/294]	0.001 (0.116)	100.00 (95.83)
[192/294]	0.113 (0.116)	95.00 (95.83)
[193/294]	0.000 (0.115)	100.00 (95.85)
[194/294]	0.011 (0.114)	100.00 (95.87)
[195/294]	0.041 (0.114)	95.00 (95.87)
[196/294]	0.143 (0.114)	95.00 (95.86)
[197/294]	0.011 (0.114)	100.00 (95.88)
[198/294]	0.201 (0.114)	95.00 (95.88)
[199/294]	0.012 (0.114)	100.00 (95.90)
[200/294]	0.038 (0.113)	95.00 (95.90)
[201/294]	0.016 (0.113)	100.00 (95.92)
[202/294]	0.017 (0.112)	100.00 (95.94)
[203/294]	0.002 (0.112)	100.00 (95.96)
[204/294]	0.054 (0.111)	95.00 (95.95)
[205/294]	0.030 (0.111)	100.00 (95.97)
[206/294]	0.002 (0.111)	100.00 (95.99)
[207/294]	0.012 (0.110)	100.00 (96.01)
[208/294]	0.009 (0.110)	100.00 (96.03)
[209/294]	0.006 (0.109)	100.00 (96.05)
[210/294]	0.012 (0.109)	100.00 (96.07)
[211/294]	0.010 (0.108)	100.00 (96.08)
[212/294]	0.076 (0.108)	95.00 (96.08)
[213/294]	0.011 (0.108)	100.00 (96.10)
[214/294]	0.000 (0.107)	100.00 (96.12)
[215/294]	0.032 (0.107)	100.00 (96.13)
[216/294]	0.006 (0.106)	100.00 (96.15)
[217/294]	0.003 (0.106)	100.00 (96.17)
[218/294]	0.000 (0.105)	100.00 (96.19)
[219/294]	0.149 (0.105)	95.00 (96.18)
[220/294]	0.013 (0.105)	100.00 (96.20)
[221/294]	0.001 (0.105)	100.00 (96.22)
[222/294]	0.002 (0.104)	100.00 (96.23)
[223/294]	0.002 (0.104)	100.00 (96.25)
[224/294]	0.073 (0.104)	95.00 (96.24)
[225/294]	0.069 (0.103)	100.00 (96.26)
[226/294]	0.009 (0.103)	100.00 (96.28)
[227/294]	0.020 (0.103)	100.00 (96.29)
[228/294]	0.017 (0.102)	100.00 (96.31)
[229/294]	0.014 (0.102)	100.00 (96.33)
[230/294]	0.000 (0.101)	100.00 (96.34)
[231/294]	0.102 (0.101)	95.00 (96.34)
[232/294]	0.003 (0.101)	100.00 (96.35)
[233/294]	0.055 (0.101)	100.00 (96.37)
[234/294]	0.129 (0.101)	95.00 (96.36)
[235/294]	0.005 (0.100)	100.00 (96.38)
[236/294]	0.010 (0.100)	100.00 (96.39)
[237/294]	0.042 (0.100)	100.00 (96.41)
[238/294]	0.003 (0.099)	100.00 (96.42)
[239/294]	0.013 (0.099)	100.00 (96.44)
[240/294]	0.000 (0.099)	100.00 (96.45)
[241/294]	0.028 (0.098)	100.00 (96.47)
[242/294]	0.004 (0.098)	100.00 (96.48)
[243/294]	0.011 (0.098)	100.00 (96.50)
[244/294]	0.001 (0.097)	100.00 (96.51)
[245/294]	0.001 (0.097)	100.00 (96.52)
[246/294]	0.000 (0.096)	100.00 (96.54)
[247/294]	0.003 (0.096)	100.00 (96.55)
[248/294]	0.007 (0.096)	100.00 (96.57)
[249/294]	0.001 (0.095)	100.00 (96.58)
[250/294]	0.010 (0.095)	100.00 (96.59)
[251/294]	0.033 (0.095)	100.00 (96.61)
[252/294]	0.004 (0.094)	100.00 (96.62)
[253/294]	0.071 (0.094)	95.00 (96.61)
[254/294]	0.042 (0.094)	95.00 (96.61)
[255/294]	0.005 (0.094)	100.00 (96.62)
[256/294]	0.025 (0.093)	100.00 (96.63)
[257/294]	0.000 (0.093)	100.00 (96.65)
[258/294]	0.000 (0.093)	100.00 (96.66)
[259/294]	0.000 (0.092)	100.00 (96.67)
[260/294]	0.000 (0.092)	100.00 (96.69)
[261/294]	0.007 (0.092)	100.00 (96.70)
[262/294]	0.000 (0.091)	100.00 (96.71)
[263/294]	0.001 (0.091)	100.00 (96.72)
[264/294]	0.025 (0.091)	100.00 (96.74)
[265/294]	0.053 (0.091)	95.00 (96.73)
[266/294]	0.001 (0.090)	100.00 (96.74)
[267/294]	0.001 (0.090)	100.00 (96.75)
[268/294]	0.000 (0.090)	100.00 (96.77)
[269/294]	0.000 (0.089)	100.00 (96.78)
[270/294]	0.073 (0.089)	95.00 (96.77)
[271/294]	0.001 (0.089)	100.00 (96.78)
[272/294]	0.001 (0.089)	100.00 (96.79)
[273/294]	0.010 (0.088)	100.00 (96.81)
[274/294]	0.001 (0.088)	100.00 (96.82)
[275/294]	0.000 (0.088)	100.00 (96.83)
[276/294]	0.003 (0.087)	100.00 (96.84)
[277/294]	0.005 (0.087)	100.00 (96.85)
[278/294]	0.041 (0.087)	100.00 (96.86)
[279/294]	0.000 (0.087)	100.00 (96.88)
[280/294]	0.000 (0.086)	100.00 (96.89)
[281/294]	0.000 (0.086)	100.00 (96.90)
[282/294]	0.002 (0.086)	100.00 (96.91)
[283/294]	0.020 (0.085)	100.00 (96.92)
[284/294]	0.001 (0.085)	100.00 (96.93)
[285/294]	0.007 (0.085)	100.00 (96.94)
[286/294]	0.000 (0.085)	100.00 (96.95)
[287/294]	0.000 (0.084)	100.00 (96.96)
[288/294]	0.000 (0.084)	100.00 (96.97)
[289/294]	0.012 (0.084)	100.00 (96.98)
[290/294]	0.046 (0.084)	100.00 (96.99)
[291/294]	0.000 (0.083)	100.00 (97.00)
[292/294]	0.023 (0.083)	100.00 (97.01)
[293/294]	0.003 (0.083)	100.00 (97.02)
 * Train Acc: 97.024
 * Avg. Data time: 0.005, Avg. Batch time: 0.043, Avg. Forward time: 0.004, Avg. Backward time: 0.021
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 95.913, Time: 5.00
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.357 (8.715)	0.00 (0.00)
[1/294]	1.072 (4.969)	35.00 (17.50)
[2/294]	0.381 (3.555)	60.00 (31.67)
[3/294]	0.565 (2.876)	50.00 (36.25)
[4/294]	0.629 (2.436)	65.00 (42.00)
[5/294]	0.520 (2.189)	30.00 (40.00)
[6/294]	0.692 (2.012)	40.00 (40.00)
[7/294]	0.532 (1.853)	50.00 (41.25)
[8/294]	0.500 (1.756)	25.00 (39.44)
[9/294]	0.578 (1.660)	60.00 (41.50)
[10/294]	0.522 (1.599)	40.00 (41.36)
[11/294]	0.525 (1.531)	60.00 (42.92)
[12/294]	0.526 (1.473)	60.00 (44.23)
[13/294]	0.593 (1.422)	65.00 (45.71)
 * Train Acc: 45.714
 * Avg. Data time: 0.116, Avg. Batch time: 0.186, Avg. Train-batch time: 0.027, Avg. Replay-batch time: 0.037
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 32.004, Time: 8.45
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.577 (3.344)	0.00 (0.00)
[1/294]	0.596 (2.808)	0.00 (0.00)
[2/294]	0.639 (2.512)	0.00 (0.00)
[3/294]	0.666 (2.297)	25.00 (6.25)
[4/294]	0.696 (2.140)	35.00 (12.00)
[5/294]	0.776 (1.971)	45.00 (17.50)
[6/294]	1.230 (1.807)	50.00 (22.14)
[7/294]	1.409 (1.683)	30.00 (23.12)
[8/294]	0.973 (1.743)	35.00 (24.44)
[9/294]	0.754 (1.686)	35.00 (25.50)
[10/294]	0.693 (1.660)	45.00 (27.27)
[11/294]	0.691 (1.646)	55.00 (29.58)
[12/294]	0.712 (1.635)	35.00 (30.00)
[13/294]	0.704 (1.618)	40.00 (30.71)
[14/294]	0.738 (1.583)	75.00 (33.67)
[15/294]	0.825 (1.543)	55.00 (35.00)
[16/294]	0.985 (1.497)	65.00 (36.76)
[17/294]	1.147 (1.463)	35.00 (36.67)
[18/294]	1.222 (1.443)	40.00 (36.84)
[19/294]	1.060 (1.412)	50.00 (37.50)
 * Train Acc: 37.500
 * Avg. Data time: 0.097, Avg. Batch time: 0.156, Avg. Train-batch time: 0.027, Avg. Replay-batch time: 0.028
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 17.090, Time: 12.50
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.605 (3.101)	0.00 (0.00)
[1/294]	0.644 (2.695)	0.00 (0.00)
[2/294]	0.666 (2.492)	0.00 (0.00)
[3/294]	0.679 (2.380)	0.00 (0.00)
[4/294]	0.675 (2.310)	0.00 (0.00)
[5/294]	0.681 (2.262)	0.00 (0.00)
[6/294]	0.680 (2.227)	0.00 (0.00)
[7/294]	0.681 (2.199)	0.00 (0.00)
[8/294]	0.684 (2.178)	0.00 (0.00)
[9/294]	0.684 (2.159)	0.00 (0.00)
[10/294]	0.680 (2.143)	10.00 (0.91)
[11/294]	0.683 (2.128)	30.00 (3.33)
[12/294]	0.685 (2.115)	50.00 (6.92)
[13/294]	0.682 (2.101)	60.00 (10.71)
[14/294]	0.681 (2.089)	30.00 (12.00)
[15/294]	0.685 (2.075)	45.00 (14.06)
[16/294]	0.681 (2.060)	35.00 (15.29)
[17/294]	0.698 (2.038)	60.00 (17.78)
[18/294]	0.751 (2.007)	40.00 (18.95)
[19/294]	0.818 (1.963)	50.00 (20.50)
[20/294]	1.098 (1.907)	65.00 (22.62)
[21/294]	1.144 (1.863)	30.00 (22.95)
[22/294]	1.283 (1.825)	40.00 (23.70)
[23/294]	1.075 (1.780)	55.00 (25.00)
 * Train Acc: 25.000
 * Avg. Data time: 0.072, Avg. Batch time: 0.145, Avg. Train-batch time: 0.029, Avg. Replay-batch time: 0.038
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 14.594, Time: 18.47
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.591 (4.699)	0.00 (0.00)
[1/294]	0.654 (3.570)	0.00 (0.00)
[2/294]	0.668 (3.137)	0.00 (0.00)
[3/294]	0.680 (2.916)	0.00 (0.00)
[4/294]	0.680 (2.780)	0.00 (0.00)
[5/294]	0.682 (2.690)	0.00 (0.00)
[6/294]	0.682 (2.625)	0.00 (0.00)
[7/294]	0.685 (2.575)	0.00 (0.00)
[8/294]	0.685 (2.536)	0.00 (0.00)
[9/294]	0.683 (2.504)	0.00 (0.00)
[10/294]	0.684 (2.477)	0.00 (0.00)
[11/294]	0.684 (2.455)	10.00 (0.83)
[12/294]	0.685 (2.435)	15.00 (1.92)
[13/294]	0.685 (2.418)	40.00 (4.64)
[14/294]	0.685 (2.401)	50.00 (7.67)
[15/294]	0.686 (2.387)	65.00 (11.25)
[16/294]	0.686 (2.374)	65.00 (14.41)
[17/294]	0.685 (2.361)	45.00 (16.11)
[18/294]	0.686 (2.347)	70.00 (18.95)
[19/294]	0.686 (2.334)	50.00 (20.50)
[20/294]	0.686 (2.320)	35.00 (21.19)
[21/294]	0.687 (2.306)	75.00 (23.64)
[22/294]	0.690 (2.288)	70.00 (25.65)
[23/294]	0.695 (2.267)	65.00 (27.29)
[24/294]	0.701 (2.242)	60.00 (28.60)
[25/294]	0.736 (2.210)	65.00 (30.00)
 * Train Acc: 30.000
 * Avg. Data time: 0.062, Avg. Batch time: 0.122, Avg. Train-batch time: 0.025, Avg. Replay-batch time: 0.032
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 13.833, Time: 19.86
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.663 (3.001)	0.00 (0.00)
[1/294]	0.639 (3.020)	0.00 (0.00)
[2/294]	0.627 (2.883)	0.00 (0.00)
[3/294]	0.671 (2.720)	0.00 (0.00)
[4/294]	0.655 (2.564)	0.00 (0.00)
[5/294]	0.683 (2.418)	55.00 (9.17)
[6/294]	0.752 (2.269)	55.00 (15.71)
[7/294]	0.840 (2.120)	60.00 (21.25)
[8/294]	0.886 (1.986)	50.00 (24.44)
[9/294]	1.171 (1.873)	30.00 (25.00)
[10/294]	1.028 (1.767)	55.00 (27.73)
[11/294]	1.237 (1.684)	55.00 (30.00)
[12/294]	1.011 (1.611)	50.00 (31.54)
[13/294]	1.030 (1.546)	60.00 (33.57)
[14/294]	0.998 (1.487)	70.00 (36.00)
[15/294]	0.798 (1.444)	40.00 (36.25)
[16/294]	0.879 (1.405)	60.00 (37.65)
[17/294]	0.964 (1.373)	50.00 (38.33)
[18/294]	0.799 (1.345)	80.00 (40.53)
[19/294]	0.883 (1.322)	50.00 (41.00)
[20/294]	0.861 (1.297)	55.00 (41.67)
[21/294]	0.819 (1.277)	35.00 (41.36)
[22/294]	0.839 (1.253)	75.00 (42.83)
[23/294]	0.929 (1.232)	70.00 (43.96)
[24/294]	0.921 (1.212)	65.00 (44.80)
[25/294]	0.924 (1.192)	70.00 (45.77)
[26/294]	0.882 (1.169)	90.00 (47.41)
[27/294]	0.914 (1.151)	60.00 (47.86)
 * Train Acc: 47.857
 * Avg. Data time: 0.069, Avg. Batch time: 0.135, Avg. Train-batch time: 0.026, Avg. Replay-batch time: 0.035
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 12.324, Time: 22.39
testing accuracies
           0          1          2          3          4          5
0  98.452381  27.539683  20.394911  16.046558  12.647152  11.622051
1  95.912698  32.003968  17.089947  14.593682  13.832830  12.324410
validation accuracies
Empty DataFrame
Columns: []
Index: [0, 1]

=============Stream Learning Run 0=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	0.905 (0.905)	60.00 (60.00)
[1/294]	1.048 (0.976)	55.00 (57.50)
[2/294]	1.303 (1.085)	45.00 (53.33)
[3/294]	1.194 (1.112)	40.00 (50.00)
[4/294]	0.900 (1.070)	45.00 (49.00)
[5/294]	0.797 (1.024)	55.00 (50.00)
[6/294]	0.816 (0.995)	55.00 (50.71)
[7/294]	0.705 (0.958)	65.00 (52.50)
[8/294]	0.709 (0.931)	50.00 (52.22)
[9/294]	0.860 (0.924)	40.00 (51.00)
[10/294]	0.751 (0.908)	50.00 (50.91)
[11/294]	0.635 (0.885)	60.00 (51.67)
[12/294]	0.641 (0.866)	70.00 (53.08)
[13/294]	0.792 (0.861)	35.00 (51.79)
[14/294]	0.589 (0.843)	75.00 (53.33)
[15/294]	0.684 (0.833)	65.00 (54.06)
[16/294]	0.989 (0.842)	40.00 (53.24)
[17/294]	0.770 (0.838)	55.00 (53.33)
[18/294]	0.499 (0.820)	70.00 (54.21)
[19/294]	0.664 (0.813)	60.00 (54.50)
[20/294]	0.662 (0.805)	60.00 (54.76)
[21/294]	0.704 (0.801)	55.00 (54.77)
[22/294]	0.849 (0.803)	35.00 (53.91)
[23/294]	0.618 (0.795)	60.00 (54.17)
[24/294]	0.595 (0.787)	70.00 (54.80)
[25/294]	0.501 (0.776)	95.00 (56.35)
[26/294]	0.628 (0.771)	60.00 (56.48)
[27/294]	0.635 (0.766)	60.00 (56.61)
[28/294]	0.528 (0.758)	75.00 (57.24)
[29/294]	0.612 (0.753)	50.00 (57.00)
[30/294]	0.631 (0.749)	65.00 (57.26)
[31/294]	0.606 (0.744)	65.00 (57.50)
[32/294]	0.413 (0.734)	85.00 (58.33)
[33/294]	0.555 (0.729)	70.00 (58.68)
[34/294]	0.581 (0.725)	65.00 (58.86)
[35/294]	0.609 (0.722)	65.00 (59.03)
[36/294]	0.641 (0.719)	60.00 (59.05)
[37/294]	0.570 (0.716)	65.00 (59.21)
[38/294]	0.571 (0.712)	75.00 (59.62)
[39/294]	0.584 (0.709)	65.00 (59.75)
[40/294]	0.516 (0.704)	75.00 (60.12)
[41/294]	0.453 (0.698)	85.00 (60.71)
[42/294]	0.602 (0.696)	65.00 (60.81)
[43/294]	0.606 (0.694)	65.00 (60.91)
[44/294]	0.526 (0.690)	70.00 (61.11)
[45/294]	0.486 (0.686)	85.00 (61.63)
[46/294]	0.540 (0.682)	75.00 (61.91)
[47/294]	0.744 (0.684)	50.00 (61.67)
[48/294]	0.626 (0.683)	50.00 (61.43)
[49/294]	0.473 (0.678)	85.00 (61.90)
[50/294]	0.570 (0.676)	70.00 (62.06)
[51/294]	0.591 (0.675)	60.00 (62.02)
[52/294]	0.431 (0.670)	90.00 (62.55)
[53/294]	0.453 (0.666)	80.00 (62.87)
[54/294]	0.498 (0.663)	80.00 (63.18)
[55/294]	0.501 (0.660)	85.00 (63.57)
[56/294]	0.454 (0.656)	85.00 (63.95)
[57/294]	0.554 (0.655)	85.00 (64.31)
[58/294]	0.530 (0.653)	75.00 (64.49)
[59/294]	0.526 (0.650)	80.00 (64.75)
[60/294]	0.396 (0.646)	85.00 (65.08)
[61/294]	0.576 (0.645)	70.00 (65.16)
[62/294]	0.489 (0.643)	65.00 (65.16)
[63/294]	0.572 (0.642)	70.00 (65.23)
[64/294]	0.575 (0.641)	80.00 (65.46)
[65/294]	0.399 (0.637)	85.00 (65.76)
[66/294]	0.502 (0.635)	75.00 (65.90)
[67/294]	0.429 (0.632)	90.00 (66.25)
[68/294]	0.534 (0.630)	80.00 (66.45)
[69/294]	0.558 (0.629)	75.00 (66.57)
[70/294]	0.417 (0.626)	90.00 (66.90)
[71/294]	0.616 (0.626)	65.00 (66.88)
[72/294]	0.568 (0.625)	70.00 (66.92)
[73/294]	0.450 (0.623)	80.00 (67.09)
[74/294]	0.479 (0.621)	70.00 (67.13)
[75/294]	0.330 (0.617)	95.00 (67.50)
[76/294]	0.447 (0.615)	80.00 (67.66)
[77/294]	0.326 (0.611)	90.00 (67.95)
[78/294]	0.407 (0.609)	80.00 (68.10)
[79/294]	0.486 (0.607)	75.00 (68.19)
[80/294]	0.502 (0.606)	90.00 (68.46)
[81/294]	0.384 (0.603)	90.00 (68.72)
[82/294]	0.524 (0.602)	65.00 (68.67)
[83/294]	0.365 (0.600)	85.00 (68.87)
[84/294]	0.382 (0.597)	90.00 (69.12)
[85/294]	0.436 (0.595)	80.00 (69.24)
[86/294]	0.437 (0.593)	75.00 (69.31)
[87/294]	0.356 (0.591)	90.00 (69.55)
[88/294]	0.491 (0.589)	70.00 (69.55)
[89/294]	0.505 (0.589)	80.00 (69.67)
[90/294]	0.480 (0.587)	80.00 (69.78)
[91/294]	0.330 (0.585)	95.00 (70.05)
[92/294]	0.617 (0.585)	65.00 (70.00)
[93/294]	0.442 (0.583)	80.00 (70.11)
[94/294]	0.495 (0.582)	85.00 (70.26)
[95/294]	0.374 (0.580)	90.00 (70.47)
[96/294]	0.384 (0.578)	85.00 (70.62)
[97/294]	0.353 (0.576)	80.00 (70.71)
[98/294]	0.235 (0.572)	100.00 (71.01)
[99/294]	0.356 (0.570)	90.00 (71.20)
[100/294]	0.442 (0.569)	80.00 (71.29)
[101/294]	0.376 (0.567)	90.00 (71.47)
[102/294]	0.456 (0.566)	75.00 (71.50)
[103/294]	0.556 (0.566)	65.00 (71.44)
[104/294]	0.383 (0.564)	85.00 (71.57)
[105/294]	0.232 (0.561)	95.00 (71.79)
[106/294]	0.448 (0.560)	80.00 (71.87)
[107/294]	0.330 (0.558)	90.00 (72.04)
[108/294]	0.377 (0.556)	80.00 (72.11)
[109/294]	0.353 (0.554)	90.00 (72.27)
[110/294]	0.337 (0.552)	90.00 (72.43)
[111/294]	0.381 (0.551)	85.00 (72.54)
[112/294]	0.317 (0.549)	100.00 (72.79)
[113/294]	0.483 (0.548)	65.00 (72.72)
[114/294]	0.342 (0.546)	95.00 (72.91)
[115/294]	0.316 (0.545)	90.00 (73.06)
[116/294]	0.412 (0.543)	80.00 (73.12)
[117/294]	0.493 (0.543)	85.00 (73.22)
[118/294]	0.419 (0.542)	80.00 (73.28)
[119/294]	0.456 (0.541)	80.00 (73.33)
[120/294]	0.369 (0.540)	80.00 (73.39)
[121/294]	0.459 (0.539)	75.00 (73.40)
[122/294]	0.500 (0.539)	70.00 (73.37)
[123/294]	0.464 (0.538)	75.00 (73.39)
[124/294]	0.408 (0.537)	80.00 (73.44)
[125/294]	0.321 (0.535)	85.00 (73.53)
[126/294]	0.446 (0.535)	85.00 (73.62)
[127/294]	0.369 (0.533)	95.00 (73.79)
[128/294]	0.277 (0.531)	90.00 (73.91)
[129/294]	0.398 (0.530)	75.00 (73.92)
[130/294]	0.278 (0.528)	90.00 (74.05)
[131/294]	0.417 (0.528)	75.00 (74.05)
[132/294]	0.284 (0.526)	90.00 (74.17)
[133/294]	0.311 (0.524)	90.00 (74.29)
[134/294]	0.236 (0.522)	95.00 (74.44)
[135/294]	0.351 (0.521)	90.00 (74.56)
[136/294]	0.351 (0.520)	90.00 (74.67)
[137/294]	0.367 (0.518)	85.00 (74.75)
[138/294]	0.294 (0.517)	85.00 (74.82)
[139/294]	0.378 (0.516)	80.00 (74.86)
[140/294]	0.418 (0.515)	85.00 (74.93)
[141/294]	0.297 (0.514)	95.00 (75.07)
[142/294]	0.349 (0.512)	80.00 (75.10)
[143/294]	0.222 (0.510)	100.00 (75.28)
[144/294]	0.348 (0.509)	90.00 (75.38)
[145/294]	0.313 (0.508)	95.00 (75.51)
[146/294]	0.342 (0.507)	90.00 (75.61)
[147/294]	0.337 (0.506)	85.00 (75.68)
[148/294]	0.364 (0.505)	80.00 (75.70)
[149/294]	0.431 (0.504)	80.00 (75.73)
[150/294]	0.397 (0.504)	85.00 (75.79)
[151/294]	0.340 (0.502)	80.00 (75.82)
[152/294]	0.358 (0.502)	95.00 (75.95)
[153/294]	0.248 (0.500)	95.00 (76.07)
[154/294]	0.338 (0.499)	85.00 (76.13)
[155/294]	0.469 (0.499)	65.00 (76.06)
[156/294]	0.371 (0.498)	85.00 (76.11)
[157/294]	0.184 (0.496)	95.00 (76.23)
[158/294]	0.285 (0.495)	90.00 (76.32)
[159/294]	0.403 (0.494)	85.00 (76.38)
[160/294]	0.485 (0.494)	75.00 (76.37)
[161/294]	0.423 (0.493)	75.00 (76.36)
[162/294]	0.255 (0.492)	95.00 (76.47)
[163/294]	0.325 (0.491)	85.00 (76.52)
[164/294]	0.353 (0.490)	90.00 (76.61)
[165/294]	0.354 (0.489)	85.00 (76.66)
[166/294]	0.333 (0.488)	85.00 (76.71)
[167/294]	0.251 (0.487)	95.00 (76.82)
[168/294]	0.351 (0.486)	85.00 (76.86)
[169/294]	0.326 (0.485)	95.00 (76.97)
[170/294]	0.473 (0.485)	80.00 (76.99)
[171/294]	0.410 (0.485)	80.00 (77.01)
[172/294]	0.333 (0.484)	85.00 (77.05)
[173/294]	0.191 (0.482)	95.00 (77.16)
[174/294]	0.245 (0.481)	95.00 (77.26)
[175/294]	0.301 (0.480)	80.00 (77.27)
[176/294]	0.334 (0.479)	90.00 (77.34)
[177/294]	0.343 (0.478)	85.00 (77.39)
[178/294]	0.284 (0.477)	90.00 (77.46)
[179/294]	0.463 (0.477)	75.00 (77.44)
[180/294]	0.212 (0.476)	95.00 (77.54)
[181/294]	0.234 (0.474)	95.00 (77.64)
[182/294]	0.296 (0.473)	90.00 (77.70)
[183/294]	0.320 (0.472)	85.00 (77.74)
[184/294]	0.214 (0.471)	100.00 (77.86)
[185/294]	0.299 (0.470)	95.00 (77.96)
[186/294]	0.292 (0.469)	90.00 (78.02)
[187/294]	0.434 (0.469)	75.00 (78.01)
[188/294]	0.481 (0.469)	85.00 (78.04)
[189/294]	0.351 (0.468)	90.00 (78.11)
[190/294]	0.170 (0.467)	100.00 (78.22)
[191/294]	0.235 (0.466)	95.00 (78.31)
[192/294]	0.267 (0.465)	90.00 (78.37)
[193/294]	0.266 (0.464)	90.00 (78.43)
[194/294]	0.343 (0.463)	75.00 (78.41)
[195/294]	0.243 (0.462)	90.00 (78.47)
[196/294]	0.144 (0.460)	100.00 (78.58)
[197/294]	0.218 (0.459)	90.00 (78.64)
[198/294]	0.268 (0.458)	95.00 (78.72)
[199/294]	0.351 (0.458)	80.00 (78.72)
[200/294]	0.464 (0.458)	80.00 (78.73)
[201/294]	0.368 (0.457)	80.00 (78.74)
[202/294]	0.387 (0.457)	85.00 (78.77)
[203/294]	0.294 (0.456)	90.00 (78.82)
[204/294]	0.351 (0.455)	80.00 (78.83)
[205/294]	0.191 (0.454)	95.00 (78.91)
[206/294]	0.360 (0.454)	85.00 (78.94)
[207/294]	0.299 (0.453)	85.00 (78.97)
[208/294]	0.185 (0.452)	100.00 (79.07)
[209/294]	0.203 (0.451)	100.00 (79.17)
[210/294]	0.218 (0.449)	95.00 (79.24)
[211/294]	0.132 (0.448)	100.00 (79.34)
[212/294]	0.217 (0.447)	100.00 (79.44)
[213/294]	0.239 (0.446)	95.00 (79.51)
[214/294]	0.288 (0.445)	95.00 (79.58)
[215/294]	0.427 (0.445)	80.00 (79.58)
[216/294]	0.324 (0.444)	95.00 (79.65)
[217/294]	0.412 (0.444)	85.00 (79.68)
[218/294]	0.229 (0.443)	90.00 (79.73)
[219/294]	0.323 (0.443)	90.00 (79.77)
[220/294]	0.190 (0.442)	95.00 (79.84)
[221/294]	0.229 (0.441)	95.00 (79.91)
[222/294]	0.405 (0.441)	80.00 (79.91)
[223/294]	0.252 (0.440)	90.00 (79.96)
[224/294]	0.218 (0.439)	95.00 (80.02)
[225/294]	0.305 (0.438)	95.00 (80.09)
[226/294]	0.166 (0.437)	95.00 (80.15)
[227/294]	0.241 (0.436)	90.00 (80.20)
[228/294]	0.122 (0.435)	100.00 (80.28)
[229/294]	0.360 (0.434)	80.00 (80.28)
[230/294]	0.246 (0.434)	95.00 (80.35)
[231/294]	0.201 (0.433)	95.00 (80.41)
[232/294]	0.183 (0.431)	100.00 (80.49)
[233/294]	0.161 (0.430)	100.00 (80.58)
[234/294]	0.205 (0.429)	100.00 (80.66)
[235/294]	0.151 (0.428)	95.00 (80.72)
[236/294]	0.170 (0.427)	95.00 (80.78)
[237/294]	0.320 (0.427)	85.00 (80.80)
[238/294]	0.204 (0.426)	95.00 (80.86)
[239/294]	0.131 (0.424)	100.00 (80.94)
[240/294]	0.205 (0.424)	95.00 (81.00)
[241/294]	0.370 (0.423)	85.00 (81.01)
[242/294]	0.287 (0.423)	85.00 (81.03)
[243/294]	0.216 (0.422)	100.00 (81.11)
[244/294]	0.368 (0.422)	80.00 (81.10)
[245/294]	0.196 (0.421)	95.00 (81.16)
[246/294]	0.380 (0.421)	80.00 (81.15)
[247/294]	0.318 (0.420)	80.00 (81.15)
[248/294]	0.224 (0.419)	95.00 (81.20)
[249/294]	0.238 (0.419)	95.00 (81.26)
[250/294]	0.317 (0.418)	80.00 (81.25)
[251/294]	0.282 (0.418)	80.00 (81.25)
[252/294]	0.180 (0.417)	90.00 (81.28)
[253/294]	0.211 (0.416)	95.00 (81.34)
[254/294]	0.327 (0.416)	85.00 (81.35)
[255/294]	0.265 (0.415)	80.00 (81.35)
[256/294]	0.277 (0.415)	80.00 (81.34)
[257/294]	0.426 (0.415)	75.00 (81.32)
[258/294]	0.154 (0.414)	95.00 (81.37)
[259/294]	0.214 (0.413)	95.00 (81.42)
[260/294]	0.178 (0.412)	100.00 (81.49)
[261/294]	0.175 (0.411)	90.00 (81.53)
[262/294]	0.211 (0.410)	90.00 (81.56)
[263/294]	0.182 (0.409)	95.00 (81.61)
[264/294]	0.375 (0.409)	85.00 (81.62)
[265/294]	0.141 (0.408)	100.00 (81.69)
[266/294]	0.123 (0.407)	100.00 (81.76)
[267/294]	0.331 (0.407)	90.00 (81.79)
[268/294]	0.138 (0.406)	100.00 (81.86)
[269/294]	0.183 (0.405)	95.00 (81.91)
[270/294]	0.278 (0.405)	90.00 (81.94)
[271/294]	0.279 (0.404)	90.00 (81.97)
[272/294]	0.357 (0.404)	95.00 (82.01)
[273/294]	0.214 (0.403)	95.00 (82.06)
[274/294]	0.278 (0.403)	85.00 (82.07)
[275/294]	0.173 (0.402)	95.00 (82.12)
[276/294]	0.154 (0.401)	100.00 (82.18)
[277/294]	0.157 (0.400)	100.00 (82.25)
[278/294]	0.335 (0.400)	80.00 (82.24)
[279/294]	0.180 (0.399)	95.00 (82.29)
[280/294]	0.301 (0.399)	85.00 (82.30)
[281/294]	0.121 (0.398)	95.00 (82.34)
[282/294]	0.104 (0.397)	100.00 (82.40)
[283/294]	0.163 (0.396)	95.00 (82.45)
[284/294]	0.070 (0.395)	100.00 (82.51)
[285/294]	0.219 (0.394)	95.00 (82.55)
[286/294]	0.358 (0.394)	80.00 (82.54)
[287/294]	0.205 (0.393)	90.00 (82.57)
[288/294]	0.096 (0.392)	100.00 (82.63)
[289/294]	0.289 (0.392)	85.00 (82.64)
[290/294]	0.222 (0.391)	95.00 (82.68)
[291/294]	0.242 (0.391)	95.00 (82.72)
[292/294]	0.285 (0.391)	90.00 (82.75)
[293/294]	0.206 (0.390)	95.00 (82.79)
 * Train Acc: 82.789
 * Avg. Data time: 0.005, Avg. Batch time: 0.054, Avg. Forward time: 0.004, Avg. Backward time: 0.022
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 94.087, Time: 4.52
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.175 (4.019)	0.00 (0.00)
[1/294]	0.246 (3.764)	0.00 (0.00)
[2/294]	0.282 (3.589)	0.00 (0.00)
[3/294]	0.137 (3.344)	0.00 (0.00)
[4/294]	0.170 (3.101)	15.00 (3.00)
[5/294]	0.206 (2.894)	10.00 (4.17)
[6/294]	0.249 (2.696)	35.00 (8.57)
[7/294]	0.193 (2.510)	50.00 (13.75)
[8/294]	0.243 (2.388)	30.00 (15.56)
[9/294]	0.281 (2.242)	55.00 (19.50)
[10/294]	0.314 (2.124)	70.00 (24.09)
[11/294]	0.199 (2.023)	50.00 (26.25)
[12/294]	0.234 (1.925)	50.00 (28.08)
[13/294]	0.286 (1.858)	35.00 (28.57)
 * Train Acc: 28.571
 * Avg. Data time: 0.131, Avg. Batch time: 0.186, Avg. Train-batch time: 0.023, Avg. Replay-batch time: 0.026
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 53.869, Time: 8.96
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.231 (2.278)	15.00 (15.00)
[1/294]	0.252 (2.145)	5.00 (10.00)
[2/294]	0.284 (2.084)	15.00 (11.67)
[3/294]	0.248 (1.980)	35.00 (17.50)
[4/294]	0.271 (1.909)	25.00 (19.00)
[5/294]	0.214 (1.814)	55.00 (25.00)
[6/294]	0.279 (1.712)	60.00 (30.00)
[7/294]	0.247 (1.638)	45.00 (31.88)
[8/294]	0.318 (1.555)	65.00 (35.56)
[9/294]	0.284 (1.487)	65.00 (38.50)
[10/294]	0.246 (1.427)	60.00 (40.45)
[11/294]	0.378 (1.358)	75.00 (43.33)
[12/294]	0.284 (1.305)	65.00 (45.00)
[13/294]	0.326 (1.254)	80.00 (47.50)
[14/294]	0.300 (1.217)	65.00 (48.67)
[15/294]	0.230 (1.182)	55.00 (49.06)
[16/294]	0.331 (1.155)	55.00 (49.41)
[17/294]	0.297 (1.130)	60.00 (50.00)
[18/294]	0.307 (1.098)	75.00 (51.32)
[19/294]	0.387 (1.064)	80.00 (52.75)
 * Train Acc: 52.750
 * Avg. Data time: 0.082, Avg. Batch time: 0.148, Avg. Train-batch time: 0.026, Avg. Replay-batch time: 0.036
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 38.669, Time: 11.68
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.355 (5.840)	0.00 (0.00)
[1/294]	0.352 (5.527)	0.00 (0.00)
[2/294]	0.334 (5.357)	0.00 (0.00)
[3/294]	0.408 (5.156)	0.00 (0.00)
[4/294]	0.334 (4.940)	0.00 (0.00)
[5/294]	0.399 (4.714)	0.00 (0.00)
[6/294]	0.337 (4.462)	0.00 (0.00)
[7/294]	0.380 (4.248)	0.00 (0.00)
[8/294]	0.389 (4.056)	0.00 (0.00)
[9/294]	0.407 (3.873)	5.00 (0.50)
[10/294]	0.430 (3.717)	5.00 (0.91)
[11/294]	0.386 (3.563)	25.00 (2.92)
[12/294]	0.359 (3.432)	25.00 (4.62)
[13/294]	0.447 (3.306)	25.00 (6.07)
[14/294]	0.446 (3.184)	35.00 (8.00)
[15/294]	0.440 (3.067)	60.00 (11.25)
[16/294]	0.437 (2.948)	70.00 (14.71)
[17/294]	0.520 (2.855)	50.00 (16.67)
[18/294]	0.428 (2.761)	65.00 (19.21)
[19/294]	0.473 (2.673)	55.00 (21.00)
[20/294]	0.511 (2.583)	75.00 (23.57)
[21/294]	0.498 (2.504)	70.00 (25.68)
[22/294]	0.620 (2.432)	80.00 (28.04)
[23/294]	0.428 (2.364)	60.00 (29.38)
 * Train Acc: 29.375
 * Avg. Data time: 0.087, Avg. Batch time: 0.142, Avg. Train-batch time: 0.023, Avg. Replay-batch time: 0.027
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 27.905, Time: 16.63
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.410 (3.631)	0.00 (0.00)
[1/294]	0.475 (3.465)	0.00 (0.00)
[2/294]	0.478 (3.443)	0.00 (0.00)
[3/294]	0.455 (3.417)	0.00 (0.00)
[4/294]	0.438 (3.357)	0.00 (0.00)
[5/294]	0.435 (3.264)	0.00 (0.00)
[6/294]	0.443 (3.149)	0.00 (0.00)
[7/294]	0.445 (3.060)	10.00 (1.25)
[8/294]	0.441 (2.934)	25.00 (3.89)
[9/294]	0.534 (2.826)	30.00 (6.50)
[10/294]	0.433 (2.726)	30.00 (8.64)
[11/294]	0.455 (2.636)	35.00 (10.83)
[12/294]	0.419 (2.544)	45.00 (13.46)
[13/294]	0.491 (2.483)	20.00 (13.93)
[14/294]	0.469 (2.388)	70.00 (17.67)
[15/294]	0.501 (2.309)	60.00 (20.31)
[16/294]	0.581 (2.256)	40.00 (21.47)
[17/294]	0.499 (2.202)	40.00 (22.50)
[18/294]	0.517 (2.143)	55.00 (24.21)
[19/294]	0.582 (2.089)	60.00 (26.00)
[20/294]	0.489 (2.037)	60.00 (27.62)
[21/294]	0.514 (1.990)	50.00 (28.64)
[22/294]	0.522 (1.948)	50.00 (29.57)
[23/294]	0.581 (1.899)	75.00 (31.46)
[24/294]	0.670 (1.857)	65.00 (32.80)
[25/294]	0.539 (1.812)	65.00 (34.04)
 * Train Acc: 34.038
 * Avg. Data time: 0.070, Avg. Batch time: 0.145, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.039
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 21.723, Time: 18.50
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.428 (3.258)	0.00 (0.00)
[1/294]	0.429 (3.195)	0.00 (0.00)
[2/294]	0.457 (3.109)	0.00 (0.00)
[3/294]	0.458 (3.007)	0.00 (0.00)
[4/294]	0.485 (2.892)	0.00 (0.00)
[5/294]	0.473 (2.790)	5.00 (0.83)
[6/294]	0.487 (2.679)	15.00 (2.86)
[7/294]	0.472 (2.579)	15.00 (4.38)
[8/294]	0.460 (2.484)	30.00 (7.22)
[9/294]	0.473 (2.381)	40.00 (10.50)
[10/294]	0.494 (2.285)	60.00 (15.00)
[11/294]	0.490 (2.190)	85.00 (20.83)
[12/294]	0.478 (2.098)	80.00 (25.38)
[13/294]	0.538 (2.009)	75.00 (28.93)
[14/294]	0.560 (1.932)	85.00 (32.67)
[15/294]	0.496 (1.871)	70.00 (35.00)
[16/294]	0.499 (1.803)	65.00 (36.76)
[17/294]	0.462 (1.743)	90.00 (39.72)
[18/294]	0.479 (1.680)	85.00 (42.11)
[19/294]	0.481 (1.632)	75.00 (43.75)
[20/294]	0.638 (1.586)	85.00 (45.71)
[21/294]	0.494 (1.539)	85.00 (47.50)
[22/294]	0.570 (1.500)	75.00 (48.70)
[23/294]	0.521 (1.458)	90.00 (50.42)
[24/294]	0.497 (1.426)	70.00 (51.20)
[25/294]	0.597 (1.392)	85.00 (52.50)
[26/294]	0.512 (1.360)	75.00 (53.33)
[27/294]	0.472 (1.329)	85.00 (54.46)
 * Train Acc: 54.464
 * Avg. Data time: 0.070, Avg. Batch time: 0.143, Avg. Train-batch time: 0.027, Avg. Replay-batch time: 0.040
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 24.198, Time: 24.04
=============Stream Learning Run 1=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	1.274 (1.274)	30.00 (30.00)
[1/294]	0.630 (0.952)	70.00 (50.00)
[2/294]	0.780 (0.895)	55.00 (51.67)
[3/294]	0.679 (0.841)	65.00 (55.00)
[4/294]	0.952 (0.863)	35.00 (51.00)
[5/294]	0.751 (0.844)	65.00 (53.33)
[6/294]	0.823 (0.841)	45.00 (52.14)
[7/294]	0.592 (0.810)	70.00 (54.38)
[8/294]	0.733 (0.801)	65.00 (55.56)
[9/294]	0.627 (0.784)	60.00 (56.00)
[10/294]	0.563 (0.764)	80.00 (58.18)
[11/294]	0.872 (0.773)	35.00 (56.25)
[12/294]	0.623 (0.761)	65.00 (56.92)
[13/294]	0.628 (0.752)	50.00 (56.43)
[14/294]	0.563 (0.739)	65.00 (57.00)
[15/294]	0.589 (0.730)	75.00 (58.12)
[16/294]	0.519 (0.717)	80.00 (59.41)
[17/294]	0.727 (0.718)	45.00 (58.61)
[18/294]	0.473 (0.705)	85.00 (60.00)
[19/294]	0.529 (0.696)	65.00 (60.25)
[20/294]	0.653 (0.694)	65.00 (60.48)
[21/294]	0.562 (0.688)	60.00 (60.45)
[22/294]	0.497 (0.680)	75.00 (61.09)
[23/294]	0.666 (0.679)	60.00 (61.04)
[24/294]	0.494 (0.672)	80.00 (61.80)
[25/294]	0.504 (0.665)	70.00 (62.12)
[26/294]	0.671 (0.666)	70.00 (62.41)
[27/294]	0.530 (0.661)	70.00 (62.68)
[28/294]	0.540 (0.657)	65.00 (62.76)
[29/294]	0.631 (0.656)	65.00 (62.83)
[30/294]	0.481 (0.650)	75.00 (63.23)
[31/294]	0.512 (0.646)	80.00 (63.75)
[32/294]	0.365 (0.637)	100.00 (64.85)
[33/294]	0.481 (0.633)	80.00 (65.29)
[34/294]	0.435 (0.627)	95.00 (66.14)
[35/294]	0.499 (0.623)	80.00 (66.53)
[36/294]	0.612 (0.623)	60.00 (66.35)
[37/294]	0.478 (0.619)	85.00 (66.84)
[38/294]	0.550 (0.618)	80.00 (67.18)
[39/294]	0.277 (0.609)	100.00 (68.00)
[40/294]	0.379 (0.603)	95.00 (68.66)
[41/294]	0.479 (0.600)	90.00 (69.17)
[42/294]	0.344 (0.595)	95.00 (69.77)
[43/294]	0.469 (0.592)	85.00 (70.11)
[44/294]	0.468 (0.589)	75.00 (70.22)
[45/294]	0.443 (0.586)	75.00 (70.33)
[46/294]	0.347 (0.581)	95.00 (70.85)
[47/294]	0.370 (0.576)	90.00 (71.25)
[48/294]	0.311 (0.571)	90.00 (71.63)
[49/294]	0.387 (0.567)	95.00 (72.10)
[50/294]	0.366 (0.563)	90.00 (72.45)
[51/294]	0.404 (0.560)	85.00 (72.69)
[52/294]	0.359 (0.556)	90.00 (73.02)
[53/294]	0.306 (0.552)	100.00 (73.52)
[54/294]	0.449 (0.550)	75.00 (73.55)
[55/294]	0.371 (0.547)	85.00 (73.75)
[56/294]	0.282 (0.542)	95.00 (74.12)
[57/294]	0.284 (0.538)	90.00 (74.40)
[58/294]	0.457 (0.536)	85.00 (74.58)
[59/294]	0.303 (0.532)	95.00 (74.92)
[60/294]	0.193 (0.527)	100.00 (75.33)
[61/294]	0.391 (0.525)	85.00 (75.48)
[62/294]	0.293 (0.521)	95.00 (75.79)
[63/294]	0.366 (0.519)	90.00 (76.02)
[64/294]	0.353 (0.516)	80.00 (76.08)
[65/294]	0.371 (0.514)	90.00 (76.29)
[66/294]	0.243 (0.510)	100.00 (76.64)
[67/294]	0.276 (0.506)	95.00 (76.91)
[68/294]	0.349 (0.504)	85.00 (77.03)
[69/294]	0.332 (0.502)	95.00 (77.29)
[70/294]	0.406 (0.500)	85.00 (77.39)
[71/294]	0.212 (0.496)	90.00 (77.57)
[72/294]	0.356 (0.494)	85.00 (77.67)
[73/294]	0.227 (0.491)	95.00 (77.91)
[74/294]	0.273 (0.488)	95.00 (78.13)
[75/294]	0.297 (0.485)	90.00 (78.29)
[76/294]	0.454 (0.485)	75.00 (78.25)
[77/294]	0.381 (0.484)	80.00 (78.27)
[78/294]	0.324 (0.481)	90.00 (78.42)
[79/294]	0.316 (0.479)	95.00 (78.62)
[80/294]	0.277 (0.477)	85.00 (78.70)
[81/294]	0.257 (0.474)	80.00 (78.72)
[82/294]	0.325 (0.472)	90.00 (78.86)
[83/294]	0.267 (0.470)	95.00 (79.05)
[84/294]	0.215 (0.467)	90.00 (79.18)
[85/294]	0.206 (0.464)	100.00 (79.42)
[86/294]	0.163 (0.461)	100.00 (79.66)
[87/294]	0.224 (0.458)	100.00 (79.89)
[88/294]	0.143 (0.454)	100.00 (80.11)
[89/294]	0.214 (0.452)	95.00 (80.28)
[90/294]	0.272 (0.450)	95.00 (80.44)
[91/294]	0.257 (0.448)	90.00 (80.54)
[92/294]	0.177 (0.445)	100.00 (80.75)
[93/294]	0.150 (0.441)	90.00 (80.85)
[94/294]	0.316 (0.440)	90.00 (80.95)
[95/294]	0.261 (0.438)	95.00 (81.09)
[96/294]	0.138 (0.435)	100.00 (81.29)
[97/294]	0.258 (0.433)	90.00 (81.38)
[98/294]	0.287 (0.432)	95.00 (81.52)
[99/294]	0.258 (0.430)	90.00 (81.60)
[100/294]	0.182 (0.428)	100.00 (81.78)
[101/294]	0.135 (0.425)	100.00 (81.96)
[102/294]	0.344 (0.424)	90.00 (82.04)
[103/294]	0.224 (0.422)	95.00 (82.16)
[104/294]	0.251 (0.421)	95.00 (82.29)
[105/294]	0.310 (0.419)	80.00 (82.26)
[106/294]	0.351 (0.419)	85.00 (82.29)
[107/294]	0.210 (0.417)	95.00 (82.41)
[108/294]	0.227 (0.415)	90.00 (82.48)
[109/294]	0.226 (0.413)	100.00 (82.64)
[110/294]	0.263 (0.412)	85.00 (82.66)
[111/294]	0.162 (0.410)	95.00 (82.77)
[112/294]	0.200 (0.408)	95.00 (82.88)
[113/294]	0.263 (0.407)	95.00 (82.98)
[114/294]	0.170 (0.405)	95.00 (83.09)
[115/294]	0.194 (0.403)	95.00 (83.19)
[116/294]	0.313 (0.402)	85.00 (83.21)
[117/294]	0.211 (0.400)	90.00 (83.26)
[118/294]	0.097 (0.398)	100.00 (83.40)
[119/294]	0.245 (0.397)	95.00 (83.50)
[120/294]	0.243 (0.395)	90.00 (83.55)
[121/294]	0.145 (0.393)	100.00 (83.69)
[122/294]	0.196 (0.392)	95.00 (83.78)
[123/294]	0.190 (0.390)	95.00 (83.87)
[124/294]	0.299 (0.389)	90.00 (83.92)
[125/294]	0.234 (0.388)	85.00 (83.93)
[126/294]	0.325 (0.388)	85.00 (83.94)
[127/294]	0.149 (0.386)	100.00 (84.06)
[128/294]	0.126 (0.384)	100.00 (84.19)
[129/294]	0.322 (0.383)	85.00 (84.19)
[130/294]	0.332 (0.383)	80.00 (84.16)
[131/294]	0.235 (0.382)	90.00 (84.20)
[132/294]	0.194 (0.380)	90.00 (84.25)
[133/294]	0.213 (0.379)	95.00 (84.33)
[134/294]	0.097 (0.377)	100.00 (84.44)
[135/294]	0.094 (0.375)	100.00 (84.56)
[136/294]	0.181 (0.374)	95.00 (84.64)
[137/294]	0.201 (0.372)	95.00 (84.71)
[138/294]	0.215 (0.371)	90.00 (84.75)
[139/294]	0.193 (0.370)	90.00 (84.79)
[140/294]	0.210 (0.369)	95.00 (84.86)
[141/294]	0.129 (0.367)	100.00 (84.96)
[142/294]	0.106 (0.365)	100.00 (85.07)
[143/294]	0.119 (0.364)	100.00 (85.17)
[144/294]	0.172 (0.362)	95.00 (85.24)
[145/294]	0.149 (0.361)	100.00 (85.34)
[146/294]	0.179 (0.359)	95.00 (85.41)
[147/294]	0.424 (0.360)	75.00 (85.34)
[148/294]	0.248 (0.359)	90.00 (85.37)
[149/294]	0.143 (0.358)	100.00 (85.47)
[150/294]	0.151 (0.356)	95.00 (85.53)
[151/294]	0.129 (0.355)	90.00 (85.56)
[152/294]	0.252 (0.354)	90.00 (85.59)
[153/294]	0.116 (0.353)	95.00 (85.65)
[154/294]	0.223 (0.352)	90.00 (85.68)
[155/294]	0.214 (0.351)	90.00 (85.71)
[156/294]	0.322 (0.351)	85.00 (85.70)
[157/294]	0.220 (0.350)	90.00 (85.73)
[158/294]	0.336 (0.350)	85.00 (85.72)
[159/294]	0.152 (0.349)	95.00 (85.78)
[160/294]	0.221 (0.348)	90.00 (85.81)
[161/294]	0.268 (0.347)	90.00 (85.83)
[162/294]	0.259 (0.347)	85.00 (85.83)
[163/294]	0.141 (0.346)	90.00 (85.85)
[164/294]	0.230 (0.345)	90.00 (85.88)
[165/294]	0.251 (0.344)	90.00 (85.90)
[166/294]	0.093 (0.343)	100.00 (85.99)
[167/294]	0.135 (0.341)	95.00 (86.04)
[168/294]	0.211 (0.341)	90.00 (86.07)
[169/294]	0.211 (0.340)	90.00 (86.09)
[170/294]	0.165 (0.339)	95.00 (86.14)
[171/294]	0.293 (0.339)	90.00 (86.16)
[172/294]	0.118 (0.337)	100.00 (86.24)
[173/294]	0.060 (0.336)	100.00 (86.32)
[174/294]	0.234 (0.335)	90.00 (86.34)
[175/294]	0.210 (0.335)	90.00 (86.36)
[176/294]	0.143 (0.333)	95.00 (86.41)
[177/294]	0.162 (0.332)	100.00 (86.49)
[178/294]	0.098 (0.331)	100.00 (86.56)
[179/294]	0.206 (0.330)	95.00 (86.61)
[180/294]	0.153 (0.329)	95.00 (86.66)
[181/294]	0.158 (0.329)	95.00 (86.70)
[182/294]	0.410 (0.329)	85.00 (86.69)
[183/294]	0.251 (0.329)	85.00 (86.68)
[184/294]	0.152 (0.328)	90.00 (86.70)
[185/294]	0.101 (0.326)	95.00 (86.75)
[186/294]	0.155 (0.325)	90.00 (86.76)
[187/294]	0.088 (0.324)	100.00 (86.84)
[188/294]	0.086 (0.323)	100.00 (86.90)
[189/294]	0.112 (0.322)	95.00 (86.95)
[190/294]	0.106 (0.321)	95.00 (86.99)
[191/294]	0.217 (0.320)	90.00 (87.01)
[192/294]	0.347 (0.320)	85.00 (86.99)
[193/294]	0.148 (0.319)	95.00 (87.04)
[194/294]	0.228 (0.319)	90.00 (87.05)
[195/294]	0.207 (0.318)	90.00 (87.07)
[196/294]	0.247 (0.318)	95.00 (87.11)
[197/294]	0.175 (0.317)	95.00 (87.15)
[198/294]	0.166 (0.317)	95.00 (87.19)
[199/294]	0.108 (0.315)	95.00 (87.22)
[200/294]	0.131 (0.315)	95.00 (87.26)
[201/294]	0.135 (0.314)	90.00 (87.28)
[202/294]	0.161 (0.313)	95.00 (87.32)
[203/294]	0.111 (0.312)	100.00 (87.38)
[204/294]	0.215 (0.311)	90.00 (87.39)
[205/294]	0.214 (0.311)	95.00 (87.43)
[206/294]	0.156 (0.310)	95.00 (87.46)
[207/294]	0.126 (0.309)	100.00 (87.52)
[208/294]	0.229 (0.309)	85.00 (87.51)
[209/294]	0.261 (0.309)	90.00 (87.52)
[210/294]	0.256 (0.309)	85.00 (87.51)
[211/294]	0.103 (0.308)	100.00 (87.57)
[212/294]	0.155 (0.307)	85.00 (87.56)
[213/294]	0.308 (0.307)	85.00 (87.55)
[214/294]	0.068 (0.306)	100.00 (87.60)
[215/294]	0.094 (0.305)	100.00 (87.66)
[216/294]	0.118 (0.304)	100.00 (87.72)
[217/294]	0.109 (0.303)	95.00 (87.75)
[218/294]	0.123 (0.302)	95.00 (87.79)
[219/294]	0.139 (0.301)	95.00 (87.82)
[220/294]	0.105 (0.301)	95.00 (87.85)
[221/294]	0.039 (0.299)	100.00 (87.91)
[222/294]	0.105 (0.298)	95.00 (87.94)
[223/294]	0.103 (0.298)	100.00 (87.99)
[224/294]	0.071 (0.297)	100.00 (88.04)
[225/294]	0.178 (0.296)	90.00 (88.05)
[226/294]	0.187 (0.296)	90.00 (88.06)
[227/294]	0.092 (0.295)	100.00 (88.11)
[228/294]	0.125 (0.294)	95.00 (88.14)
[229/294]	0.128 (0.293)	95.00 (88.17)
[230/294]	0.082 (0.292)	100.00 (88.23)
[231/294]	0.167 (0.292)	95.00 (88.25)
[232/294]	0.320 (0.292)	95.00 (88.28)
[233/294]	0.182 (0.291)	95.00 (88.31)
[234/294]	0.209 (0.291)	85.00 (88.30)
[235/294]	0.197 (0.291)	90.00 (88.31)
[236/294]	0.200 (0.290)	85.00 (88.29)
[237/294]	0.092 (0.289)	100.00 (88.34)
[238/294]	0.073 (0.289)	100.00 (88.39)
[239/294]	0.092 (0.288)	95.00 (88.42)
[240/294]	0.030 (0.287)	100.00 (88.46)
[241/294]	0.173 (0.286)	95.00 (88.49)
[242/294]	0.093 (0.285)	100.00 (88.54)
[243/294]	0.197 (0.285)	90.00 (88.55)
[244/294]	0.076 (0.284)	100.00 (88.59)
[245/294]	0.049 (0.283)	100.00 (88.64)
[246/294]	0.082 (0.282)	100.00 (88.68)
[247/294]	0.168 (0.282)	95.00 (88.71)
[248/294]	0.138 (0.281)	90.00 (88.71)
[249/294]	0.106 (0.281)	95.00 (88.74)
[250/294]	0.138 (0.280)	95.00 (88.76)
[251/294]	0.172 (0.280)	95.00 (88.79)
[252/294]	0.085 (0.279)	100.00 (88.83)
[253/294]	0.125 (0.278)	100.00 (88.88)
[254/294]	0.110 (0.278)	95.00 (88.90)
[255/294]	0.071 (0.277)	95.00 (88.93)
[256/294]	0.215 (0.277)	90.00 (88.93)
[257/294]	0.175 (0.276)	95.00 (88.95)
[258/294]	0.092 (0.275)	95.00 (88.98)
[259/294]	0.131 (0.275)	95.00 (89.00)
[260/294]	0.050 (0.274)	100.00 (89.04)
[261/294]	0.159 (0.274)	90.00 (89.05)
[262/294]	0.128 (0.273)	95.00 (89.07)
[263/294]	0.054 (0.272)	100.00 (89.11)
[264/294]	0.145 (0.272)	95.00 (89.13)
[265/294]	0.153 (0.271)	90.00 (89.14)
[266/294]	0.065 (0.271)	100.00 (89.18)
[267/294]	0.150 (0.270)	95.00 (89.20)
[268/294]	0.036 (0.269)	100.00 (89.24)
[269/294]	0.104 (0.269)	100.00 (89.28)
[270/294]	0.106 (0.268)	100.00 (89.32)
[271/294]	0.203 (0.268)	90.00 (89.32)
[272/294]	0.149 (0.267)	95.00 (89.34)
[273/294]	0.096 (0.267)	100.00 (89.38)
[274/294]	0.098 (0.266)	100.00 (89.42)
[275/294]	0.088 (0.265)	95.00 (89.44)
[276/294]	0.152 (0.265)	95.00 (89.46)
[277/294]	0.159 (0.265)	95.00 (89.48)
[278/294]	0.157 (0.264)	90.00 (89.48)
[279/294]	0.051 (0.264)	100.00 (89.52)
[280/294]	0.078 (0.263)	100.00 (89.56)
[281/294]	0.096 (0.262)	95.00 (89.57)
[282/294]	0.109 (0.262)	100.00 (89.61)
[283/294]	0.143 (0.261)	90.00 (89.61)
[284/294]	0.050 (0.261)	100.00 (89.65)
[285/294]	0.100 (0.260)	95.00 (89.67)
[286/294]	0.072 (0.259)	100.00 (89.70)
[287/294]	0.127 (0.259)	100.00 (89.74)
[288/294]	0.129 (0.258)	95.00 (89.76)
[289/294]	0.089 (0.258)	95.00 (89.78)
[290/294]	0.153 (0.258)	95.00 (89.79)
[291/294]	0.100 (0.257)	100.00 (89.83)
[292/294]	0.141 (0.257)	95.00 (89.85)
[293/294]	0.113 (0.256)	95.00 (89.86)
 * Train Acc: 89.864
 * Avg. Data time: 0.006, Avg. Batch time: 0.056, Avg. Forward time: 0.005, Avg. Backward time: 0.027
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 93.135, Time: 94.98
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.132 (3.291)	0.00 (0.00)
[1/294]	0.164 (3.223)	0.00 (0.00)
[2/294]	0.059 (3.047)	0.00 (0.00)
[3/294]	0.094 (2.836)	5.00 (1.25)
[4/294]	0.187 (2.607)	5.00 (2.00)
[5/294]	0.061 (2.403)	25.00 (5.83)
[6/294]	0.165 (2.203)	55.00 (12.86)
[7/294]	0.252 (2.071)	50.00 (17.50)
[8/294]	0.098 (1.938)	55.00 (21.67)
[9/294]	0.246 (1.811)	60.00 (25.50)
[10/294]	0.114 (1.700)	70.00 (29.55)
[11/294]	0.136 (1.624)	65.00 (32.50)
[12/294]	0.130 (1.562)	65.00 (35.00)
[13/294]	0.359 (1.488)	75.00 (37.86)
 * Train Acc: 37.857
 * Avg. Data time: 1.152, Avg. Batch time: 1.198, Avg. Train-batch time: 0.023, Avg. Replay-batch time: 0.021
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 51.984, Time: 326.73
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.229 (4.737)	0.00 (0.00)
[1/294]	0.274 (4.510)	0.00 (0.00)
[2/294]	0.223 (4.375)	0.00 (0.00)
[3/294]	0.382 (4.131)	0.00 (0.00)
[4/294]	0.240 (3.996)	0.00 (0.00)
[5/294]	0.190 (3.773)	0.00 (0.00)
[6/294]	0.400 (3.533)	5.00 (0.71)
[7/294]	0.459 (3.269)	40.00 (5.62)
[8/294]	0.229 (3.110)	20.00 (7.22)
[9/294]	0.394 (2.898)	60.00 (12.50)
[10/294]	0.271 (2.739)	50.00 (15.91)
[11/294]	0.304 (2.598)	50.00 (18.75)
[12/294]	0.484 (2.472)	65.00 (22.31)
[13/294]	0.299 (2.346)	75.00 (26.07)
[14/294]	0.375 (2.257)	55.00 (28.00)
[15/294]	0.320 (2.181)	55.00 (29.69)
[16/294]	0.370 (2.110)	50.00 (30.88)
[17/294]	0.306 (2.039)	55.00 (32.22)
[18/294]	0.434 (1.960)	75.00 (34.47)
[19/294]	0.266 (1.900)	65.00 (36.00)
 * Train Acc: 36.000
 * Avg. Data time: 0.094, Avg. Batch time: 0.148, Avg. Train-batch time: 0.024, Avg. Replay-batch time: 0.025
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 34.458, Time: 12.40
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.455 (4.032)	0.00 (0.00)
[1/294]	0.352 (3.752)	0.00 (0.00)
[2/294]	0.314 (3.621)	0.00 (0.00)
[3/294]	0.459 (3.487)	0.00 (0.00)
[4/294]	0.269 (3.397)	0.00 (0.00)
[5/294]	0.447 (3.235)	5.00 (0.83)
[6/294]	0.347 (3.114)	0.00 (0.71)
[7/294]	0.409 (2.952)	5.00 (1.25)
[8/294]	0.355 (2.829)	10.00 (2.22)
[9/294]	0.505 (2.714)	30.00 (5.00)
[10/294]	0.313 (2.610)	40.00 (8.18)
[11/294]	0.311 (2.524)	35.00 (10.42)
[12/294]	0.372 (2.434)	35.00 (12.31)
[13/294]	0.339 (2.346)	60.00 (15.71)
[14/294]	0.363 (2.288)	30.00 (16.67)
[15/294]	0.422 (2.212)	60.00 (19.38)
[16/294]	0.282 (2.139)	60.00 (21.76)
[17/294]	0.410 (2.061)	75.00 (24.72)
[18/294]	0.484 (2.005)	65.00 (26.84)
[19/294]	0.396 (1.951)	60.00 (28.50)
[20/294]	0.483 (1.886)	80.00 (30.95)
[21/294]	0.457 (1.831)	70.00 (32.73)
[22/294]	0.439 (1.776)	70.00 (34.35)
[23/294]	0.404 (1.726)	85.00 (36.46)
 * Train Acc: 36.458
 * Avg. Data time: 0.078, Avg. Batch time: 0.151, Avg. Train-batch time: 0.028, Avg. Replay-batch time: 0.037
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 34.115, Time: 18.87
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.372 (3.339)	0.00 (0.00)
[1/294]	0.567 (3.121)	0.00 (0.00)
[2/294]	0.314 (2.995)	5.00 (1.67)
[3/294]	0.349 (2.814)	10.00 (3.75)
[4/294]	0.550 (2.737)	5.00 (4.00)
[5/294]	0.355 (2.640)	10.00 (5.00)
[6/294]	0.456 (2.555)	15.00 (6.43)
[7/294]	0.395 (2.398)	55.00 (12.50)
[8/294]	0.320 (2.302)	35.00 (15.00)
[9/294]	0.248 (2.207)	35.00 (17.00)
[10/294]	0.526 (2.129)	45.00 (19.55)
[11/294]	0.550 (2.067)	40.00 (21.25)
[12/294]	0.448 (1.996)	50.00 (23.46)
[13/294]	0.421 (1.928)	55.00 (25.71)
[14/294]	0.316 (1.860)	65.00 (28.33)
[15/294]	0.393 (1.804)	60.00 (30.31)
[16/294]	0.524 (1.755)	60.00 (32.06)
[17/294]	0.460 (1.716)	45.00 (32.78)
[18/294]	0.490 (1.682)	55.00 (33.95)
[19/294]	0.331 (1.634)	70.00 (35.75)
[20/294]	0.343 (1.602)	45.00 (36.19)
[21/294]	0.425 (1.558)	75.00 (37.95)
[22/294]	0.371 (1.532)	45.00 (38.26)
[23/294]	0.390 (1.499)	65.00 (39.38)
[24/294]	0.371 (1.466)	75.00 (40.80)
[25/294]	0.379 (1.448)	55.00 (41.35)
 * Train Acc: 41.346
 * Avg. Data time: 0.063, Avg. Batch time: 0.128, Avg. Train-batch time: 0.026, Avg. Replay-batch time: 0.036
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 27.380, Time: 19.84
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.385 (3.044)	0.00 (0.00)
[1/294]	0.456 (3.086)	0.00 (0.00)
[2/294]	0.276 (3.031)	0.00 (0.00)
[3/294]	0.400 (2.915)	0.00 (0.00)
[4/294]	0.314 (2.744)	10.00 (2.00)
[5/294]	0.383 (2.559)	35.00 (7.50)
[6/294]	0.237 (2.393)	25.00 (10.00)
[7/294]	0.350 (2.237)	60.00 (16.25)
[8/294]	0.465 (2.132)	45.00 (19.44)
[9/294]	0.367 (2.024)	60.00 (23.50)
[10/294]	0.413 (1.914)	75.00 (28.18)
[11/294]	0.366 (1.818)	60.00 (30.83)
[12/294]	0.380 (1.731)	75.00 (34.23)
[13/294]	0.379 (1.664)	60.00 (36.07)
[14/294]	0.407 (1.615)	50.00 (37.00)
[15/294]	0.322 (1.555)	75.00 (39.38)
[16/294]	0.343 (1.512)	65.00 (40.88)
[17/294]	0.536 (1.469)	70.00 (42.50)
[18/294]	0.527 (1.431)	70.00 (43.95)
[19/294]	0.415 (1.387)	75.00 (45.50)
[20/294]	0.379 (1.346)	70.00 (46.67)
[21/294]	0.335 (1.305)	90.00 (48.64)
[22/294]	0.361 (1.276)	60.00 (49.13)
[23/294]	0.362 (1.247)	75.00 (50.21)
[24/294]	0.492 (1.216)	95.00 (52.00)
[25/294]	0.368 (1.184)	90.00 (53.46)
[26/294]	0.470 (1.154)	90.00 (54.81)
[27/294]	0.308 (1.129)	80.00 (55.71)
 * Train Acc: 55.714
 * Avg. Data time: 0.072, Avg. Batch time: 0.138, Avg. Train-batch time: 0.027, Avg. Replay-batch time: 0.036
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 28.127, Time: 22.77
testing accuracies
           0          1          2          3          4          5
0  94.087302  53.869048  38.669494  27.904895  21.722876  24.198251
1  93.134921  51.984127  34.457672  34.114842  27.379628  28.127485
validation accuracies
Empty DataFrame
Columns: []
Index: [0, 1]

=============Stream Learning Run 0=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	1.883 (1.883)	45.00 (45.00)
[1/294]	1.156 (1.520)	40.00 (42.50)
[2/294]	0.949 (1.329)	50.00 (45.00)
[3/294]	0.705 (1.173)	60.00 (48.75)
[4/294]	0.990 (1.137)	50.00 (49.00)
[5/294]	0.953 (1.106)	50.00 (49.17)
[6/294]	1.076 (1.102)	50.00 (49.29)
[7/294]	0.614 (1.041)	60.00 (50.62)
[8/294]	0.466 (0.977)	90.00 (55.00)
[9/294]	0.459 (0.925)	85.00 (58.00)
[10/294]	0.534 (0.890)	75.00 (59.55)
[11/294]	0.778 (0.880)	50.00 (58.75)
[12/294]	0.678 (0.865)	60.00 (58.85)
[13/294]	0.715 (0.854)	55.00 (58.57)
[14/294]	0.417 (0.825)	90.00 (60.67)
[15/294]	0.494 (0.804)	70.00 (61.25)
[16/294]	0.510 (0.787)	90.00 (62.94)
[17/294]	0.593 (0.776)	75.00 (63.61)
[18/294]	0.400 (0.756)	90.00 (65.00)
[19/294]	0.468 (0.742)	75.00 (65.50)
[20/294]	0.583 (0.734)	75.00 (65.95)
[21/294]	0.495 (0.723)	75.00 (66.36)
[22/294]	0.486 (0.713)	80.00 (66.96)
[23/294]	0.439 (0.702)	90.00 (67.92)
[24/294]	0.572 (0.697)	80.00 (68.40)
[25/294]	0.592 (0.692)	80.00 (68.85)
[26/294]	0.691 (0.692)	45.00 (67.96)
[27/294]	0.510 (0.686)	55.00 (67.50)
[28/294]	0.108 (0.666)	100.00 (68.62)
[29/294]	0.291 (0.653)	90.00 (69.33)
[30/294]	0.397 (0.645)	90.00 (70.00)
[31/294]	0.559 (0.643)	65.00 (69.84)
[32/294]	0.372 (0.634)	70.00 (69.85)
[33/294]	0.349 (0.626)	80.00 (70.15)
[34/294]	0.643 (0.626)	60.00 (69.86)
[35/294]	0.195 (0.614)	100.00 (70.69)
[36/294]	0.349 (0.607)	85.00 (71.08)
[37/294]	0.330 (0.600)	95.00 (71.71)
[38/294]	0.432 (0.596)	90.00 (72.18)
[39/294]	0.424 (0.591)	90.00 (72.62)
[40/294]	0.286 (0.584)	100.00 (73.29)
[41/294]	0.245 (0.576)	100.00 (73.93)
[42/294]	0.352 (0.571)	90.00 (74.30)
[43/294]	0.237 (0.563)	90.00 (74.66)
[44/294]	0.258 (0.556)	90.00 (75.00)
[45/294]	0.144 (0.547)	100.00 (75.54)
[46/294]	0.409 (0.544)	90.00 (75.85)
[47/294]	0.314 (0.540)	95.00 (76.25)
[48/294]	0.190 (0.532)	100.00 (76.73)
[49/294]	0.121 (0.524)	100.00 (77.20)
[50/294]	0.086 (0.516)	100.00 (77.65)
[51/294]	0.061 (0.507)	100.00 (78.08)
[52/294]	0.225 (0.502)	90.00 (78.30)
[53/294]	0.238 (0.497)	100.00 (78.70)
[54/294]	0.084 (0.489)	100.00 (79.09)
[55/294]	0.171 (0.484)	95.00 (79.38)
[56/294]	0.068 (0.476)	100.00 (79.74)
[57/294]	0.037 (0.469)	100.00 (80.09)
[58/294]	0.049 (0.462)	100.00 (80.42)
[59/294]	0.004 (0.454)	100.00 (80.75)
[60/294]	0.020 (0.447)	100.00 (81.07)
[61/294]	0.026 (0.440)	100.00 (81.37)
[62/294]	0.128 (0.435)	100.00 (81.67)
[63/294]	0.188 (0.431)	90.00 (81.80)
[64/294]	0.103 (0.426)	100.00 (82.08)
[65/294]	0.085 (0.421)	100.00 (82.35)
[66/294]	0.436 (0.421)	80.00 (82.31)
[67/294]	0.801 (0.427)	55.00 (81.91)
[68/294]	0.743 (0.431)	60.00 (81.59)
[69/294]	0.766 (0.436)	65.00 (81.36)
[70/294]	0.486 (0.437)	75.00 (81.27)
[71/294]	0.198 (0.434)	90.00 (81.39)
[72/294]	0.201 (0.430)	95.00 (81.58)
[73/294]	0.044 (0.425)	100.00 (81.82)
[74/294]	0.061 (0.420)	100.00 (82.07)
[75/294]	0.176 (0.417)	95.00 (82.24)
[76/294]	0.271 (0.415)	90.00 (82.34)
[77/294]	0.102 (0.411)	95.00 (82.50)
[78/294]	0.181 (0.408)	90.00 (82.59)
[79/294]	0.107 (0.404)	95.00 (82.75)
[80/294]	0.164 (0.402)	95.00 (82.90)
[81/294]	0.189 (0.399)	90.00 (82.99)
[82/294]	0.366 (0.399)	80.00 (82.95)
[83/294]	0.412 (0.399)	75.00 (82.86)
[84/294]	0.655 (0.402)	75.00 (82.76)
[85/294]	0.244 (0.400)	90.00 (82.85)
[86/294]	0.171 (0.397)	95.00 (82.99)
[87/294]	0.256 (0.396)	90.00 (83.07)
[88/294]	0.218 (0.394)	90.00 (83.15)
[89/294]	0.143 (0.391)	100.00 (83.33)
[90/294]	0.021 (0.387)	100.00 (83.52)
[91/294]	0.512 (0.388)	70.00 (83.37)
[92/294]	0.058 (0.385)	100.00 (83.55)
[93/294]	0.269 (0.383)	90.00 (83.62)
[94/294]	0.229 (0.382)	85.00 (83.63)
[95/294]	0.065 (0.378)	100.00 (83.80)
[96/294]	0.098 (0.376)	95.00 (83.92)
[97/294]	0.046 (0.372)	100.00 (84.08)
[98/294]	0.038 (0.369)	100.00 (84.24)
[99/294]	0.282 (0.368)	90.00 (84.30)
[100/294]	0.326 (0.368)	85.00 (84.31)
[101/294]	0.048 (0.364)	100.00 (84.46)
[102/294]	0.114 (0.362)	100.00 (84.61)
[103/294]	0.424 (0.363)	90.00 (84.66)
[104/294]	0.361 (0.363)	85.00 (84.67)
[105/294]	0.001 (0.359)	100.00 (84.81)
[106/294]	0.003 (0.356)	100.00 (84.95)
[107/294]	0.009 (0.353)	100.00 (85.09)
[108/294]	0.007 (0.349)	100.00 (85.23)
[109/294]	0.160 (0.348)	95.00 (85.32)
[110/294]	0.343 (0.348)	80.00 (85.27)
[111/294]	0.199 (0.346)	95.00 (85.36)
[112/294]	0.100 (0.344)	95.00 (85.44)
[113/294]	0.312 (0.344)	90.00 (85.48)
[114/294]	0.344 (0.344)	90.00 (85.52)
[115/294]	0.174 (0.342)	95.00 (85.60)
[116/294]	0.585 (0.344)	60.00 (85.38)
[117/294]	0.668 (0.347)	75.00 (85.30)
[118/294]	1.202 (0.354)	55.00 (85.04)
[119/294]	0.457 (0.355)	75.00 (84.96)
[120/294]	0.056 (0.353)	100.00 (85.08)
[121/294]	0.025 (0.350)	100.00 (85.20)
[122/294]	0.219 (0.349)	90.00 (85.24)
[123/294]	0.975 (0.354)	75.00 (85.16)
[124/294]	0.987 (0.359)	65.00 (85.00)
[125/294]	0.126 (0.357)	95.00 (85.08)
[126/294]	1.275 (0.365)	55.00 (84.84)
[127/294]	0.395 (0.365)	80.00 (84.80)
[128/294]	0.139 (0.363)	100.00 (84.92)
[129/294]	0.068 (0.361)	100.00 (85.04)
[130/294]	0.203 (0.360)	90.00 (85.08)
[131/294]	0.075 (0.357)	100.00 (85.19)
[132/294]	0.194 (0.356)	100.00 (85.30)
[133/294]	0.091 (0.354)	100.00 (85.41)
[134/294]	0.167 (0.353)	100.00 (85.52)
[135/294]	0.231 (0.352)	100.00 (85.62)
[136/294]	0.095 (0.350)	100.00 (85.73)
[137/294]	0.051 (0.348)	100.00 (85.83)
[138/294]	0.098 (0.346)	95.00 (85.90)
[139/294]	0.159 (0.345)	100.00 (86.00)
[140/294]	0.125 (0.343)	100.00 (86.10)
[141/294]	0.213 (0.342)	100.00 (86.20)
[142/294]	0.291 (0.342)	90.00 (86.22)
[143/294]	0.096 (0.340)	100.00 (86.32)
[144/294]	0.150 (0.339)	100.00 (86.41)
[145/294]	0.299 (0.339)	80.00 (86.37)
[146/294]	0.200 (0.338)	90.00 (86.39)
[147/294]	0.185 (0.337)	90.00 (86.42)
[148/294]	0.308 (0.336)	80.00 (86.38)
[149/294]	0.106 (0.335)	95.00 (86.43)
[150/294]	0.120 (0.333)	100.00 (86.52)
[151/294]	0.148 (0.332)	100.00 (86.61)
[152/294]	0.237 (0.332)	90.00 (86.63)
[153/294]	0.173 (0.331)	95.00 (86.69)
[154/294]	0.261 (0.330)	95.00 (86.74)
[155/294]	0.135 (0.329)	95.00 (86.79)
[156/294]	0.122 (0.328)	95.00 (86.85)
[157/294]	0.328 (0.328)	85.00 (86.84)
[158/294]	0.341 (0.328)	90.00 (86.86)
[159/294]	0.271 (0.327)	95.00 (86.91)
[160/294]	0.177 (0.326)	95.00 (86.96)
[161/294]	0.186 (0.326)	100.00 (87.04)
[162/294]	0.148 (0.324)	100.00 (87.12)
[163/294]	0.225 (0.324)	85.00 (87.10)
[164/294]	0.004 (0.322)	100.00 (87.18)
[165/294]	0.107 (0.321)	95.00 (87.23)
[166/294]	0.210 (0.320)	85.00 (87.22)
[167/294]	0.100 (0.319)	100.00 (87.29)
[168/294]	0.114 (0.317)	100.00 (87.37)
[169/294]	0.051 (0.316)	100.00 (87.44)
[170/294]	0.059 (0.314)	100.00 (87.51)
[171/294]	0.063 (0.313)	100.00 (87.59)
[172/294]	0.007 (0.311)	100.00 (87.66)
[173/294]	0.040 (0.310)	100.00 (87.73)
[174/294]	0.025 (0.308)	100.00 (87.80)
[175/294]	0.043 (0.306)	100.00 (87.87)
[176/294]	0.053 (0.305)	95.00 (87.91)
[177/294]	0.009 (0.303)	100.00 (87.98)
[178/294]	0.174 (0.303)	90.00 (87.99)
[179/294]	0.046 (0.301)	100.00 (88.06)
[180/294]	0.360 (0.302)	85.00 (88.04)
[181/294]	0.090 (0.300)	95.00 (88.08)
[182/294]	0.002 (0.299)	100.00 (88.14)
[183/294]	0.009 (0.297)	100.00 (88.21)
[184/294]	0.027 (0.296)	100.00 (88.27)
[185/294]	0.312 (0.296)	90.00 (88.28)
[186/294]	0.069 (0.295)	100.00 (88.34)
[187/294]	0.029 (0.293)	100.00 (88.40)
[188/294]	0.528 (0.294)	75.00 (88.33)
[189/294]	0.878 (0.297)	60.00 (88.18)
[190/294]	0.345 (0.298)	95.00 (88.22)
[191/294]	0.381 (0.298)	80.00 (88.18)
[192/294]	0.012 (0.297)	100.00 (88.24)
[193/294]	0.010 (0.295)	100.00 (88.30)
[194/294]	0.147 (0.294)	95.00 (88.33)
[195/294]	0.054 (0.293)	100.00 (88.39)
[196/294]	0.006 (0.292)	100.00 (88.45)
[197/294]	0.378 (0.292)	80.00 (88.41)
[198/294]	0.724 (0.294)	60.00 (88.27)
[199/294]	0.002 (0.293)	100.00 (88.33)
[200/294]	0.012 (0.291)	100.00 (88.38)
[201/294]	0.079 (0.290)	95.00 (88.42)
[202/294]	0.016 (0.289)	100.00 (88.47)
[203/294]	0.079 (0.288)	100.00 (88.53)
[204/294]	0.272 (0.288)	95.00 (88.56)
[205/294]	0.099 (0.287)	100.00 (88.62)
[206/294]	0.004 (0.286)	100.00 (88.67)
[207/294]	0.101 (0.285)	100.00 (88.73)
[208/294]	0.066 (0.284)	100.00 (88.78)
[209/294]	0.142 (0.283)	100.00 (88.83)
[210/294]	0.086 (0.282)	100.00 (88.89)
[211/294]	0.225 (0.282)	85.00 (88.87)
[212/294]	0.166 (0.281)	100.00 (88.92)
[213/294]	0.019 (0.280)	100.00 (88.97)
[214/294]	0.077 (0.279)	100.00 (89.02)
[215/294]	0.048 (0.278)	100.00 (89.07)
[216/294]	0.004 (0.277)	100.00 (89.12)
[217/294]	0.130 (0.276)	100.00 (89.17)
[218/294]	0.066 (0.275)	100.00 (89.22)
[219/294]	0.025 (0.274)	100.00 (89.27)
[220/294]	0.054 (0.273)	100.00 (89.32)
[221/294]	0.112 (0.272)	95.00 (89.35)
[222/294]	0.217 (0.272)	85.00 (89.33)
[223/294]	0.063 (0.271)	95.00 (89.35)
[224/294]	0.200 (0.271)	90.00 (89.36)
[225/294]	0.322 (0.271)	95.00 (89.38)
[226/294]	0.174 (0.271)	95.00 (89.41)
[227/294]	0.084 (0.270)	100.00 (89.45)
[228/294]	0.218 (0.270)	95.00 (89.48)
[229/294]	0.106 (0.269)	95.00 (89.50)
[230/294]	0.000 (0.268)	100.00 (89.55)
[231/294]	0.447 (0.269)	85.00 (89.53)
[232/294]	0.174 (0.268)	90.00 (89.53)
[233/294]	0.039 (0.267)	100.00 (89.57)
[234/294]	0.015 (0.266)	100.00 (89.62)
[235/294]	0.065 (0.265)	100.00 (89.66)
[236/294]	0.069 (0.264)	100.00 (89.70)
[237/294]	0.059 (0.264)	100.00 (89.75)
[238/294]	0.004 (0.262)	100.00 (89.79)
[239/294]	0.002 (0.261)	100.00 (89.83)
[240/294]	0.003 (0.260)	100.00 (89.88)
[241/294]	0.012 (0.259)	100.00 (89.92)
[242/294]	0.042 (0.258)	100.00 (89.96)
[243/294]	0.047 (0.257)	100.00 (90.00)
[244/294]	0.199 (0.257)	95.00 (90.02)
[245/294]	0.119 (0.257)	95.00 (90.04)
[246/294]	0.329 (0.257)	85.00 (90.02)
[247/294]	0.057 (0.256)	100.00 (90.06)
[248/294]	0.006 (0.255)	100.00 (90.10)
[249/294]	0.010 (0.254)	100.00 (90.14)
[250/294]	0.026 (0.253)	100.00 (90.18)
[251/294]	0.058 (0.252)	100.00 (90.22)
[252/294]	0.034 (0.252)	100.00 (90.26)
[253/294]	0.049 (0.251)	100.00 (90.30)
[254/294]	0.019 (0.250)	100.00 (90.33)
[255/294]	0.175 (0.250)	90.00 (90.33)
[256/294]	0.031 (0.249)	100.00 (90.37)
[257/294]	0.006 (0.248)	100.00 (90.41)
[258/294]	0.005 (0.247)	100.00 (90.44)
[259/294]	0.004 (0.246)	100.00 (90.48)
[260/294]	0.006 (0.245)	100.00 (90.52)
[261/294]	0.005 (0.244)	100.00 (90.55)
[262/294]	0.001 (0.243)	100.00 (90.59)
[263/294]	0.020 (0.242)	100.00 (90.62)
[264/294]	0.131 (0.242)	90.00 (90.62)
[265/294]	0.216 (0.242)	90.00 (90.62)
[266/294]	0.047 (0.241)	100.00 (90.66)
[267/294]	0.034 (0.240)	100.00 (90.69)
[268/294]	0.010 (0.239)	100.00 (90.72)
[269/294]	0.030 (0.239)	100.00 (90.76)
[270/294]	0.031 (0.238)	100.00 (90.79)
[271/294]	0.121 (0.237)	100.00 (90.83)
[272/294]	0.318 (0.238)	85.00 (90.81)
[273/294]	0.001 (0.237)	100.00 (90.84)
[274/294]	0.046 (0.236)	100.00 (90.87)
[275/294]	0.107 (0.236)	95.00 (90.89)
[276/294]	0.113 (0.235)	95.00 (90.90)
[277/294]	0.054 (0.235)	100.00 (90.94)
[278/294]	0.153 (0.234)	90.00 (90.93)
[279/294]	0.262 (0.234)	90.00 (90.93)
[280/294]	0.048 (0.234)	95.00 (90.94)
[281/294]	0.063 (0.233)	95.00 (90.96)
[282/294]	0.006 (0.232)	100.00 (90.99)
[283/294]	0.101 (0.232)	100.00 (91.02)
[284/294]	0.060 (0.231)	100.00 (91.05)
[285/294]	0.072 (0.231)	100.00 (91.08)
[286/294]	0.016 (0.230)	100.00 (91.11)
[287/294]	0.032 (0.229)	100.00 (91.15)
[288/294]	0.076 (0.229)	95.00 (91.16)
[289/294]	0.013 (0.228)	100.00 (91.19)
[290/294]	0.142 (0.228)	95.00 (91.20)
[291/294]	0.001 (0.227)	100.00 (91.23)
[292/294]	0.006 (0.226)	100.00 (91.26)
[293/294]	0.008 (0.226)	100.00 (91.29)
 * Train Acc: 91.293
 * Avg. Data time: 1.442, Avg. Batch time: 1.472, Avg. Forward time: 0.004, Avg. Backward time: 0.017
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 97.222, Time: 541.72
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.297 (5.145)	0.00 (0.00)
[1/294]	0.698 (4.519)	10.00 (5.00)
[2/294]	0.533 (3.580)	35.00 (15.00)
[3/294]	0.431 (2.904)	50.00 (23.75)
[4/294]	0.624 (2.400)	95.00 (38.00)
[5/294]	0.479 (2.084)	80.00 (45.00)
[6/294]	0.509 (1.896)	60.00 (47.14)
[7/294]	0.559 (1.765)	30.00 (45.00)
[8/294]	0.497 (1.639)	65.00 (47.22)
[9/294]	0.548 (1.531)	85.00 (51.00)
[10/294]	0.431 (1.470)	40.00 (50.00)
[11/294]	0.545 (1.387)	70.00 (51.67)
[12/294]	0.589 (1.308)	80.00 (53.85)
[13/294]	0.511 (1.249)	90.00 (56.43)
 * Train Acc: 56.429
 * Avg. Data time: 5.526, Avg. Batch time: 5.575, Avg. Train-batch time: 0.026, Avg. Replay-batch time: 0.022
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 38.790, Time: 362.92
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.428 (4.128)	0.00 (0.00)
[1/294]	0.447 (3.526)	0.00 (0.00)
[2/294]	0.461 (2.946)	10.00 (3.33)
[3/294]	0.531 (2.493)	50.00 (15.00)
[4/294]	0.564 (2.154)	55.00 (23.00)
[5/294]	0.696 (1.913)	70.00 (30.83)
[6/294]	0.607 (1.744)	70.00 (36.43)
[7/294]	0.686 (1.616)	55.00 (38.75)
[8/294]	0.727 (1.519)	50.00 (40.00)
[9/294]	0.734 (1.453)	40.00 (40.00)
[10/294]	0.687 (1.390)	50.00 (40.91)
[11/294]	0.669 (1.331)	65.00 (42.92)
[12/294]	0.641 (1.282)	50.00 (43.46)
[13/294]	0.631 (1.238)	50.00 (43.93)
[14/294]	0.639 (1.196)	55.00 (44.67)
[15/294]	0.729 (1.151)	95.00 (47.81)
[16/294]	0.680 (1.111)	80.00 (49.71)
[17/294]	0.656 (1.081)	75.00 (51.11)
[18/294]	0.699 (1.055)	85.00 (52.89)
[19/294]	0.698 (1.028)	85.00 (54.50)
 * Train Acc: 54.500
 * Avg. Data time: 3.208, Avg. Batch time: 3.251, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.020
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 34.813, Time: 1247.92
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.532 (3.561)	0.00 (0.00)
[1/294]	0.538 (3.476)	0.00 (0.00)
[2/294]	0.574 (3.262)	0.00 (0.00)
[3/294]	0.557 (3.042)	0.00 (0.00)
[4/294]	0.591 (2.841)	0.00 (0.00)
[5/294]	0.600 (2.686)	5.00 (0.83)
[6/294]	0.619 (2.566)	15.00 (2.86)
[7/294]	0.614 (2.470)	45.00 (8.12)
[8/294]	0.622 (2.368)	50.00 (12.78)
[9/294]	0.630 (2.283)	60.00 (17.50)
[10/294]	0.642 (2.214)	50.00 (20.45)
[11/294]	0.654 (2.143)	50.00 (22.92)
[12/294]	0.659 (2.070)	50.00 (25.00)
[13/294]	0.669 (1.999)	55.00 (27.14)
[14/294]	0.708 (1.931)	60.00 (29.33)
[15/294]	0.684 (1.861)	70.00 (31.88)
[16/294]	0.702 (1.793)	90.00 (35.29)
[17/294]	0.707 (1.742)	85.00 (38.06)
[18/294]	0.722 (1.708)	55.00 (38.95)
[19/294]	0.694 (1.668)	70.00 (40.50)
[20/294]	0.716 (1.624)	75.00 (42.14)
[21/294]	0.839 (1.573)	100.00 (44.77)
[22/294]	0.756 (1.523)	100.00 (47.17)
[23/294]	0.799 (1.475)	95.00 (49.17)
 * Train Acc: 49.167
 * Avg. Data time: 5.285, Avg. Batch time: 5.329, Avg. Train-batch time: 0.023, Avg. Replay-batch time: 0.021
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 29.875, Time: 1117.33
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.572 (4.281)	0.00 (0.00)
[1/294]	0.558 (4.130)	0.00 (0.00)
[2/294]	0.563 (3.869)	0.00 (0.00)
[3/294]	0.569 (3.500)	0.00 (0.00)
[4/294]	0.585 (3.261)	0.00 (0.00)
[5/294]	0.605 (3.076)	0.00 (0.00)
[6/294]	0.616 (2.903)	10.00 (1.43)
[7/294]	0.625 (2.780)	5.00 (1.88)
[8/294]	0.603 (2.636)	35.00 (5.56)
[9/294]	0.717 (2.479)	55.00 (10.50)
[10/294]	0.706 (2.340)	50.00 (14.09)
[11/294]	0.720 (2.230)	50.00 (17.08)
[12/294]	0.721 (2.119)	55.00 (20.00)
[13/294]	0.809 (2.028)	60.00 (22.86)
[14/294]	0.721 (1.949)	50.00 (24.67)
[15/294]	0.729 (1.883)	50.00 (26.25)
[16/294]	0.924 (1.825)	50.00 (27.65)
[17/294]	0.920 (1.760)	85.00 (30.83)
[18/294]	0.940 (1.695)	55.00 (32.11)
[19/294]	0.863 (1.642)	55.00 (33.25)
[20/294]	0.797 (1.604)	35.00 (33.33)
[21/294]	0.845 (1.565)	85.00 (35.68)
[22/294]	0.762 (1.525)	80.00 (37.61)
[23/294]	0.731 (1.483)	100.00 (40.21)
[24/294]	0.821 (1.442)	95.00 (42.40)
[25/294]	0.745 (1.410)	90.00 (44.23)
 * Train Acc: 44.231
 * Avg. Data time: 3.810, Avg. Batch time: 3.848, Avg. Train-batch time: 0.017, Avg. Replay-batch time: 0.020
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 25.732, Time: 855.22
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.583 (4.416)	0.00 (0.00)
[1/294]	0.584 (3.939)	0.00 (0.00)
[2/294]	0.578 (3.506)	0.00 (0.00)
[3/294]	0.602 (3.283)	0.00 (0.00)
[4/294]	0.600 (3.142)	0.00 (0.00)
[5/294]	0.602 (3.041)	0.00 (0.00)
[6/294]	0.610 (2.956)	0.00 (0.00)
[7/294]	0.608 (2.880)	0.00 (0.00)
[8/294]	0.619 (2.799)	0.00 (0.00)
[9/294]	0.615 (2.715)	45.00 (4.50)
[10/294]	0.621 (2.629)	50.00 (8.64)
[11/294]	0.640 (2.532)	50.00 (12.08)
[12/294]	0.640 (2.442)	50.00 (15.00)
[13/294]	0.724 (2.356)	50.00 (17.50)
[14/294]	0.756 (2.276)	50.00 (19.67)
[15/294]	0.817 (2.188)	50.00 (21.56)
[16/294]	0.776 (2.100)	55.00 (23.53)
[17/294]	0.858 (2.027)	50.00 (25.00)
[18/294]	0.978 (1.968)	50.00 (26.32)
[19/294]	0.845 (1.907)	60.00 (28.00)
[20/294]	0.852 (1.854)	50.00 (29.05)
[21/294]	0.952 (1.811)	50.00 (30.00)
[22/294]	0.984 (1.766)	50.00 (30.87)
[23/294]	0.924 (1.725)	50.00 (31.67)
[24/294]	0.914 (1.690)	50.00 (32.40)
[25/294]	0.812 (1.654)	50.00 (33.08)
[26/294]	0.784 (1.617)	80.00 (34.81)
[27/294]	0.775 (1.584)	55.00 (35.54)
 * Train Acc: 35.536
 * Avg. Data time: 1.906, Avg. Batch time: 1.950, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.021
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 20.223, Time: 791.58
=============Stream Learning Run 1=============
Changing output layer to contain 12 classes
============BEGINNING STREAM LEARNING============
=============Training Task 0=============
Active output nodes for this task: 
[0, 1]
=============Training Epoch 0=============
Batch	 Loss		 Acc
[0/294]	0.826 (0.826)	50.00 (50.00)
[1/294]	0.716 (0.771)	50.00 (50.00)
[2/294]	0.625 (0.722)	65.00 (55.00)
[3/294]	0.552 (0.680)	60.00 (56.25)
[4/294]	0.654 (0.675)	55.00 (56.00)
[5/294]	0.633 (0.668)	60.00 (56.67)
[6/294]	0.475 (0.640)	80.00 (60.00)
[7/294]	0.525 (0.626)	80.00 (62.50)
[8/294]	0.360 (0.596)	95.00 (66.11)
[9/294]	0.644 (0.601)	75.00 (67.00)
[10/294]	0.555 (0.597)	75.00 (67.73)
[11/294]	0.330 (0.575)	95.00 (70.00)
[12/294]	0.223 (0.548)	100.00 (72.31)
[13/294]	0.208 (0.523)	95.00 (73.93)
[14/294]	0.122 (0.497)	100.00 (75.67)
[15/294]	0.415 (0.491)	85.00 (76.25)
[16/294]	0.502 (0.492)	70.00 (75.88)
[17/294]	0.134 (0.472)	95.00 (76.94)
[18/294]	0.460 (0.472)	80.00 (77.11)
[19/294]	0.609 (0.478)	60.00 (76.25)
[20/294]	0.231 (0.467)	90.00 (76.90)
[21/294]	0.057 (0.448)	100.00 (77.95)
[22/294]	0.073 (0.432)	100.00 (78.91)
[23/294]	0.761 (0.445)	80.00 (78.96)
[24/294]	1.307 (0.480)	50.00 (77.80)
[25/294]	0.105 (0.465)	95.00 (78.46)
[26/294]	0.012 (0.449)	100.00 (79.26)
[27/294]	0.009 (0.433)	100.00 (80.00)
[28/294]	0.008 (0.418)	100.00 (80.69)
[29/294]	0.005 (0.404)	100.00 (81.33)
[30/294]	0.040 (0.393)	100.00 (81.94)
[31/294]	1.608 (0.431)	50.00 (80.94)
[32/294]	0.141 (0.422)	95.00 (81.36)
[33/294]	0.258 (0.417)	85.00 (81.47)
[34/294]	0.324 (0.414)	80.00 (81.43)
[35/294]	0.141 (0.407)	100.00 (81.94)
[36/294]	0.300 (0.404)	80.00 (81.89)
[37/294]	0.442 (0.405)	65.00 (81.45)
[38/294]	0.328 (0.403)	90.00 (81.67)
[39/294]	0.203 (0.398)	95.00 (82.00)
[40/294]	0.097 (0.391)	100.00 (82.44)
[41/294]	0.003 (0.381)	100.00 (82.86)
[42/294]	0.064 (0.374)	100.00 (83.26)
[43/294]	0.166 (0.369)	95.00 (83.52)
[44/294]	0.162 (0.365)	95.00 (83.78)
[45/294]	0.022 (0.357)	100.00 (84.13)
[46/294]	0.188 (0.354)	90.00 (84.26)
[47/294]	0.136 (0.349)	95.00 (84.48)
[48/294]	0.007 (0.342)	100.00 (84.80)
[49/294]	1.033 (0.356)	50.00 (84.10)
[50/294]	0.614 (0.361)	65.00 (83.73)
[51/294]	0.263 (0.359)	90.00 (83.85)
[52/294]	0.214 (0.356)	90.00 (83.96)
[53/294]	0.096 (0.352)	100.00 (84.26)
[54/294]	0.089 (0.347)	95.00 (84.45)
[55/294]	0.196 (0.344)	85.00 (84.46)
[56/294]	0.434 (0.346)	65.00 (84.12)
[57/294]	0.241 (0.344)	85.00 (84.14)
[58/294]	0.167 (0.341)	100.00 (84.41)
[59/294]	0.163 (0.338)	100.00 (84.67)
[60/294]	0.058 (0.333)	100.00 (84.92)
[61/294]	0.023 (0.328)	100.00 (85.16)
[62/294]	0.039 (0.324)	100.00 (85.40)
[63/294]	0.249 (0.323)	95.00 (85.55)
[64/294]	0.140 (0.320)	95.00 (85.69)
[65/294]	0.037 (0.315)	100.00 (85.91)
[66/294]	0.420 (0.317)	75.00 (85.75)
[67/294]	0.167 (0.315)	90.00 (85.81)
[68/294]	0.131 (0.312)	100.00 (86.01)
[69/294]	0.322 (0.312)	100.00 (86.21)
[70/294]	0.349 (0.313)	90.00 (86.27)
[71/294]	0.261 (0.312)	95.00 (86.39)
[72/294]	0.275 (0.312)	95.00 (86.51)
[73/294]	0.155 (0.309)	95.00 (86.62)
[74/294]	0.222 (0.308)	85.00 (86.60)
[75/294]	0.298 (0.308)	75.00 (86.45)
[76/294]	0.019 (0.304)	100.00 (86.62)
[77/294]	0.615 (0.308)	55.00 (86.22)
[78/294]	0.430 (0.310)	70.00 (86.01)
[79/294]	0.371 (0.311)	75.00 (85.88)
[80/294]	0.087 (0.308)	95.00 (85.99)
[81/294]	0.184 (0.306)	95.00 (86.10)
[82/294]	0.099 (0.304)	100.00 (86.27)
[83/294]	0.177 (0.302)	85.00 (86.25)
[84/294]	0.080 (0.300)	100.00 (86.41)
[85/294]	0.074 (0.297)	95.00 (86.51)
[86/294]	0.081 (0.295)	95.00 (86.61)
[87/294]	0.001 (0.291)	100.00 (86.76)
[88/294]	0.043 (0.289)	100.00 (86.91)
[89/294]	0.040 (0.286)	100.00 (87.06)
[90/294]	0.044 (0.283)	100.00 (87.20)
[91/294]	0.071 (0.281)	100.00 (87.34)
[92/294]	0.028 (0.278)	100.00 (87.47)
[93/294]	0.022 (0.275)	100.00 (87.61)
[94/294]	0.153 (0.274)	90.00 (87.63)
[95/294]	0.090 (0.272)	100.00 (87.76)
[96/294]	0.053 (0.270)	100.00 (87.89)
[97/294]	0.112 (0.268)	95.00 (87.96)
[98/294]	0.018 (0.266)	100.00 (88.08)
[99/294]	0.036 (0.264)	100.00 (88.20)
[100/294]	0.103 (0.262)	100.00 (88.32)
[101/294]	0.190 (0.261)	95.00 (88.38)
[102/294]	0.086 (0.260)	100.00 (88.50)
[103/294]	0.039 (0.257)	100.00 (88.61)
[104/294]	0.095 (0.256)	100.00 (88.71)
[105/294]	0.091 (0.254)	100.00 (88.82)
[106/294]	0.167 (0.253)	90.00 (88.83)
[107/294]	0.005 (0.251)	100.00 (88.94)
[108/294]	0.002 (0.249)	100.00 (89.04)
[109/294]	0.051 (0.247)	95.00 (89.09)
[110/294]	0.018 (0.245)	100.00 (89.19)
[111/294]	0.045 (0.243)	100.00 (89.29)
[112/294]	0.050 (0.242)	100.00 (89.38)
[113/294]	0.006 (0.239)	100.00 (89.47)
[114/294]	0.003 (0.237)	100.00 (89.57)
[115/294]	0.002 (0.235)	100.00 (89.66)
[116/294]	0.016 (0.233)	100.00 (89.74)
[117/294]	0.006 (0.232)	100.00 (89.83)
[118/294]	0.008 (0.230)	100.00 (89.92)
[119/294]	0.009 (0.228)	100.00 (90.00)
[120/294]	0.045 (0.226)	95.00 (90.04)
[121/294]	0.004 (0.225)	100.00 (90.12)
[122/294]	0.128 (0.224)	100.00 (90.20)
[123/294]	0.033 (0.222)	100.00 (90.28)
[124/294]	0.014 (0.221)	100.00 (90.36)
[125/294]	0.031 (0.219)	100.00 (90.44)
[126/294]	0.005 (0.217)	100.00 (90.51)
[127/294]	0.022 (0.216)	100.00 (90.59)
[128/294]	0.039 (0.214)	100.00 (90.66)
[129/294]	0.122 (0.214)	95.00 (90.69)
[130/294]	0.257 (0.214)	90.00 (90.69)
[131/294]	0.071 (0.213)	95.00 (90.72)
[132/294]	0.000 (0.211)	100.00 (90.79)
[133/294]	0.001 (0.210)	100.00 (90.86)
[134/294]	0.094 (0.209)	95.00 (90.89)
[135/294]	0.043 (0.208)	100.00 (90.96)
[136/294]	0.004 (0.206)	100.00 (91.02)
[137/294]	0.000 (0.205)	100.00 (91.09)
[138/294]	0.058 (0.204)	100.00 (91.15)
[139/294]	0.136 (0.203)	100.00 (91.21)
[140/294]	0.004 (0.202)	100.00 (91.28)
[141/294]	0.004 (0.200)	100.00 (91.34)
[142/294]	0.103 (0.200)	95.00 (91.36)
[143/294]	0.040 (0.199)	100.00 (91.42)
[144/294]	0.000 (0.197)	100.00 (91.48)
[145/294]	0.000 (0.196)	100.00 (91.54)
[146/294]	0.000 (0.195)	100.00 (91.60)
[147/294]	0.152 (0.194)	100.00 (91.66)
[148/294]	0.127 (0.194)	95.00 (91.68)
[149/294]	0.000 (0.193)	100.00 (91.73)
[150/294]	0.002 (0.191)	100.00 (91.79)
[151/294]	0.000 (0.190)	100.00 (91.84)
[152/294]	0.000 (0.189)	100.00 (91.90)
[153/294]	0.001 (0.188)	100.00 (91.95)
[154/294]	0.012 (0.186)	100.00 (92.00)
[155/294]	0.000 (0.185)	100.00 (92.05)
[156/294]	0.021 (0.184)	100.00 (92.10)
[157/294]	0.725 (0.188)	80.00 (92.03)
[158/294]	0.009 (0.186)	100.00 (92.08)
[159/294]	0.041 (0.186)	100.00 (92.12)
[160/294]	0.004 (0.184)	100.00 (92.17)
[161/294]	0.000 (0.183)	100.00 (92.22)
[162/294]	0.001 (0.182)	100.00 (92.27)
[163/294]	0.006 (0.181)	100.00 (92.32)
[164/294]	0.006 (0.180)	100.00 (92.36)
[165/294]	0.006 (0.179)	100.00 (92.41)
[166/294]	0.001 (0.178)	100.00 (92.46)
[167/294]	0.002 (0.177)	100.00 (92.50)
[168/294]	0.004 (0.176)	100.00 (92.54)
[169/294]	0.206 (0.176)	90.00 (92.53)
[170/294]	0.469 (0.178)	75.00 (92.43)
[171/294]	0.033 (0.177)	100.00 (92.47)
[172/294]	0.005 (0.176)	100.00 (92.51)
[173/294]	0.005 (0.175)	100.00 (92.56)
[174/294]	0.024 (0.174)	100.00 (92.60)
[175/294]	0.006 (0.173)	100.00 (92.64)
[176/294]	0.002 (0.172)	100.00 (92.68)
[177/294]	0.000 (0.171)	100.00 (92.72)
[178/294]	0.001 (0.170)	100.00 (92.77)
[179/294]	0.008 (0.169)	100.00 (92.81)
[180/294]	0.043 (0.169)	100.00 (92.85)
[181/294]	0.074 (0.168)	95.00 (92.86)
[182/294]	0.023 (0.167)	100.00 (92.90)
[183/294]	0.015 (0.167)	100.00 (92.93)
[184/294]	0.001 (0.166)	100.00 (92.97)
[185/294]	0.013 (0.165)	100.00 (93.01)
[186/294]	0.001 (0.164)	100.00 (93.05)
[187/294]	0.001 (0.163)	100.00 (93.09)
[188/294]	0.009 (0.162)	100.00 (93.12)
[189/294]	0.341 (0.163)	85.00 (93.08)
[190/294]	0.074 (0.163)	100.00 (93.12)
[191/294]	0.032 (0.162)	100.00 (93.15)
[192/294]	0.252 (0.162)	95.00 (93.16)
[193/294]	0.054 (0.162)	100.00 (93.20)
[194/294]	0.071 (0.161)	95.00 (93.21)
[195/294]	0.001 (0.161)	100.00 (93.24)
[196/294]	0.002 (0.160)	100.00 (93.27)
[197/294]	0.000 (0.159)	100.00 (93.31)
[198/294]	0.005 (0.158)	100.00 (93.34)
[199/294]	0.001 (0.157)	100.00 (93.38)
[200/294]	0.005 (0.157)	100.00 (93.41)
[201/294]	0.038 (0.156)	100.00 (93.44)
[202/294]	0.002 (0.155)	100.00 (93.47)
[203/294]	0.027 (0.155)	100.00 (93.50)
[204/294]	0.062 (0.154)	100.00 (93.54)
[205/294]	0.050 (0.154)	100.00 (93.57)
[206/294]	0.225 (0.154)	95.00 (93.57)
[207/294]	0.017 (0.153)	100.00 (93.61)
[208/294]	0.013 (0.153)	100.00 (93.64)
[209/294]	0.150 (0.153)	90.00 (93.62)
[210/294]	0.036 (0.152)	100.00 (93.65)
[211/294]	0.007 (0.152)	100.00 (93.68)
[212/294]	0.015 (0.151)	100.00 (93.71)
[213/294]	0.308 (0.152)	95.00 (93.71)
[214/294]	0.038 (0.151)	100.00 (93.74)
[215/294]	0.045 (0.151)	100.00 (93.77)
[216/294]	0.000 (0.150)	100.00 (93.80)
[217/294]	0.013 (0.149)	100.00 (93.83)
[218/294]	0.030 (0.149)	100.00 (93.86)
[219/294]	0.026 (0.148)	100.00 (93.89)
[220/294]	0.239 (0.149)	85.00 (93.85)
[221/294]	0.097 (0.148)	95.00 (93.85)
[222/294]	0.014 (0.148)	100.00 (93.88)
[223/294]	0.177 (0.148)	90.00 (93.86)
[224/294]	0.005 (0.147)	100.00 (93.89)
[225/294]	0.000 (0.147)	100.00 (93.92)
[226/294]	0.404 (0.148)	90.00 (93.90)
[227/294]	0.013 (0.147)	100.00 (93.93)
[228/294]	0.004 (0.147)	100.00 (93.95)
[229/294]	0.007 (0.146)	100.00 (93.98)
[230/294]	0.012 (0.145)	100.00 (94.00)
[231/294]	0.752 (0.148)	60.00 (93.86)
[232/294]	0.123 (0.148)	90.00 (93.84)
[233/294]	0.041 (0.147)	100.00 (93.87)
[234/294]	0.106 (0.147)	90.00 (93.85)
[235/294]	0.006 (0.147)	100.00 (93.88)
[236/294]	0.013 (0.146)	100.00 (93.90)
[237/294]	0.003 (0.145)	100.00 (93.93)
[238/294]	0.021 (0.145)	100.00 (93.95)
[239/294]	0.020 (0.144)	100.00 (93.98)
[240/294]	0.030 (0.144)	100.00 (94.00)
[241/294]	0.001 (0.143)	100.00 (94.03)
[242/294]	0.058 (0.143)	100.00 (94.05)
[243/294]	0.104 (0.143)	95.00 (94.06)
[244/294]	0.004 (0.142)	100.00 (94.08)
[245/294]	0.032 (0.142)	100.00 (94.11)
[246/294]	0.004 (0.141)	100.00 (94.13)
[247/294]	0.001 (0.141)	100.00 (94.15)
[248/294]	0.001 (0.140)	100.00 (94.18)
[249/294]	0.001 (0.140)	100.00 (94.20)
[250/294]	0.001 (0.139)	100.00 (94.22)
[251/294]	0.024 (0.139)	100.00 (94.25)
[252/294]	0.424 (0.140)	80.00 (94.19)
[253/294]	0.051 (0.139)	100.00 (94.21)
[254/294]	0.006 (0.139)	100.00 (94.24)
[255/294]	0.031 (0.138)	100.00 (94.26)
[256/294]	0.003 (0.138)	100.00 (94.28)
[257/294]	0.020 (0.137)	100.00 (94.30)
[258/294]	0.039 (0.137)	100.00 (94.32)
[259/294]	0.033 (0.137)	100.00 (94.35)
[260/294]	0.004 (0.136)	100.00 (94.37)
[261/294]	0.000 (0.136)	100.00 (94.39)
[262/294]	0.000 (0.135)	100.00 (94.41)
[263/294]	0.016 (0.135)	100.00 (94.43)
[264/294]	0.007 (0.134)	100.00 (94.45)
[265/294]	0.069 (0.134)	95.00 (94.45)
[266/294]	0.058 (0.134)	95.00 (94.46)
[267/294]	0.038 (0.133)	100.00 (94.48)
[268/294]	0.009 (0.133)	100.00 (94.50)
[269/294]	0.022 (0.132)	100.00 (94.52)
[270/294]	0.034 (0.132)	100.00 (94.54)
[271/294]	0.073 (0.132)	95.00 (94.54)
[272/294]	0.091 (0.132)	95.00 (94.54)
[273/294]	0.000 (0.131)	100.00 (94.56)
[274/294]	0.000 (0.131)	100.00 (94.58)
[275/294]	0.000 (0.130)	100.00 (94.60)
[276/294]	0.001 (0.130)	100.00 (94.62)
[277/294]	0.001 (0.129)	100.00 (94.64)
[278/294]	0.008 (0.129)	100.00 (94.66)
[279/294]	0.087 (0.129)	95.00 (94.66)
[280/294]	0.000 (0.128)	100.00 (94.68)
[281/294]	0.015 (0.128)	100.00 (94.70)
[282/294]	0.030 (0.128)	100.00 (94.72)
[283/294]	0.000 (0.127)	100.00 (94.74)
[284/294]	0.013 (0.127)	100.00 (94.75)
[285/294]	0.297 (0.127)	90.00 (94.74)
[286/294]	0.010 (0.127)	100.00 (94.76)
[287/294]	0.059 (0.127)	100.00 (94.77)
[288/294]	0.058 (0.126)	100.00 (94.79)
[289/294]	1.037 (0.130)	70.00 (94.71)
[290/294]	0.061 (0.129)	100.00 (94.73)
[291/294]	0.005 (0.129)	100.00 (94.74)
[292/294]	0.001 (0.128)	100.00 (94.76)
[293/294]	0.006 (0.128)	100.00 (94.78)
 * Train Acc: 94.779
 * Avg. Data time: 1.378, Avg. Batch time: 1.408, Avg. Forward time: 0.004, Avg. Backward time: 0.017
Constructing exemplars for class 0
Constructing exemplars for class 1
 * Test Acc: 95.238, Time: 112.06
=============Training Task 1=============
Active output nodes for this task: 
[0, 1, 2, 3]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.313 (6.976)	0.00 (0.00)
[1/294]	1.285 (5.516)	5.00 (2.50)
[2/294]	0.298 (4.085)	25.00 (10.00)
[3/294]	0.287 (3.343)	5.00 (8.75)
[4/294]	1.033 (2.852)	15.00 (10.00)
[5/294]	0.346 (2.561)	25.00 (12.50)
[6/294]	0.477 (2.353)	25.00 (14.29)
[7/294]	0.549 (2.149)	55.00 (19.38)
[8/294]	0.481 (1.974)	55.00 (23.33)
[9/294]	0.560 (1.830)	90.00 (30.00)
[10/294]	0.451 (1.745)	50.00 (31.82)
[11/294]	0.624 (1.649)	55.00 (33.75)
[12/294]	0.519 (1.546)	100.00 (38.85)
[13/294]	0.490 (1.473)	60.00 (40.36)
 * Train Acc: 40.357
 * Avg. Data time: 1.577, Avg. Batch time: 1.618, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.019
Constructing exemplars for class 2
Constructing exemplars for class 3
 * Test Acc: 50.516, Time: 149.27
=============Training Task 2=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.439 (4.339)	0.00 (0.00)
[1/294]	0.462 (3.670)	0.00 (0.00)
[2/294]	0.450 (3.167)	0.00 (0.00)
[3/294]	0.534 (2.848)	0.00 (0.00)
[4/294]	0.524 (2.600)	35.00 (7.00)
[5/294]	0.554 (2.397)	45.00 (13.33)
[6/294]	0.612 (2.248)	45.00 (17.86)
[7/294]	0.640 (2.082)	50.00 (21.88)
[8/294]	0.587 (1.942)	50.00 (25.00)
[9/294]	0.662 (1.817)	55.00 (28.00)
[10/294]	0.672 (1.709)	95.00 (34.09)
[11/294]	0.619 (1.642)	50.00 (35.42)
[12/294]	0.727 (1.600)	25.00 (34.62)
[13/294]	0.761 (1.565)	35.00 (34.64)
[14/294]	0.790 (1.494)	100.00 (39.00)
[15/294]	0.650 (1.440)	80.00 (41.56)
[16/294]	0.816 (1.385)	85.00 (44.12)
[17/294]	0.675 (1.350)	45.00 (44.17)
[18/294]	0.768 (1.314)	70.00 (45.53)
[19/294]	0.688 (1.275)	85.00 (47.50)
 * Train Acc: 47.500
 * Avg. Data time: 0.661, Avg. Batch time: 0.704, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.020
Constructing exemplars for class 4
Constructing exemplars for class 5
 * Test Acc: 31.693, Time: 806.32
=============Training Task 3=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.556 (3.610)	0.00 (0.00)
[1/294]	0.529 (3.360)	0.00 (0.00)
[2/294]	0.534 (3.096)	0.00 (0.00)
[3/294]	0.545 (2.898)	0.00 (0.00)
[4/294]	0.560 (2.703)	0.00 (0.00)
[5/294]	0.572 (2.531)	25.00 (4.17)
[6/294]	0.610 (2.381)	50.00 (10.71)
[7/294]	0.615 (2.239)	40.00 (14.38)
[8/294]	0.620 (2.125)	40.00 (17.22)
[9/294]	0.686 (2.027)	50.00 (20.50)
[10/294]	0.668 (1.937)	50.00 (23.18)
[11/294]	0.722 (1.846)	50.00 (25.42)
[12/294]	0.719 (1.754)	100.00 (31.15)
[13/294]	0.734 (1.672)	100.00 (36.07)
[14/294]	0.796 (1.610)	55.00 (37.33)
[15/294]	0.765 (1.556)	70.00 (39.38)
[16/294]	0.765 (1.504)	80.00 (41.76)
[17/294]	0.751 (1.450)	90.00 (44.44)
[18/294]	0.846 (1.406)	80.00 (46.32)
[19/294]	0.785 (1.367)	80.00 (48.00)
[20/294]	0.871 (1.334)	60.00 (48.57)
[21/294]	0.782 (1.298)	80.00 (50.00)
[22/294]	0.798 (1.265)	85.00 (51.52)
[23/294]	0.787 (1.234)	95.00 (53.33)
 * Train Acc: 53.333
 * Avg. Data time: 5.186, Avg. Batch time: 5.229, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.021
Constructing exemplars for class 6
Constructing exemplars for class 7
 * Test Acc: 25.770, Time: 1227.88
=============Training Task 4=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.560 (4.212)	0.00 (0.00)
[1/294]	0.559 (3.905)	0.00 (0.00)
[2/294]	0.559 (3.618)	0.00 (0.00)
[3/294]	0.565 (3.324)	0.00 (0.00)
[4/294]	0.610 (3.074)	5.00 (1.00)
[5/294]	0.603 (2.868)	10.00 (2.50)
[6/294]	0.617 (2.708)	35.00 (7.14)
[7/294]	0.632 (2.611)	30.00 (10.00)
[8/294]	0.623 (2.526)	20.00 (11.11)
[9/294]	0.645 (2.444)	40.00 (14.00)
[10/294]	0.679 (2.362)	50.00 (17.27)
[11/294]	0.705 (2.289)	50.00 (20.00)
[12/294]	0.665 (2.216)	70.00 (23.85)
[13/294]	0.671 (2.138)	100.00 (29.29)
[14/294]	0.657 (2.047)	90.00 (33.33)
[15/294]	0.695 (1.971)	65.00 (35.31)
[16/294]	0.754 (1.909)	65.00 (37.06)
[17/294]	0.750 (1.836)	90.00 (40.00)
[18/294]	0.768 (1.782)	55.00 (40.79)
[19/294]	0.747 (1.735)	50.00 (41.25)
[20/294]	0.744 (1.698)	40.00 (41.19)
[21/294]	0.758 (1.641)	95.00 (43.64)
[22/294]	0.770 (1.586)	100.00 (46.09)
[23/294]	0.773 (1.535)	90.00 (47.92)
[24/294]	0.801 (1.491)	85.00 (49.40)
[25/294]	0.794 (1.447)	100.00 (51.35)
 * Train Acc: 51.346
 * Avg. Data time: 4.547, Avg. Batch time: 4.591, Avg. Train-batch time: 0.022, Avg. Replay-batch time: 0.021
Constructing exemplars for class 8
Constructing exemplars for class 9
 * Test Acc: 26.855, Time: 2178.81
=============Training Task 5=============
Active output nodes for this task: 
[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]
=============Training Epoch 0=============
Getting replay labels
Batch	 Loss		 Acc
[0/294]	0.557 (6.066)	0.00 (0.00)
[1/294]	0.566 (5.291)	0.00 (0.00)
[2/294]	0.555 (4.603)	0.00 (0.00)
[3/294]	0.559 (4.114)	0.00 (0.00)
[4/294]	0.560 (3.739)	0.00 (0.00)
[5/294]	0.548 (3.465)	10.00 (1.67)
[6/294]	0.568 (3.258)	10.00 (2.86)
[7/294]	0.594 (3.078)	25.00 (5.62)
[8/294]	0.610 (2.927)	35.00 (8.89)
[9/294]	0.608 (2.799)	50.00 (13.00)
[10/294]	0.597 (2.688)	60.00 (17.27)
[11/294]	0.606 (2.576)	70.00 (21.67)
[12/294]	0.613 (2.463)	90.00 (26.92)
[13/294]	0.637 (2.358)	85.00 (31.07)
[14/294]	0.594 (2.267)	70.00 (33.67)
[15/294]	0.635 (2.194)	65.00 (35.62)
[16/294]	0.699 (2.124)	60.00 (37.06)
[17/294]	0.670 (2.052)	85.00 (39.72)
[18/294]	0.657 (1.962)	100.00 (42.89)
[19/294]	0.751 (1.882)	95.00 (45.50)
[20/294]	0.797 (1.812)	100.00 (48.10)
[21/294]	0.811 (1.753)	95.00 (50.23)
[22/294]	0.789 (1.687)	100.00 (52.39)
[23/294]	0.782 (1.625)	100.00 (54.38)
[24/294]	0.841 (1.568)	100.00 (56.20)
[25/294]	0.757 (1.519)	90.00 (57.50)
[26/294]	0.747 (1.469)	100.00 (59.07)
[27/294]	0.770 (1.423)	100.00 (60.54)
 * Train Acc: 60.536
 * Avg. Data time: 6.698, Avg. Batch time: 6.741, Avg. Train-batch time: 0.021, Avg. Replay-batch time: 0.022
Constructing exemplars for class 10
Constructing exemplars for class 11
 * Test Acc: 32.527, Time: 2596.67
testing accuracies
           0          1          2          3          4          5
0  97.222222  38.789683  34.813146  29.874652  25.731785  20.222635
1  95.238095  50.515873  31.693122  25.769919  26.855236  32.527167
validation accuracies
Empty DataFrame
Columns: []
Index: [0, 1]
